{"ast":null,"code":"const {\n  CstParser,\n  Lexer,\n  createToken\n} = /* @__PURE__ */(() => {\n  var freeGlobal = typeof global == \"object\" && global && global.Object === Object && global;\n  const freeGlobal$1 = freeGlobal;\n  var freeSelf = typeof self == \"object\" && self && self.Object === Object && self;\n  var root = freeGlobal$1 || freeSelf || Function(\"return this\")();\n  const root$1 = root;\n  var Symbol$1 = root$1.Symbol;\n  const Symbol$2 = Symbol$1;\n  var objectProto$j = Object.prototype;\n  var hasOwnProperty$g = objectProto$j.hasOwnProperty;\n  var nativeObjectToString$1 = objectProto$j.toString;\n  var symToStringTag$1 = Symbol$2 ? Symbol$2.toStringTag : void 0;\n  function getRawTag(value) {\n    var isOwn = hasOwnProperty$g.call(value, symToStringTag$1),\n      tag = value[symToStringTag$1];\n    try {\n      value[symToStringTag$1] = void 0;\n      var unmasked = true;\n    } catch (e) {}\n    var result = nativeObjectToString$1.call(value);\n    if (unmasked) {\n      if (isOwn) {\n        value[symToStringTag$1] = tag;\n      } else {\n        delete value[symToStringTag$1];\n      }\n    }\n    return result;\n  }\n  var objectProto$i = Object.prototype;\n  var nativeObjectToString = objectProto$i.toString;\n  function objectToString(value) {\n    return nativeObjectToString.call(value);\n  }\n  var nullTag = \"[object Null]\",\n    undefinedTag = \"[object Undefined]\";\n  var symToStringTag = Symbol$2 ? Symbol$2.toStringTag : void 0;\n  function baseGetTag(value) {\n    if (value == null) {\n      return value === void 0 ? undefinedTag : nullTag;\n    }\n    return symToStringTag && symToStringTag in Object(value) ? getRawTag(value) : objectToString(value);\n  }\n  function isObjectLike(value) {\n    return value != null && typeof value == \"object\";\n  }\n  var symbolTag$3 = \"[object Symbol]\";\n  function isSymbol(value) {\n    return typeof value == \"symbol\" || isObjectLike(value) && baseGetTag(value) == symbolTag$3;\n  }\n  function arrayMap(array, iteratee) {\n    var index = -1,\n      length = array == null ? 0 : array.length,\n      result = Array(length);\n    while (++index < length) {\n      result[index] = iteratee(array[index], index, array);\n    }\n    return result;\n  }\n  var isArray = Array.isArray;\n  const isArray$1 = isArray;\n  var INFINITY$3 = 1 / 0;\n  var symbolProto$2 = Symbol$2 ? Symbol$2.prototype : void 0,\n    symbolToString = symbolProto$2 ? symbolProto$2.toString : void 0;\n  function baseToString(value) {\n    if (typeof value == \"string\") {\n      return value;\n    }\n    if (isArray$1(value)) {\n      return arrayMap(value, baseToString) + \"\";\n    }\n    if (isSymbol(value)) {\n      return symbolToString ? symbolToString.call(value) : \"\";\n    }\n    var result = value + \"\";\n    return result == \"0\" && 1 / value == -INFINITY$3 ? \"-0\" : result;\n  }\n  var reWhitespace = /\\s/;\n  function trimmedEndIndex(string) {\n    var index = string.length;\n    while (index-- && reWhitespace.test(string.charAt(index))) {}\n    return index;\n  }\n  var reTrimStart = /^\\s+/;\n  function baseTrim(string) {\n    return string ? string.slice(0, trimmedEndIndex(string) + 1).replace(reTrimStart, \"\") : string;\n  }\n  function isObject(value) {\n    var type = typeof value;\n    return value != null && (type == \"object\" || type == \"function\");\n  }\n  var NAN = 0 / 0;\n  var reIsBadHex = /^[-+]0x[0-9a-f]+$/i;\n  var reIsBinary = /^0b[01]+$/i;\n  var reIsOctal = /^0o[0-7]+$/i;\n  var freeParseInt = parseInt;\n  function toNumber(value) {\n    if (typeof value == \"number\") {\n      return value;\n    }\n    if (isSymbol(value)) {\n      return NAN;\n    }\n    if (isObject(value)) {\n      var other = typeof value.valueOf == \"function\" ? value.valueOf() : value;\n      value = isObject(other) ? other + \"\" : other;\n    }\n    if (typeof value != \"string\") {\n      return value === 0 ? value : +value;\n    }\n    value = baseTrim(value);\n    var isBinary = reIsBinary.test(value);\n    return isBinary || reIsOctal.test(value) ? freeParseInt(value.slice(2), isBinary ? 2 : 8) : reIsBadHex.test(value) ? NAN : +value;\n  }\n  var INFINITY$2 = 1 / 0,\n    MAX_INTEGER = 17976931348623157e292;\n  function toFinite(value) {\n    if (!value) {\n      return value === 0 ? value : 0;\n    }\n    value = toNumber(value);\n    if (value === INFINITY$2 || value === -INFINITY$2) {\n      var sign = value < 0 ? -1 : 1;\n      return sign * MAX_INTEGER;\n    }\n    return value === value ? value : 0;\n  }\n  function toInteger(value) {\n    var result = toFinite(value),\n      remainder = result % 1;\n    return result === result ? remainder ? result - remainder : result : 0;\n  }\n  function identity(value) {\n    return value;\n  }\n  var asyncTag = \"[object AsyncFunction]\",\n    funcTag$2 = \"[object Function]\",\n    genTag$1 = \"[object GeneratorFunction]\",\n    proxyTag = \"[object Proxy]\";\n  function isFunction(value) {\n    if (!isObject(value)) {\n      return false;\n    }\n    var tag = baseGetTag(value);\n    return tag == funcTag$2 || tag == genTag$1 || tag == asyncTag || tag == proxyTag;\n  }\n  var coreJsData = root$1[\"__core-js_shared__\"];\n  const coreJsData$1 = coreJsData;\n  var maskSrcKey = function () {\n    var uid = /[^.]+$/.exec(coreJsData$1 && coreJsData$1.keys && coreJsData$1.keys.IE_PROTO || \"\");\n    return uid ? \"Symbol(src)_1.\" + uid : \"\";\n  }();\n  function isMasked(func) {\n    return !!maskSrcKey && maskSrcKey in func;\n  }\n  var funcProto$1 = Function.prototype;\n  var funcToString$1 = funcProto$1.toString;\n  function toSource(func) {\n    if (func != null) {\n      try {\n        return funcToString$1.call(func);\n      } catch (e) {}\n      try {\n        return func + \"\";\n      } catch (e) {}\n    }\n    return \"\";\n  }\n  var reRegExpChar = /[\\\\^$.*+?()[\\]{}|]/g;\n  var reIsHostCtor = /^\\[object .+?Constructor\\]$/;\n  var funcProto = Function.prototype,\n    objectProto$h = Object.prototype;\n  var funcToString = funcProto.toString;\n  var hasOwnProperty$f = objectProto$h.hasOwnProperty;\n  var reIsNative = RegExp(\"^\" + funcToString.call(hasOwnProperty$f).replace(reRegExpChar, \"\\\\$&\").replace(/hasOwnProperty|(function).*?(?=\\\\\\()| for .+?(?=\\\\\\])/g, \"$1.*?\") + \"$\");\n  function baseIsNative(value) {\n    if (!isObject(value) || isMasked(value)) {\n      return false;\n    }\n    var pattern = isFunction(value) ? reIsNative : reIsHostCtor;\n    return pattern.test(toSource(value));\n  }\n  function getValue(object, key) {\n    return object == null ? void 0 : object[key];\n  }\n  function getNative(object, key) {\n    var value = getValue(object, key);\n    return baseIsNative(value) ? value : void 0;\n  }\n  var WeakMap = getNative(root$1, \"WeakMap\");\n  const WeakMap$1 = WeakMap;\n  var objectCreate = Object.create;\n  var baseCreate = function () {\n    function object() {}\n    return function (proto) {\n      if (!isObject(proto)) {\n        return {};\n      }\n      if (objectCreate) {\n        return objectCreate(proto);\n      }\n      object.prototype = proto;\n      var result = new object();\n      object.prototype = void 0;\n      return result;\n    };\n  }();\n  const baseCreate$1 = baseCreate;\n  function apply(func, thisArg, args) {\n    switch (args.length) {\n      case 0:\n        return func.call(thisArg);\n      case 1:\n        return func.call(thisArg, args[0]);\n      case 2:\n        return func.call(thisArg, args[0], args[1]);\n      case 3:\n        return func.call(thisArg, args[0], args[1], args[2]);\n    }\n    return func.apply(thisArg, args);\n  }\n  function noop() {}\n  function copyArray(source, array) {\n    var index = -1,\n      length = source.length;\n    array || (array = Array(length));\n    while (++index < length) {\n      array[index] = source[index];\n    }\n    return array;\n  }\n  var HOT_COUNT = 800,\n    HOT_SPAN = 16;\n  var nativeNow = Date.now;\n  function shortOut(func) {\n    var count = 0,\n      lastCalled = 0;\n    return function () {\n      var stamp = nativeNow(),\n        remaining = HOT_SPAN - (stamp - lastCalled);\n      lastCalled = stamp;\n      if (remaining > 0) {\n        if (++count >= HOT_COUNT) {\n          return arguments[0];\n        }\n      } else {\n        count = 0;\n      }\n      return func.apply(void 0, arguments);\n    };\n  }\n  function constant(value) {\n    return function () {\n      return value;\n    };\n  }\n  var defineProperty = function () {\n    try {\n      var func = getNative(Object, \"defineProperty\");\n      func({}, \"\", {});\n      return func;\n    } catch (e) {}\n  }();\n  const defineProperty$1 = defineProperty;\n  var baseSetToString = !defineProperty$1 ? identity : function (func, string) {\n    return defineProperty$1(func, \"toString\", {\n      configurable: true,\n      enumerable: false,\n      value: constant(string),\n      writable: true\n    });\n  };\n  const baseSetToString$1 = baseSetToString;\n  var setToString = shortOut(baseSetToString$1);\n  const setToString$1 = setToString;\n  function arrayEach(array, iteratee) {\n    var index = -1,\n      length = array == null ? 0 : array.length;\n    while (++index < length) {\n      if (iteratee(array[index], index, array) === false) {\n        break;\n      }\n    }\n    return array;\n  }\n  function baseFindIndex(array, predicate, fromIndex, fromRight) {\n    var length = array.length,\n      index = fromIndex + (fromRight ? 1 : -1);\n    while (fromRight ? index-- : ++index < length) {\n      if (predicate(array[index], index, array)) {\n        return index;\n      }\n    }\n    return -1;\n  }\n  function baseIsNaN(value) {\n    return value !== value;\n  }\n  function strictIndexOf(array, value, fromIndex) {\n    var index = fromIndex - 1,\n      length = array.length;\n    while (++index < length) {\n      if (array[index] === value) {\n        return index;\n      }\n    }\n    return -1;\n  }\n  function baseIndexOf(array, value, fromIndex) {\n    return value === value ? strictIndexOf(array, value, fromIndex) : baseFindIndex(array, baseIsNaN, fromIndex);\n  }\n  function arrayIncludes(array, value) {\n    var length = array == null ? 0 : array.length;\n    return !!length && baseIndexOf(array, value, 0) > -1;\n  }\n  var MAX_SAFE_INTEGER$1 = 9007199254740991;\n  var reIsUint = /^(?:0|[1-9]\\d*)$/;\n  function isIndex(value, length) {\n    var type = typeof value;\n    length = length == null ? MAX_SAFE_INTEGER$1 : length;\n    return !!length && (type == \"number\" || type != \"symbol\" && reIsUint.test(value)) && value > -1 && value % 1 == 0 && value < length;\n  }\n  function baseAssignValue(object, key, value) {\n    if (key == \"__proto__\" && defineProperty$1) {\n      defineProperty$1(object, key, {\n        configurable: true,\n        enumerable: true,\n        value,\n        writable: true\n      });\n    } else {\n      object[key] = value;\n    }\n  }\n  function eq(value, other) {\n    return value === other || value !== value && other !== other;\n  }\n  var objectProto$g = Object.prototype;\n  var hasOwnProperty$e = objectProto$g.hasOwnProperty;\n  function assignValue(object, key, value) {\n    var objValue = object[key];\n    if (!(hasOwnProperty$e.call(object, key) && eq(objValue, value)) || value === void 0 && !(key in object)) {\n      baseAssignValue(object, key, value);\n    }\n  }\n  function copyObject(source, props, object, customizer) {\n    var isNew = !object;\n    object || (object = {});\n    var index = -1,\n      length = props.length;\n    while (++index < length) {\n      var key = props[index];\n      var newValue = customizer ? customizer(object[key], source[key], key, object, source) : void 0;\n      if (newValue === void 0) {\n        newValue = source[key];\n      }\n      if (isNew) {\n        baseAssignValue(object, key, newValue);\n      } else {\n        assignValue(object, key, newValue);\n      }\n    }\n    return object;\n  }\n  var nativeMax$3 = Math.max;\n  function overRest(func, start, transform) {\n    start = nativeMax$3(start === void 0 ? func.length - 1 : start, 0);\n    return function () {\n      var args = arguments,\n        index = -1,\n        length = nativeMax$3(args.length - start, 0),\n        array = Array(length);\n      while (++index < length) {\n        array[index] = args[start + index];\n      }\n      index = -1;\n      var otherArgs = Array(start + 1);\n      while (++index < start) {\n        otherArgs[index] = args[index];\n      }\n      otherArgs[start] = transform(array);\n      return apply(func, this, otherArgs);\n    };\n  }\n  function baseRest(func, start) {\n    return setToString$1(overRest(func, start, identity), func + \"\");\n  }\n  var MAX_SAFE_INTEGER = 9007199254740991;\n  function isLength(value) {\n    return typeof value == \"number\" && value > -1 && value % 1 == 0 && value <= MAX_SAFE_INTEGER;\n  }\n  function isArrayLike(value) {\n    return value != null && isLength(value.length) && !isFunction(value);\n  }\n  function isIterateeCall(value, index, object) {\n    if (!isObject(object)) {\n      return false;\n    }\n    var type = typeof index;\n    if (type == \"number\" ? isArrayLike(object) && isIndex(index, object.length) : type == \"string\" && index in object) {\n      return eq(object[index], value);\n    }\n    return false;\n  }\n  function createAssigner(assigner) {\n    return baseRest(function (object, sources) {\n      var index = -1,\n        length = sources.length,\n        customizer = length > 1 ? sources[length - 1] : void 0,\n        guard = length > 2 ? sources[2] : void 0;\n      customizer = assigner.length > 3 && typeof customizer == \"function\" ? (length--, customizer) : void 0;\n      if (guard && isIterateeCall(sources[0], sources[1], guard)) {\n        customizer = length < 3 ? void 0 : customizer;\n        length = 1;\n      }\n      object = Object(object);\n      while (++index < length) {\n        var source = sources[index];\n        if (source) {\n          assigner(object, source, index, customizer);\n        }\n      }\n      return object;\n    });\n  }\n  var objectProto$f = Object.prototype;\n  function isPrototype(value) {\n    var Ctor = value && value.constructor,\n      proto = typeof Ctor == \"function\" && Ctor.prototype || objectProto$f;\n    return value === proto;\n  }\n  function baseTimes(n, iteratee) {\n    var index = -1,\n      result = Array(n);\n    while (++index < n) {\n      result[index] = iteratee(index);\n    }\n    return result;\n  }\n  var argsTag$3 = \"[object Arguments]\";\n  function baseIsArguments(value) {\n    return isObjectLike(value) && baseGetTag(value) == argsTag$3;\n  }\n  var objectProto$e = Object.prototype;\n  var hasOwnProperty$d = objectProto$e.hasOwnProperty;\n  var propertyIsEnumerable$1 = objectProto$e.propertyIsEnumerable;\n  var isArguments = baseIsArguments(function () {\n    return arguments;\n  }()) ? baseIsArguments : function (value) {\n    return isObjectLike(value) && hasOwnProperty$d.call(value, \"callee\") && !propertyIsEnumerable$1.call(value, \"callee\");\n  };\n  const isArguments$1 = isArguments;\n  function stubFalse() {\n    return false;\n  }\n  var freeExports$2 = typeof exports == \"object\" && exports && !exports.nodeType && exports;\n  var freeModule$2 = freeExports$2 && typeof module == \"object\" && module && !module.nodeType && module;\n  var moduleExports$2 = freeModule$2 && freeModule$2.exports === freeExports$2;\n  var Buffer$1 = moduleExports$2 ? root$1.Buffer : void 0;\n  var nativeIsBuffer = Buffer$1 ? Buffer$1.isBuffer : void 0;\n  var isBuffer = nativeIsBuffer || stubFalse;\n  const isBuffer$1 = isBuffer;\n  var argsTag$2 = \"[object Arguments]\",\n    arrayTag$2 = \"[object Array]\",\n    boolTag$3 = \"[object Boolean]\",\n    dateTag$3 = \"[object Date]\",\n    errorTag$2 = \"[object Error]\",\n    funcTag$1 = \"[object Function]\",\n    mapTag$6 = \"[object Map]\",\n    numberTag$3 = \"[object Number]\",\n    objectTag$3 = \"[object Object]\",\n    regexpTag$4 = \"[object RegExp]\",\n    setTag$6 = \"[object Set]\",\n    stringTag$4 = \"[object String]\",\n    weakMapTag$2 = \"[object WeakMap]\";\n  var arrayBufferTag$3 = \"[object ArrayBuffer]\",\n    dataViewTag$4 = \"[object DataView]\",\n    float32Tag$2 = \"[object Float32Array]\",\n    float64Tag$2 = \"[object Float64Array]\",\n    int8Tag$2 = \"[object Int8Array]\",\n    int16Tag$2 = \"[object Int16Array]\",\n    int32Tag$2 = \"[object Int32Array]\",\n    uint8Tag$2 = \"[object Uint8Array]\",\n    uint8ClampedTag$2 = \"[object Uint8ClampedArray]\",\n    uint16Tag$2 = \"[object Uint16Array]\",\n    uint32Tag$2 = \"[object Uint32Array]\";\n  var typedArrayTags = {};\n  typedArrayTags[float32Tag$2] = typedArrayTags[float64Tag$2] = typedArrayTags[int8Tag$2] = typedArrayTags[int16Tag$2] = typedArrayTags[int32Tag$2] = typedArrayTags[uint8Tag$2] = typedArrayTags[uint8ClampedTag$2] = typedArrayTags[uint16Tag$2] = typedArrayTags[uint32Tag$2] = true;\n  typedArrayTags[argsTag$2] = typedArrayTags[arrayTag$2] = typedArrayTags[arrayBufferTag$3] = typedArrayTags[boolTag$3] = typedArrayTags[dataViewTag$4] = typedArrayTags[dateTag$3] = typedArrayTags[errorTag$2] = typedArrayTags[funcTag$1] = typedArrayTags[mapTag$6] = typedArrayTags[numberTag$3] = typedArrayTags[objectTag$3] = typedArrayTags[regexpTag$4] = typedArrayTags[setTag$6] = typedArrayTags[stringTag$4] = typedArrayTags[weakMapTag$2] = false;\n  function baseIsTypedArray(value) {\n    return isObjectLike(value) && isLength(value.length) && !!typedArrayTags[baseGetTag(value)];\n  }\n  function baseUnary(func) {\n    return function (value) {\n      return func(value);\n    };\n  }\n  var freeExports$1 = typeof exports == \"object\" && exports && !exports.nodeType && exports;\n  var freeModule$1 = freeExports$1 && typeof module == \"object\" && module && !module.nodeType && module;\n  var moduleExports$1 = freeModule$1 && freeModule$1.exports === freeExports$1;\n  var freeProcess = moduleExports$1 && freeGlobal$1.process;\n  var nodeUtil = function () {\n    try {\n      var types = freeModule$1 && freeModule$1.require && freeModule$1.require(\"util\").types;\n      if (types) {\n        return types;\n      }\n      return freeProcess && freeProcess.binding && freeProcess.binding(\"util\");\n    } catch (e) {}\n  }();\n  const nodeUtil$1 = nodeUtil;\n  var nodeIsTypedArray = nodeUtil$1 && nodeUtil$1.isTypedArray;\n  var isTypedArray = nodeIsTypedArray ? baseUnary(nodeIsTypedArray) : baseIsTypedArray;\n  const isTypedArray$1 = isTypedArray;\n  var objectProto$d = Object.prototype;\n  var hasOwnProperty$c = objectProto$d.hasOwnProperty;\n  function arrayLikeKeys(value, inherited) {\n    var isArr = isArray$1(value),\n      isArg = !isArr && isArguments$1(value),\n      isBuff = !isArr && !isArg && isBuffer$1(value),\n      isType = !isArr && !isArg && !isBuff && isTypedArray$1(value),\n      skipIndexes = isArr || isArg || isBuff || isType,\n      result = skipIndexes ? baseTimes(value.length, String) : [],\n      length = result.length;\n    for (var key in value) {\n      if ((inherited || hasOwnProperty$c.call(value, key)) && !(skipIndexes && (\n      // Safari 9 has enumerable `arguments.length` in strict mode.\n      key == \"length\" ||\n      // Node.js 0.10 has enumerable non-index properties on buffers.\n      isBuff && (key == \"offset\" || key == \"parent\") ||\n      // PhantomJS 2 has enumerable non-index properties on typed arrays.\n      isType && (key == \"buffer\" || key == \"byteLength\" || key == \"byteOffset\") ||\n      // Skip index properties.\n      isIndex(key, length)))) {\n        result.push(key);\n      }\n    }\n    return result;\n  }\n  function overArg(func, transform) {\n    return function (arg) {\n      return func(transform(arg));\n    };\n  }\n  var nativeKeys = overArg(Object.keys, Object);\n  const nativeKeys$1 = nativeKeys;\n  var objectProto$c = Object.prototype;\n  var hasOwnProperty$b = objectProto$c.hasOwnProperty;\n  function baseKeys(object) {\n    if (!isPrototype(object)) {\n      return nativeKeys$1(object);\n    }\n    var result = [];\n    for (var key in Object(object)) {\n      if (hasOwnProperty$b.call(object, key) && key != \"constructor\") {\n        result.push(key);\n      }\n    }\n    return result;\n  }\n  function keys(object) {\n    return isArrayLike(object) ? arrayLikeKeys(object) : baseKeys(object);\n  }\n  var objectProto$b = Object.prototype;\n  var hasOwnProperty$a = objectProto$b.hasOwnProperty;\n  var assign = createAssigner(function (object, source) {\n    if (isPrototype(source) || isArrayLike(source)) {\n      copyObject(source, keys(source), object);\n      return;\n    }\n    for (var key in source) {\n      if (hasOwnProperty$a.call(source, key)) {\n        assignValue(object, key, source[key]);\n      }\n    }\n  });\n  const assign$1 = assign;\n  function nativeKeysIn(object) {\n    var result = [];\n    if (object != null) {\n      for (var key in Object(object)) {\n        result.push(key);\n      }\n    }\n    return result;\n  }\n  var objectProto$a = Object.prototype;\n  var hasOwnProperty$9 = objectProto$a.hasOwnProperty;\n  function baseKeysIn(object) {\n    if (!isObject(object)) {\n      return nativeKeysIn(object);\n    }\n    var isProto = isPrototype(object),\n      result = [];\n    for (var key in object) {\n      if (!(key == \"constructor\" && (isProto || !hasOwnProperty$9.call(object, key)))) {\n        result.push(key);\n      }\n    }\n    return result;\n  }\n  function keysIn(object) {\n    return isArrayLike(object) ? arrayLikeKeys(object, true) : baseKeysIn(object);\n  }\n  var reIsDeepProp = /\\.|\\[(?:[^[\\]]*|([\"'])(?:(?!\\1)[^\\\\]|\\\\.)*?\\1)\\]/,\n    reIsPlainProp = /^\\w*$/;\n  function isKey(value, object) {\n    if (isArray$1(value)) {\n      return false;\n    }\n    var type = typeof value;\n    if (type == \"number\" || type == \"symbol\" || type == \"boolean\" || value == null || isSymbol(value)) {\n      return true;\n    }\n    return reIsPlainProp.test(value) || !reIsDeepProp.test(value) || object != null && value in Object(object);\n  }\n  var nativeCreate = getNative(Object, \"create\");\n  const nativeCreate$1 = nativeCreate;\n  function hashClear() {\n    this.__data__ = nativeCreate$1 ? nativeCreate$1(null) : {};\n    this.size = 0;\n  }\n  function hashDelete(key) {\n    var result = this.has(key) && delete this.__data__[key];\n    this.size -= result ? 1 : 0;\n    return result;\n  }\n  var HASH_UNDEFINED$2 = \"__lodash_hash_undefined__\";\n  var objectProto$9 = Object.prototype;\n  var hasOwnProperty$8 = objectProto$9.hasOwnProperty;\n  function hashGet(key) {\n    var data = this.__data__;\n    if (nativeCreate$1) {\n      var result = data[key];\n      return result === HASH_UNDEFINED$2 ? void 0 : result;\n    }\n    return hasOwnProperty$8.call(data, key) ? data[key] : void 0;\n  }\n  var objectProto$8 = Object.prototype;\n  var hasOwnProperty$7 = objectProto$8.hasOwnProperty;\n  function hashHas(key) {\n    var data = this.__data__;\n    return nativeCreate$1 ? data[key] !== void 0 : hasOwnProperty$7.call(data, key);\n  }\n  var HASH_UNDEFINED$1 = \"__lodash_hash_undefined__\";\n  function hashSet(key, value) {\n    var data = this.__data__;\n    this.size += this.has(key) ? 0 : 1;\n    data[key] = nativeCreate$1 && value === void 0 ? HASH_UNDEFINED$1 : value;\n    return this;\n  }\n  function Hash(entries) {\n    var index = -1,\n      length = entries == null ? 0 : entries.length;\n    this.clear();\n    while (++index < length) {\n      var entry = entries[index];\n      this.set(entry[0], entry[1]);\n    }\n  }\n  Hash.prototype.clear = hashClear;\n  Hash.prototype[\"delete\"] = hashDelete;\n  Hash.prototype.get = hashGet;\n  Hash.prototype.has = hashHas;\n  Hash.prototype.set = hashSet;\n  function listCacheClear() {\n    this.__data__ = [];\n    this.size = 0;\n  }\n  function assocIndexOf(array, key) {\n    var length = array.length;\n    while (length--) {\n      if (eq(array[length][0], key)) {\n        return length;\n      }\n    }\n    return -1;\n  }\n  var arrayProto = Array.prototype;\n  var splice = arrayProto.splice;\n  function listCacheDelete(key) {\n    var data = this.__data__,\n      index = assocIndexOf(data, key);\n    if (index < 0) {\n      return false;\n    }\n    var lastIndex = data.length - 1;\n    if (index == lastIndex) {\n      data.pop();\n    } else {\n      splice.call(data, index, 1);\n    }\n    --this.size;\n    return true;\n  }\n  function listCacheGet(key) {\n    var data = this.__data__,\n      index = assocIndexOf(data, key);\n    return index < 0 ? void 0 : data[index][1];\n  }\n  function listCacheHas(key) {\n    return assocIndexOf(this.__data__, key) > -1;\n  }\n  function listCacheSet(key, value) {\n    var data = this.__data__,\n      index = assocIndexOf(data, key);\n    if (index < 0) {\n      ++this.size;\n      data.push([key, value]);\n    } else {\n      data[index][1] = value;\n    }\n    return this;\n  }\n  function ListCache(entries) {\n    var index = -1,\n      length = entries == null ? 0 : entries.length;\n    this.clear();\n    while (++index < length) {\n      var entry = entries[index];\n      this.set(entry[0], entry[1]);\n    }\n  }\n  ListCache.prototype.clear = listCacheClear;\n  ListCache.prototype[\"delete\"] = listCacheDelete;\n  ListCache.prototype.get = listCacheGet;\n  ListCache.prototype.has = listCacheHas;\n  ListCache.prototype.set = listCacheSet;\n  var Map$1 = getNative(root$1, \"Map\");\n  const Map$2 = Map$1;\n  function mapCacheClear() {\n    this.size = 0;\n    this.__data__ = {\n      hash: new Hash(),\n      map: new (Map$2 || ListCache)(),\n      string: new Hash()\n    };\n  }\n  function isKeyable(value) {\n    var type = typeof value;\n    return type == \"string\" || type == \"number\" || type == \"symbol\" || type == \"boolean\" ? value !== \"__proto__\" : value === null;\n  }\n  function getMapData(map2, key) {\n    var data = map2.__data__;\n    return isKeyable(key) ? data[typeof key == \"string\" ? \"string\" : \"hash\"] : data.map;\n  }\n  function mapCacheDelete(key) {\n    var result = getMapData(this, key)[\"delete\"](key);\n    this.size -= result ? 1 : 0;\n    return result;\n  }\n  function mapCacheGet(key) {\n    return getMapData(this, key).get(key);\n  }\n  function mapCacheHas(key) {\n    return getMapData(this, key).has(key);\n  }\n  function mapCacheSet(key, value) {\n    var data = getMapData(this, key),\n      size = data.size;\n    data.set(key, value);\n    this.size += data.size == size ? 0 : 1;\n    return this;\n  }\n  function MapCache(entries) {\n    var index = -1,\n      length = entries == null ? 0 : entries.length;\n    this.clear();\n    while (++index < length) {\n      var entry = entries[index];\n      this.set(entry[0], entry[1]);\n    }\n  }\n  MapCache.prototype.clear = mapCacheClear;\n  MapCache.prototype[\"delete\"] = mapCacheDelete;\n  MapCache.prototype.get = mapCacheGet;\n  MapCache.prototype.has = mapCacheHas;\n  MapCache.prototype.set = mapCacheSet;\n  var FUNC_ERROR_TEXT$1 = \"Expected a function\";\n  function memoize(func, resolver) {\n    if (typeof func != \"function\" || resolver != null && typeof resolver != \"function\") {\n      throw new TypeError(FUNC_ERROR_TEXT$1);\n    }\n    var memoized = function () {\n      var args = arguments,\n        key = resolver ? resolver.apply(this, args) : args[0],\n        cache = memoized.cache;\n      if (cache.has(key)) {\n        return cache.get(key);\n      }\n      var result = func.apply(this, args);\n      memoized.cache = cache.set(key, result) || cache;\n      return result;\n    };\n    memoized.cache = new (memoize.Cache || MapCache)();\n    return memoized;\n  }\n  memoize.Cache = MapCache;\n  var MAX_MEMOIZE_SIZE = 500;\n  function memoizeCapped(func) {\n    var result = memoize(func, function (key) {\n      if (cache.size === MAX_MEMOIZE_SIZE) {\n        cache.clear();\n      }\n      return key;\n    });\n    var cache = result.cache;\n    return result;\n  }\n  var rePropName = /[^.[\\]]+|\\[(?:(-?\\d+(?:\\.\\d+)?)|([\"'])((?:(?!\\2)[^\\\\]|\\\\.)*?)\\2)\\]|(?=(?:\\.|\\[\\])(?:\\.|\\[\\]|$))/g;\n  var reEscapeChar = /\\\\(\\\\)?/g;\n  var stringToPath = memoizeCapped(function (string) {\n    var result = [];\n    if (string.charCodeAt(0) === 46) {\n      result.push(\"\");\n    }\n    string.replace(rePropName, function (match, number, quote, subString) {\n      result.push(quote ? subString.replace(reEscapeChar, \"$1\") : number || match);\n    });\n    return result;\n  });\n  const stringToPath$1 = stringToPath;\n  function toString(value) {\n    return value == null ? \"\" : baseToString(value);\n  }\n  function castPath(value, object) {\n    if (isArray$1(value)) {\n      return value;\n    }\n    return isKey(value, object) ? [value] : stringToPath$1(toString(value));\n  }\n  var INFINITY$1 = 1 / 0;\n  function toKey(value) {\n    if (typeof value == \"string\" || isSymbol(value)) {\n      return value;\n    }\n    var result = value + \"\";\n    return result == \"0\" && 1 / value == -INFINITY$1 ? \"-0\" : result;\n  }\n  function baseGet(object, path) {\n    path = castPath(path, object);\n    var index = 0,\n      length = path.length;\n    while (object != null && index < length) {\n      object = object[toKey(path[index++])];\n    }\n    return index && index == length ? object : void 0;\n  }\n  function get(object, path, defaultValue) {\n    var result = object == null ? void 0 : baseGet(object, path);\n    return result === void 0 ? defaultValue : result;\n  }\n  function arrayPush(array, values2) {\n    var index = -1,\n      length = values2.length,\n      offset = array.length;\n    while (++index < length) {\n      array[offset + index] = values2[index];\n    }\n    return array;\n  }\n  var spreadableSymbol = Symbol$2 ? Symbol$2.isConcatSpreadable : void 0;\n  function isFlattenable(value) {\n    return isArray$1(value) || isArguments$1(value) || !!(spreadableSymbol && value && value[spreadableSymbol]);\n  }\n  function baseFlatten(array, depth, predicate, isStrict, result) {\n    var index = -1,\n      length = array.length;\n    predicate || (predicate = isFlattenable);\n    result || (result = []);\n    while (++index < length) {\n      var value = array[index];\n      if (depth > 0 && predicate(value)) {\n        if (depth > 1) {\n          baseFlatten(value, depth - 1, predicate, isStrict, result);\n        } else {\n          arrayPush(result, value);\n        }\n      } else if (!isStrict) {\n        result[result.length] = value;\n      }\n    }\n    return result;\n  }\n  function flatten(array) {\n    var length = array == null ? 0 : array.length;\n    return length ? baseFlatten(array, 1) : [];\n  }\n  var getPrototype = overArg(Object.getPrototypeOf, Object);\n  const getPrototype$1 = getPrototype;\n  function baseSlice(array, start, end) {\n    var index = -1,\n      length = array.length;\n    if (start < 0) {\n      start = -start > length ? 0 : length + start;\n    }\n    end = end > length ? length : end;\n    if (end < 0) {\n      end += length;\n    }\n    length = start > end ? 0 : end - start >>> 0;\n    start >>>= 0;\n    var result = Array(length);\n    while (++index < length) {\n      result[index] = array[index + start];\n    }\n    return result;\n  }\n  function arrayReduce(array, iteratee, accumulator, initAccum) {\n    var index = -1,\n      length = array == null ? 0 : array.length;\n    if (initAccum && length) {\n      accumulator = array[++index];\n    }\n    while (++index < length) {\n      accumulator = iteratee(accumulator, array[index], index, array);\n    }\n    return accumulator;\n  }\n  function stackClear() {\n    this.__data__ = new ListCache();\n    this.size = 0;\n  }\n  function stackDelete(key) {\n    var data = this.__data__,\n      result = data[\"delete\"](key);\n    this.size = data.size;\n    return result;\n  }\n  function stackGet(key) {\n    return this.__data__.get(key);\n  }\n  function stackHas(key) {\n    return this.__data__.has(key);\n  }\n  var LARGE_ARRAY_SIZE$2 = 200;\n  function stackSet(key, value) {\n    var data = this.__data__;\n    if (data instanceof ListCache) {\n      var pairs = data.__data__;\n      if (!Map$2 || pairs.length < LARGE_ARRAY_SIZE$2 - 1) {\n        pairs.push([key, value]);\n        this.size = ++data.size;\n        return this;\n      }\n      data = this.__data__ = new MapCache(pairs);\n    }\n    data.set(key, value);\n    this.size = data.size;\n    return this;\n  }\n  function Stack(entries) {\n    var data = this.__data__ = new ListCache(entries);\n    this.size = data.size;\n  }\n  Stack.prototype.clear = stackClear;\n  Stack.prototype[\"delete\"] = stackDelete;\n  Stack.prototype.get = stackGet;\n  Stack.prototype.has = stackHas;\n  Stack.prototype.set = stackSet;\n  function baseAssign(object, source) {\n    return object && copyObject(source, keys(source), object);\n  }\n  function baseAssignIn(object, source) {\n    return object && copyObject(source, keysIn(source), object);\n  }\n  var freeExports = typeof exports == \"object\" && exports && !exports.nodeType && exports;\n  var freeModule = freeExports && typeof module == \"object\" && module && !module.nodeType && module;\n  var moduleExports = freeModule && freeModule.exports === freeExports;\n  var Buffer = moduleExports ? root$1.Buffer : void 0,\n    allocUnsafe = Buffer ? Buffer.allocUnsafe : void 0;\n  function cloneBuffer(buffer, isDeep) {\n    if (isDeep) {\n      return buffer.slice();\n    }\n    var length = buffer.length,\n      result = allocUnsafe ? allocUnsafe(length) : new buffer.constructor(length);\n    buffer.copy(result);\n    return result;\n  }\n  function arrayFilter(array, predicate) {\n    var index = -1,\n      length = array == null ? 0 : array.length,\n      resIndex = 0,\n      result = [];\n    while (++index < length) {\n      var value = array[index];\n      if (predicate(value, index, array)) {\n        result[resIndex++] = value;\n      }\n    }\n    return result;\n  }\n  function stubArray() {\n    return [];\n  }\n  var objectProto$7 = Object.prototype;\n  var propertyIsEnumerable = objectProto$7.propertyIsEnumerable;\n  var nativeGetSymbols$1 = Object.getOwnPropertySymbols;\n  var getSymbols = !nativeGetSymbols$1 ? stubArray : function (object) {\n    if (object == null) {\n      return [];\n    }\n    object = Object(object);\n    return arrayFilter(nativeGetSymbols$1(object), function (symbol) {\n      return propertyIsEnumerable.call(object, symbol);\n    });\n  };\n  const getSymbols$1 = getSymbols;\n  function copySymbols(source, object) {\n    return copyObject(source, getSymbols$1(source), object);\n  }\n  var nativeGetSymbols = Object.getOwnPropertySymbols;\n  var getSymbolsIn = !nativeGetSymbols ? stubArray : function (object) {\n    var result = [];\n    while (object) {\n      arrayPush(result, getSymbols$1(object));\n      object = getPrototype$1(object);\n    }\n    return result;\n  };\n  const getSymbolsIn$1 = getSymbolsIn;\n  function copySymbolsIn(source, object) {\n    return copyObject(source, getSymbolsIn$1(source), object);\n  }\n  function baseGetAllKeys(object, keysFunc, symbolsFunc) {\n    var result = keysFunc(object);\n    return isArray$1(object) ? result : arrayPush(result, symbolsFunc(object));\n  }\n  function getAllKeys(object) {\n    return baseGetAllKeys(object, keys, getSymbols$1);\n  }\n  function getAllKeysIn(object) {\n    return baseGetAllKeys(object, keysIn, getSymbolsIn$1);\n  }\n  var DataView = getNative(root$1, \"DataView\");\n  const DataView$1 = DataView;\n  var Promise$1 = getNative(root$1, \"Promise\");\n  const Promise$2 = Promise$1;\n  var Set = getNative(root$1, \"Set\");\n  const Set$1 = Set;\n  var mapTag$5 = \"[object Map]\",\n    objectTag$2 = \"[object Object]\",\n    promiseTag = \"[object Promise]\",\n    setTag$5 = \"[object Set]\",\n    weakMapTag$1 = \"[object WeakMap]\";\n  var dataViewTag$3 = \"[object DataView]\";\n  var dataViewCtorString = toSource(DataView$1),\n    mapCtorString = toSource(Map$2),\n    promiseCtorString = toSource(Promise$2),\n    setCtorString = toSource(Set$1),\n    weakMapCtorString = toSource(WeakMap$1);\n  var getTag = baseGetTag;\n  if (DataView$1 && getTag(new DataView$1(new ArrayBuffer(1))) != dataViewTag$3 || Map$2 && getTag(new Map$2()) != mapTag$5 || Promise$2 && getTag(Promise$2.resolve()) != promiseTag || Set$1 && getTag(new Set$1()) != setTag$5 || WeakMap$1 && getTag(new WeakMap$1()) != weakMapTag$1) {\n    getTag = function (value) {\n      var result = baseGetTag(value),\n        Ctor = result == objectTag$2 ? value.constructor : void 0,\n        ctorString = Ctor ? toSource(Ctor) : \"\";\n      if (ctorString) {\n        switch (ctorString) {\n          case dataViewCtorString:\n            return dataViewTag$3;\n          case mapCtorString:\n            return mapTag$5;\n          case promiseCtorString:\n            return promiseTag;\n          case setCtorString:\n            return setTag$5;\n          case weakMapCtorString:\n            return weakMapTag$1;\n        }\n      }\n      return result;\n    };\n  }\n  const getTag$1 = getTag;\n  var objectProto$6 = Object.prototype;\n  var hasOwnProperty$6 = objectProto$6.hasOwnProperty;\n  function initCloneArray(array) {\n    var length = array.length,\n      result = new array.constructor(length);\n    if (length && typeof array[0] == \"string\" && hasOwnProperty$6.call(array, \"index\")) {\n      result.index = array.index;\n      result.input = array.input;\n    }\n    return result;\n  }\n  var Uint8Array = root$1.Uint8Array;\n  const Uint8Array$1 = Uint8Array;\n  function cloneArrayBuffer(arrayBuffer) {\n    var result = new arrayBuffer.constructor(arrayBuffer.byteLength);\n    new Uint8Array$1(result).set(new Uint8Array$1(arrayBuffer));\n    return result;\n  }\n  function cloneDataView(dataView, isDeep) {\n    var buffer = isDeep ? cloneArrayBuffer(dataView.buffer) : dataView.buffer;\n    return new dataView.constructor(buffer, dataView.byteOffset, dataView.byteLength);\n  }\n  var reFlags = /\\w*$/;\n  function cloneRegExp(regexp) {\n    var result = new regexp.constructor(regexp.source, reFlags.exec(regexp));\n    result.lastIndex = regexp.lastIndex;\n    return result;\n  }\n  var symbolProto$1 = Symbol$2 ? Symbol$2.prototype : void 0,\n    symbolValueOf$1 = symbolProto$1 ? symbolProto$1.valueOf : void 0;\n  function cloneSymbol(symbol) {\n    return symbolValueOf$1 ? Object(symbolValueOf$1.call(symbol)) : {};\n  }\n  function cloneTypedArray(typedArray, isDeep) {\n    var buffer = isDeep ? cloneArrayBuffer(typedArray.buffer) : typedArray.buffer;\n    return new typedArray.constructor(buffer, typedArray.byteOffset, typedArray.length);\n  }\n  var boolTag$2 = \"[object Boolean]\",\n    dateTag$2 = \"[object Date]\",\n    mapTag$4 = \"[object Map]\",\n    numberTag$2 = \"[object Number]\",\n    regexpTag$3 = \"[object RegExp]\",\n    setTag$4 = \"[object Set]\",\n    stringTag$3 = \"[object String]\",\n    symbolTag$2 = \"[object Symbol]\";\n  var arrayBufferTag$2 = \"[object ArrayBuffer]\",\n    dataViewTag$2 = \"[object DataView]\",\n    float32Tag$1 = \"[object Float32Array]\",\n    float64Tag$1 = \"[object Float64Array]\",\n    int8Tag$1 = \"[object Int8Array]\",\n    int16Tag$1 = \"[object Int16Array]\",\n    int32Tag$1 = \"[object Int32Array]\",\n    uint8Tag$1 = \"[object Uint8Array]\",\n    uint8ClampedTag$1 = \"[object Uint8ClampedArray]\",\n    uint16Tag$1 = \"[object Uint16Array]\",\n    uint32Tag$1 = \"[object Uint32Array]\";\n  function initCloneByTag(object, tag, isDeep) {\n    var Ctor = object.constructor;\n    switch (tag) {\n      case arrayBufferTag$2:\n        return cloneArrayBuffer(object);\n      case boolTag$2:\n      case dateTag$2:\n        return new Ctor(+object);\n      case dataViewTag$2:\n        return cloneDataView(object, isDeep);\n      case float32Tag$1:\n      case float64Tag$1:\n      case int8Tag$1:\n      case int16Tag$1:\n      case int32Tag$1:\n      case uint8Tag$1:\n      case uint8ClampedTag$1:\n      case uint16Tag$1:\n      case uint32Tag$1:\n        return cloneTypedArray(object, isDeep);\n      case mapTag$4:\n        return new Ctor();\n      case numberTag$2:\n      case stringTag$3:\n        return new Ctor(object);\n      case regexpTag$3:\n        return cloneRegExp(object);\n      case setTag$4:\n        return new Ctor();\n      case symbolTag$2:\n        return cloneSymbol(object);\n    }\n  }\n  function initCloneObject(object) {\n    return typeof object.constructor == \"function\" && !isPrototype(object) ? baseCreate$1(getPrototype$1(object)) : {};\n  }\n  var mapTag$3 = \"[object Map]\";\n  function baseIsMap(value) {\n    return isObjectLike(value) && getTag$1(value) == mapTag$3;\n  }\n  var nodeIsMap = nodeUtil$1 && nodeUtil$1.isMap;\n  var isMap = nodeIsMap ? baseUnary(nodeIsMap) : baseIsMap;\n  const isMap$1 = isMap;\n  var setTag$3 = \"[object Set]\";\n  function baseIsSet(value) {\n    return isObjectLike(value) && getTag$1(value) == setTag$3;\n  }\n  var nodeIsSet = nodeUtil$1 && nodeUtil$1.isSet;\n  var isSet = nodeIsSet ? baseUnary(nodeIsSet) : baseIsSet;\n  const isSet$1 = isSet;\n  var CLONE_DEEP_FLAG = 1,\n    CLONE_FLAT_FLAG = 2,\n    CLONE_SYMBOLS_FLAG$1 = 4;\n  var argsTag$1 = \"[object Arguments]\",\n    arrayTag$1 = \"[object Array]\",\n    boolTag$1 = \"[object Boolean]\",\n    dateTag$1 = \"[object Date]\",\n    errorTag$1 = \"[object Error]\",\n    funcTag = \"[object Function]\",\n    genTag = \"[object GeneratorFunction]\",\n    mapTag$2 = \"[object Map]\",\n    numberTag$1 = \"[object Number]\",\n    objectTag$1 = \"[object Object]\",\n    regexpTag$2 = \"[object RegExp]\",\n    setTag$2 = \"[object Set]\",\n    stringTag$2 = \"[object String]\",\n    symbolTag$1 = \"[object Symbol]\",\n    weakMapTag = \"[object WeakMap]\";\n  var arrayBufferTag$1 = \"[object ArrayBuffer]\",\n    dataViewTag$1 = \"[object DataView]\",\n    float32Tag = \"[object Float32Array]\",\n    float64Tag = \"[object Float64Array]\",\n    int8Tag = \"[object Int8Array]\",\n    int16Tag = \"[object Int16Array]\",\n    int32Tag = \"[object Int32Array]\",\n    uint8Tag = \"[object Uint8Array]\",\n    uint8ClampedTag = \"[object Uint8ClampedArray]\",\n    uint16Tag = \"[object Uint16Array]\",\n    uint32Tag = \"[object Uint32Array]\";\n  var cloneableTags = {};\n  cloneableTags[argsTag$1] = cloneableTags[arrayTag$1] = cloneableTags[arrayBufferTag$1] = cloneableTags[dataViewTag$1] = cloneableTags[boolTag$1] = cloneableTags[dateTag$1] = cloneableTags[float32Tag] = cloneableTags[float64Tag] = cloneableTags[int8Tag] = cloneableTags[int16Tag] = cloneableTags[int32Tag] = cloneableTags[mapTag$2] = cloneableTags[numberTag$1] = cloneableTags[objectTag$1] = cloneableTags[regexpTag$2] = cloneableTags[setTag$2] = cloneableTags[stringTag$2] = cloneableTags[symbolTag$1] = cloneableTags[uint8Tag] = cloneableTags[uint8ClampedTag] = cloneableTags[uint16Tag] = cloneableTags[uint32Tag] = true;\n  cloneableTags[errorTag$1] = cloneableTags[funcTag] = cloneableTags[weakMapTag] = false;\n  function baseClone(value, bitmask, customizer, key, object, stack) {\n    var result,\n      isDeep = bitmask & CLONE_DEEP_FLAG,\n      isFlat = bitmask & CLONE_FLAT_FLAG,\n      isFull = bitmask & CLONE_SYMBOLS_FLAG$1;\n    if (customizer) {\n      result = object ? customizer(value, key, object, stack) : customizer(value);\n    }\n    if (result !== void 0) {\n      return result;\n    }\n    if (!isObject(value)) {\n      return value;\n    }\n    var isArr = isArray$1(value);\n    if (isArr) {\n      result = initCloneArray(value);\n      if (!isDeep) {\n        return copyArray(value, result);\n      }\n    } else {\n      var tag = getTag$1(value),\n        isFunc = tag == funcTag || tag == genTag;\n      if (isBuffer$1(value)) {\n        return cloneBuffer(value, isDeep);\n      }\n      if (tag == objectTag$1 || tag == argsTag$1 || isFunc && !object) {\n        result = isFlat || isFunc ? {} : initCloneObject(value);\n        if (!isDeep) {\n          return isFlat ? copySymbolsIn(value, baseAssignIn(result, value)) : copySymbols(value, baseAssign(result, value));\n        }\n      } else {\n        if (!cloneableTags[tag]) {\n          return object ? value : {};\n        }\n        result = initCloneByTag(value, tag, isDeep);\n      }\n    }\n    stack || (stack = new Stack());\n    var stacked = stack.get(value);\n    if (stacked) {\n      return stacked;\n    }\n    stack.set(value, result);\n    if (isSet$1(value)) {\n      value.forEach(function (subValue) {\n        result.add(baseClone(subValue, bitmask, customizer, subValue, value, stack));\n      });\n    } else if (isMap$1(value)) {\n      value.forEach(function (subValue, key2) {\n        result.set(key2, baseClone(subValue, bitmask, customizer, key2, value, stack));\n      });\n    }\n    var keysFunc = isFull ? isFlat ? getAllKeysIn : getAllKeys : isFlat ? keysIn : keys;\n    var props = isArr ? void 0 : keysFunc(value);\n    arrayEach(props || value, function (subValue, key2) {\n      if (props) {\n        key2 = subValue;\n        subValue = value[key2];\n      }\n      assignValue(result, key2, baseClone(subValue, bitmask, customizer, key2, value, stack));\n    });\n    return result;\n  }\n  var CLONE_SYMBOLS_FLAG = 4;\n  function clone(value) {\n    return baseClone(value, CLONE_SYMBOLS_FLAG);\n  }\n  function compact(array) {\n    var index = -1,\n      length = array == null ? 0 : array.length,\n      resIndex = 0,\n      result = [];\n    while (++index < length) {\n      var value = array[index];\n      if (value) {\n        result[resIndex++] = value;\n      }\n    }\n    return result;\n  }\n  var HASH_UNDEFINED = \"__lodash_hash_undefined__\";\n  function setCacheAdd(value) {\n    this.__data__.set(value, HASH_UNDEFINED);\n    return this;\n  }\n  function setCacheHas(value) {\n    return this.__data__.has(value);\n  }\n  function SetCache(values2) {\n    var index = -1,\n      length = values2 == null ? 0 : values2.length;\n    this.__data__ = new MapCache();\n    while (++index < length) {\n      this.add(values2[index]);\n    }\n  }\n  SetCache.prototype.add = SetCache.prototype.push = setCacheAdd;\n  SetCache.prototype.has = setCacheHas;\n  function arraySome(array, predicate) {\n    var index = -1,\n      length = array == null ? 0 : array.length;\n    while (++index < length) {\n      if (predicate(array[index], index, array)) {\n        return true;\n      }\n    }\n    return false;\n  }\n  function cacheHas(cache, key) {\n    return cache.has(key);\n  }\n  var COMPARE_PARTIAL_FLAG$5 = 1,\n    COMPARE_UNORDERED_FLAG$3 = 2;\n  function equalArrays(array, other, bitmask, customizer, equalFunc, stack) {\n    var isPartial = bitmask & COMPARE_PARTIAL_FLAG$5,\n      arrLength = array.length,\n      othLength = other.length;\n    if (arrLength != othLength && !(isPartial && othLength > arrLength)) {\n      return false;\n    }\n    var arrStacked = stack.get(array);\n    var othStacked = stack.get(other);\n    if (arrStacked && othStacked) {\n      return arrStacked == other && othStacked == array;\n    }\n    var index = -1,\n      result = true,\n      seen = bitmask & COMPARE_UNORDERED_FLAG$3 ? new SetCache() : void 0;\n    stack.set(array, other);\n    stack.set(other, array);\n    while (++index < arrLength) {\n      var arrValue = array[index],\n        othValue = other[index];\n      if (customizer) {\n        var compared = isPartial ? customizer(othValue, arrValue, index, other, array, stack) : customizer(arrValue, othValue, index, array, other, stack);\n      }\n      if (compared !== void 0) {\n        if (compared) {\n          continue;\n        }\n        result = false;\n        break;\n      }\n      if (seen) {\n        if (!arraySome(other, function (othValue2, othIndex) {\n          if (!cacheHas(seen, othIndex) && (arrValue === othValue2 || equalFunc(arrValue, othValue2, bitmask, customizer, stack))) {\n            return seen.push(othIndex);\n          }\n        })) {\n          result = false;\n          break;\n        }\n      } else if (!(arrValue === othValue || equalFunc(arrValue, othValue, bitmask, customizer, stack))) {\n        result = false;\n        break;\n      }\n    }\n    stack[\"delete\"](array);\n    stack[\"delete\"](other);\n    return result;\n  }\n  function mapToArray(map2) {\n    var index = -1,\n      result = Array(map2.size);\n    map2.forEach(function (value, key) {\n      result[++index] = [key, value];\n    });\n    return result;\n  }\n  function setToArray(set) {\n    var index = -1,\n      result = Array(set.size);\n    set.forEach(function (value) {\n      result[++index] = value;\n    });\n    return result;\n  }\n  var COMPARE_PARTIAL_FLAG$4 = 1,\n    COMPARE_UNORDERED_FLAG$2 = 2;\n  var boolTag = \"[object Boolean]\",\n    dateTag = \"[object Date]\",\n    errorTag = \"[object Error]\",\n    mapTag$1 = \"[object Map]\",\n    numberTag = \"[object Number]\",\n    regexpTag$1 = \"[object RegExp]\",\n    setTag$1 = \"[object Set]\",\n    stringTag$1 = \"[object String]\",\n    symbolTag = \"[object Symbol]\";\n  var arrayBufferTag = \"[object ArrayBuffer]\",\n    dataViewTag = \"[object DataView]\";\n  var symbolProto = Symbol$2 ? Symbol$2.prototype : void 0,\n    symbolValueOf = symbolProto ? symbolProto.valueOf : void 0;\n  function equalByTag(object, other, tag, bitmask, customizer, equalFunc, stack) {\n    switch (tag) {\n      case dataViewTag:\n        if (object.byteLength != other.byteLength || object.byteOffset != other.byteOffset) {\n          return false;\n        }\n        object = object.buffer;\n        other = other.buffer;\n      case arrayBufferTag:\n        if (object.byteLength != other.byteLength || !equalFunc(new Uint8Array$1(object), new Uint8Array$1(other))) {\n          return false;\n        }\n        return true;\n      case boolTag:\n      case dateTag:\n      case numberTag:\n        return eq(+object, +other);\n      case errorTag:\n        return object.name == other.name && object.message == other.message;\n      case regexpTag$1:\n      case stringTag$1:\n        return object == other + \"\";\n      case mapTag$1:\n        var convert = mapToArray;\n      case setTag$1:\n        var isPartial = bitmask & COMPARE_PARTIAL_FLAG$4;\n        convert || (convert = setToArray);\n        if (object.size != other.size && !isPartial) {\n          return false;\n        }\n        var stacked = stack.get(object);\n        if (stacked) {\n          return stacked == other;\n        }\n        bitmask |= COMPARE_UNORDERED_FLAG$2;\n        stack.set(object, other);\n        var result = equalArrays(convert(object), convert(other), bitmask, customizer, equalFunc, stack);\n        stack[\"delete\"](object);\n        return result;\n      case symbolTag:\n        if (symbolValueOf) {\n          return symbolValueOf.call(object) == symbolValueOf.call(other);\n        }\n    }\n    return false;\n  }\n  var COMPARE_PARTIAL_FLAG$3 = 1;\n  var objectProto$5 = Object.prototype;\n  var hasOwnProperty$5 = objectProto$5.hasOwnProperty;\n  function equalObjects(object, other, bitmask, customizer, equalFunc, stack) {\n    var isPartial = bitmask & COMPARE_PARTIAL_FLAG$3,\n      objProps = getAllKeys(object),\n      objLength = objProps.length,\n      othProps = getAllKeys(other),\n      othLength = othProps.length;\n    if (objLength != othLength && !isPartial) {\n      return false;\n    }\n    var index = objLength;\n    while (index--) {\n      var key = objProps[index];\n      if (!(isPartial ? key in other : hasOwnProperty$5.call(other, key))) {\n        return false;\n      }\n    }\n    var objStacked = stack.get(object);\n    var othStacked = stack.get(other);\n    if (objStacked && othStacked) {\n      return objStacked == other && othStacked == object;\n    }\n    var result = true;\n    stack.set(object, other);\n    stack.set(other, object);\n    var skipCtor = isPartial;\n    while (++index < objLength) {\n      key = objProps[index];\n      var objValue = object[key],\n        othValue = other[key];\n      if (customizer) {\n        var compared = isPartial ? customizer(othValue, objValue, key, other, object, stack) : customizer(objValue, othValue, key, object, other, stack);\n      }\n      if (!(compared === void 0 ? objValue === othValue || equalFunc(objValue, othValue, bitmask, customizer, stack) : compared)) {\n        result = false;\n        break;\n      }\n      skipCtor || (skipCtor = key == \"constructor\");\n    }\n    if (result && !skipCtor) {\n      var objCtor = object.constructor,\n        othCtor = other.constructor;\n      if (objCtor != othCtor && \"constructor\" in object && \"constructor\" in other && !(typeof objCtor == \"function\" && objCtor instanceof objCtor && typeof othCtor == \"function\" && othCtor instanceof othCtor)) {\n        result = false;\n      }\n    }\n    stack[\"delete\"](object);\n    stack[\"delete\"](other);\n    return result;\n  }\n  var COMPARE_PARTIAL_FLAG$2 = 1;\n  var argsTag = \"[object Arguments]\",\n    arrayTag = \"[object Array]\",\n    objectTag = \"[object Object]\";\n  var objectProto$4 = Object.prototype;\n  var hasOwnProperty$4 = objectProto$4.hasOwnProperty;\n  function baseIsEqualDeep(object, other, bitmask, customizer, equalFunc, stack) {\n    var objIsArr = isArray$1(object),\n      othIsArr = isArray$1(other),\n      objTag = objIsArr ? arrayTag : getTag$1(object),\n      othTag = othIsArr ? arrayTag : getTag$1(other);\n    objTag = objTag == argsTag ? objectTag : objTag;\n    othTag = othTag == argsTag ? objectTag : othTag;\n    var objIsObj = objTag == objectTag,\n      othIsObj = othTag == objectTag,\n      isSameTag = objTag == othTag;\n    if (isSameTag && isBuffer$1(object)) {\n      if (!isBuffer$1(other)) {\n        return false;\n      }\n      objIsArr = true;\n      objIsObj = false;\n    }\n    if (isSameTag && !objIsObj) {\n      stack || (stack = new Stack());\n      return objIsArr || isTypedArray$1(object) ? equalArrays(object, other, bitmask, customizer, equalFunc, stack) : equalByTag(object, other, objTag, bitmask, customizer, equalFunc, stack);\n    }\n    if (!(bitmask & COMPARE_PARTIAL_FLAG$2)) {\n      var objIsWrapped = objIsObj && hasOwnProperty$4.call(object, \"__wrapped__\"),\n        othIsWrapped = othIsObj && hasOwnProperty$4.call(other, \"__wrapped__\");\n      if (objIsWrapped || othIsWrapped) {\n        var objUnwrapped = objIsWrapped ? object.value() : object,\n          othUnwrapped = othIsWrapped ? other.value() : other;\n        stack || (stack = new Stack());\n        return equalFunc(objUnwrapped, othUnwrapped, bitmask, customizer, stack);\n      }\n    }\n    if (!isSameTag) {\n      return false;\n    }\n    stack || (stack = new Stack());\n    return equalObjects(object, other, bitmask, customizer, equalFunc, stack);\n  }\n  function baseIsEqual(value, other, bitmask, customizer, stack) {\n    if (value === other) {\n      return true;\n    }\n    if (value == null || other == null || !isObjectLike(value) && !isObjectLike(other)) {\n      return value !== value && other !== other;\n    }\n    return baseIsEqualDeep(value, other, bitmask, customizer, baseIsEqual, stack);\n  }\n  var COMPARE_PARTIAL_FLAG$1 = 1,\n    COMPARE_UNORDERED_FLAG$1 = 2;\n  function baseIsMatch(object, source, matchData, customizer) {\n    var index = matchData.length,\n      length = index,\n      noCustomizer = !customizer;\n    if (object == null) {\n      return !length;\n    }\n    object = Object(object);\n    while (index--) {\n      var data = matchData[index];\n      if (noCustomizer && data[2] ? data[1] !== object[data[0]] : !(data[0] in object)) {\n        return false;\n      }\n    }\n    while (++index < length) {\n      data = matchData[index];\n      var key = data[0],\n        objValue = object[key],\n        srcValue = data[1];\n      if (noCustomizer && data[2]) {\n        if (objValue === void 0 && !(key in object)) {\n          return false;\n        }\n      } else {\n        var stack = new Stack();\n        if (customizer) {\n          var result = customizer(objValue, srcValue, key, object, source, stack);\n        }\n        if (!(result === void 0 ? baseIsEqual(srcValue, objValue, COMPARE_PARTIAL_FLAG$1 | COMPARE_UNORDERED_FLAG$1, customizer, stack) : result)) {\n          return false;\n        }\n      }\n    }\n    return true;\n  }\n  function isStrictComparable(value) {\n    return value === value && !isObject(value);\n  }\n  function getMatchData(object) {\n    var result = keys(object),\n      length = result.length;\n    while (length--) {\n      var key = result[length],\n        value = object[key];\n      result[length] = [key, value, isStrictComparable(value)];\n    }\n    return result;\n  }\n  function matchesStrictComparable(key, srcValue) {\n    return function (object) {\n      if (object == null) {\n        return false;\n      }\n      return object[key] === srcValue && (srcValue !== void 0 || key in Object(object));\n    };\n  }\n  function baseMatches(source) {\n    var matchData = getMatchData(source);\n    if (matchData.length == 1 && matchData[0][2]) {\n      return matchesStrictComparable(matchData[0][0], matchData[0][1]);\n    }\n    return function (object) {\n      return object === source || baseIsMatch(object, source, matchData);\n    };\n  }\n  function baseHasIn(object, key) {\n    return object != null && key in Object(object);\n  }\n  function hasPath(object, path, hasFunc) {\n    path = castPath(path, object);\n    var index = -1,\n      length = path.length,\n      result = false;\n    while (++index < length) {\n      var key = toKey(path[index]);\n      if (!(result = object != null && hasFunc(object, key))) {\n        break;\n      }\n      object = object[key];\n    }\n    if (result || ++index != length) {\n      return result;\n    }\n    length = object == null ? 0 : object.length;\n    return !!length && isLength(length) && isIndex(key, length) && (isArray$1(object) || isArguments$1(object));\n  }\n  function hasIn(object, path) {\n    return object != null && hasPath(object, path, baseHasIn);\n  }\n  var COMPARE_PARTIAL_FLAG = 1,\n    COMPARE_UNORDERED_FLAG = 2;\n  function baseMatchesProperty(path, srcValue) {\n    if (isKey(path) && isStrictComparable(srcValue)) {\n      return matchesStrictComparable(toKey(path), srcValue);\n    }\n    return function (object) {\n      var objValue = get(object, path);\n      return objValue === void 0 && objValue === srcValue ? hasIn(object, path) : baseIsEqual(srcValue, objValue, COMPARE_PARTIAL_FLAG | COMPARE_UNORDERED_FLAG);\n    };\n  }\n  function baseProperty(key) {\n    return function (object) {\n      return object == null ? void 0 : object[key];\n    };\n  }\n  function basePropertyDeep(path) {\n    return function (object) {\n      return baseGet(object, path);\n    };\n  }\n  function property(path) {\n    return isKey(path) ? baseProperty(toKey(path)) : basePropertyDeep(path);\n  }\n  function baseIteratee(value) {\n    if (typeof value == \"function\") {\n      return value;\n    }\n    if (value == null) {\n      return identity;\n    }\n    if (typeof value == \"object\") {\n      return isArray$1(value) ? baseMatchesProperty(value[0], value[1]) : baseMatches(value);\n    }\n    return property(value);\n  }\n  function arrayAggregator(array, setter, iteratee, accumulator) {\n    var index = -1,\n      length = array == null ? 0 : array.length;\n    while (++index < length) {\n      var value = array[index];\n      setter(accumulator, value, iteratee(value), array);\n    }\n    return accumulator;\n  }\n  function createBaseFor(fromRight) {\n    return function (object, iteratee, keysFunc) {\n      var index = -1,\n        iterable = Object(object),\n        props = keysFunc(object),\n        length = props.length;\n      while (length--) {\n        var key = props[fromRight ? length : ++index];\n        if (iteratee(iterable[key], key, iterable) === false) {\n          break;\n        }\n      }\n      return object;\n    };\n  }\n  var baseFor = createBaseFor();\n  const baseFor$1 = baseFor;\n  function baseForOwn(object, iteratee) {\n    return object && baseFor$1(object, iteratee, keys);\n  }\n  function createBaseEach(eachFunc, fromRight) {\n    return function (collection, iteratee) {\n      if (collection == null) {\n        return collection;\n      }\n      if (!isArrayLike(collection)) {\n        return eachFunc(collection, iteratee);\n      }\n      var length = collection.length,\n        index = fromRight ? length : -1,\n        iterable = Object(collection);\n      while (fromRight ? index-- : ++index < length) {\n        if (iteratee(iterable[index], index, iterable) === false) {\n          break;\n        }\n      }\n      return collection;\n    };\n  }\n  var baseEach = createBaseEach(baseForOwn);\n  const baseEach$1 = baseEach;\n  function baseAggregator(collection, setter, iteratee, accumulator) {\n    baseEach$1(collection, function (value, key, collection2) {\n      setter(accumulator, value, iteratee(value), collection2);\n    });\n    return accumulator;\n  }\n  function createAggregator(setter, initializer) {\n    return function (collection, iteratee) {\n      var func = isArray$1(collection) ? arrayAggregator : baseAggregator,\n        accumulator = initializer ? initializer() : {};\n      return func(collection, setter, baseIteratee(iteratee), accumulator);\n    };\n  }\n  var objectProto$3 = Object.prototype;\n  var hasOwnProperty$3 = objectProto$3.hasOwnProperty;\n  var defaults = baseRest(function (object, sources) {\n    object = Object(object);\n    var index = -1;\n    var length = sources.length;\n    var guard = length > 2 ? sources[2] : void 0;\n    if (guard && isIterateeCall(sources[0], sources[1], guard)) {\n      length = 1;\n    }\n    while (++index < length) {\n      var source = sources[index];\n      var props = keysIn(source);\n      var propsIndex = -1;\n      var propsLength = props.length;\n      while (++propsIndex < propsLength) {\n        var key = props[propsIndex];\n        var value = object[key];\n        if (value === void 0 || eq(value, objectProto$3[key]) && !hasOwnProperty$3.call(object, key)) {\n          object[key] = source[key];\n        }\n      }\n    }\n    return object;\n  });\n  const defaults$1 = defaults;\n  function isArrayLikeObject(value) {\n    return isObjectLike(value) && isArrayLike(value);\n  }\n  function arrayIncludesWith(array, value, comparator) {\n    var index = -1,\n      length = array == null ? 0 : array.length;\n    while (++index < length) {\n      if (comparator(value, array[index])) {\n        return true;\n      }\n    }\n    return false;\n  }\n  var LARGE_ARRAY_SIZE$1 = 200;\n  function baseDifference(array, values2, iteratee, comparator) {\n    var index = -1,\n      includes2 = arrayIncludes,\n      isCommon = true,\n      length = array.length,\n      result = [],\n      valuesLength = values2.length;\n    if (!length) {\n      return result;\n    }\n    if (iteratee) {\n      values2 = arrayMap(values2, baseUnary(iteratee));\n    }\n    if (comparator) {\n      includes2 = arrayIncludesWith;\n      isCommon = false;\n    } else if (values2.length >= LARGE_ARRAY_SIZE$1) {\n      includes2 = cacheHas;\n      isCommon = false;\n      values2 = new SetCache(values2);\n    }\n    outer: while (++index < length) {\n      var value = array[index],\n        computed = iteratee == null ? value : iteratee(value);\n      value = comparator || value !== 0 ? value : 0;\n      if (isCommon && computed === computed) {\n        var valuesIndex = valuesLength;\n        while (valuesIndex--) {\n          if (values2[valuesIndex] === computed) {\n            continue outer;\n          }\n        }\n        result.push(value);\n      } else if (!includes2(values2, computed, comparator)) {\n        result.push(value);\n      }\n    }\n    return result;\n  }\n  var difference = baseRest(function (array, values2) {\n    return isArrayLikeObject(array) ? baseDifference(array, baseFlatten(values2, 1, isArrayLikeObject, true)) : [];\n  });\n  const difference$1 = difference;\n  function last(array) {\n    var length = array == null ? 0 : array.length;\n    return length ? array[length - 1] : void 0;\n  }\n  function drop(array, n, guard) {\n    var length = array == null ? 0 : array.length;\n    if (!length) {\n      return [];\n    }\n    n = guard || n === void 0 ? 1 : toInteger(n);\n    return baseSlice(array, n < 0 ? 0 : n, length);\n  }\n  function dropRight(array, n, guard) {\n    var length = array == null ? 0 : array.length;\n    if (!length) {\n      return [];\n    }\n    n = guard || n === void 0 ? 1 : toInteger(n);\n    n = length - n;\n    return baseSlice(array, 0, n < 0 ? 0 : n);\n  }\n  function castFunction(value) {\n    return typeof value == \"function\" ? value : identity;\n  }\n  function forEach(collection, iteratee) {\n    var func = isArray$1(collection) ? arrayEach : baseEach$1;\n    return func(collection, castFunction(iteratee));\n  }\n  function arrayEvery(array, predicate) {\n    var index = -1,\n      length = array == null ? 0 : array.length;\n    while (++index < length) {\n      if (!predicate(array[index], index, array)) {\n        return false;\n      }\n    }\n    return true;\n  }\n  function baseEvery(collection, predicate) {\n    var result = true;\n    baseEach$1(collection, function (value, index, collection2) {\n      result = !!predicate(value, index, collection2);\n      return result;\n    });\n    return result;\n  }\n  function every(collection, predicate, guard) {\n    var func = isArray$1(collection) ? arrayEvery : baseEvery;\n    if (guard && isIterateeCall(collection, predicate, guard)) {\n      predicate = void 0;\n    }\n    return func(collection, baseIteratee(predicate));\n  }\n  function baseFilter(collection, predicate) {\n    var result = [];\n    baseEach$1(collection, function (value, index, collection2) {\n      if (predicate(value, index, collection2)) {\n        result.push(value);\n      }\n    });\n    return result;\n  }\n  function filter(collection, predicate) {\n    var func = isArray$1(collection) ? arrayFilter : baseFilter;\n    return func(collection, baseIteratee(predicate));\n  }\n  function createFind(findIndexFunc) {\n    return function (collection, predicate, fromIndex) {\n      var iterable = Object(collection);\n      if (!isArrayLike(collection)) {\n        var iteratee = baseIteratee(predicate);\n        collection = keys(collection);\n        predicate = function (key) {\n          return iteratee(iterable[key], key, iterable);\n        };\n      }\n      var index = findIndexFunc(collection, predicate, fromIndex);\n      return index > -1 ? iterable[iteratee ? collection[index] : index] : void 0;\n    };\n  }\n  var nativeMax$2 = Math.max;\n  function findIndex(array, predicate, fromIndex) {\n    var length = array == null ? 0 : array.length;\n    if (!length) {\n      return -1;\n    }\n    var index = fromIndex == null ? 0 : toInteger(fromIndex);\n    if (index < 0) {\n      index = nativeMax$2(length + index, 0);\n    }\n    return baseFindIndex(array, baseIteratee(predicate), index);\n  }\n  var find = createFind(findIndex);\n  const find$1 = find;\n  function head(array) {\n    return array && array.length ? array[0] : void 0;\n  }\n  function baseMap(collection, iteratee) {\n    var index = -1,\n      result = isArrayLike(collection) ? Array(collection.length) : [];\n    baseEach$1(collection, function (value, key, collection2) {\n      result[++index] = iteratee(value, key, collection2);\n    });\n    return result;\n  }\n  function map(collection, iteratee) {\n    var func = isArray$1(collection) ? arrayMap : baseMap;\n    return func(collection, baseIteratee(iteratee));\n  }\n  function flatMap(collection, iteratee) {\n    return baseFlatten(map(collection, iteratee), 1);\n  }\n  var objectProto$2 = Object.prototype;\n  var hasOwnProperty$2 = objectProto$2.hasOwnProperty;\n  var groupBy = createAggregator(function (result, value, key) {\n    if (hasOwnProperty$2.call(result, key)) {\n      result[key].push(value);\n    } else {\n      baseAssignValue(result, key, [value]);\n    }\n  });\n  const groupBy$1 = groupBy;\n  var objectProto$1 = Object.prototype;\n  var hasOwnProperty$1 = objectProto$1.hasOwnProperty;\n  function baseHas(object, key) {\n    return object != null && hasOwnProperty$1.call(object, key);\n  }\n  function has(object, path) {\n    return object != null && hasPath(object, path, baseHas);\n  }\n  var stringTag = \"[object String]\";\n  function isString(value) {\n    return typeof value == \"string\" || !isArray$1(value) && isObjectLike(value) && baseGetTag(value) == stringTag;\n  }\n  function baseValues(object, props) {\n    return arrayMap(props, function (key) {\n      return object[key];\n    });\n  }\n  function values(object) {\n    return object == null ? [] : baseValues(object, keys(object));\n  }\n  var nativeMax$1 = Math.max;\n  function includes(collection, value, fromIndex, guard) {\n    collection = isArrayLike(collection) ? collection : values(collection);\n    fromIndex = fromIndex && !guard ? toInteger(fromIndex) : 0;\n    var length = collection.length;\n    if (fromIndex < 0) {\n      fromIndex = nativeMax$1(length + fromIndex, 0);\n    }\n    return isString(collection) ? fromIndex <= length && collection.indexOf(value, fromIndex) > -1 : !!length && baseIndexOf(collection, value, fromIndex) > -1;\n  }\n  var nativeMax = Math.max;\n  function indexOf(array, value, fromIndex) {\n    var length = array == null ? 0 : array.length;\n    if (!length) {\n      return -1;\n    }\n    var index = fromIndex == null ? 0 : toInteger(fromIndex);\n    if (index < 0) {\n      index = nativeMax(length + index, 0);\n    }\n    return baseIndexOf(array, value, index);\n  }\n  var mapTag = \"[object Map]\",\n    setTag = \"[object Set]\";\n  var objectProto = Object.prototype;\n  var hasOwnProperty = objectProto.hasOwnProperty;\n  function isEmpty(value) {\n    if (value == null) {\n      return true;\n    }\n    if (isArrayLike(value) && (isArray$1(value) || typeof value == \"string\" || typeof value.splice == \"function\" || isBuffer$1(value) || isTypedArray$1(value) || isArguments$1(value))) {\n      return !value.length;\n    }\n    var tag = getTag$1(value);\n    if (tag == mapTag || tag == setTag) {\n      return !value.size;\n    }\n    if (isPrototype(value)) {\n      return !baseKeys(value).length;\n    }\n    for (var key in value) {\n      if (hasOwnProperty.call(value, key)) {\n        return false;\n      }\n    }\n    return true;\n  }\n  var regexpTag = \"[object RegExp]\";\n  function baseIsRegExp(value) {\n    return isObjectLike(value) && baseGetTag(value) == regexpTag;\n  }\n  var nodeIsRegExp = nodeUtil$1 && nodeUtil$1.isRegExp;\n  var isRegExp = nodeIsRegExp ? baseUnary(nodeIsRegExp) : baseIsRegExp;\n  const isRegExp$1 = isRegExp;\n  function isUndefined(value) {\n    return value === void 0;\n  }\n  var FUNC_ERROR_TEXT = \"Expected a function\";\n  function negate(predicate) {\n    if (typeof predicate != \"function\") {\n      throw new TypeError(FUNC_ERROR_TEXT);\n    }\n    return function () {\n      var args = arguments;\n      switch (args.length) {\n        case 0:\n          return !predicate.call(this);\n        case 1:\n          return !predicate.call(this, args[0]);\n        case 2:\n          return !predicate.call(this, args[0], args[1]);\n        case 3:\n          return !predicate.call(this, args[0], args[1], args[2]);\n      }\n      return !predicate.apply(this, args);\n    };\n  }\n  function baseSet(object, path, value, customizer) {\n    if (!isObject(object)) {\n      return object;\n    }\n    path = castPath(path, object);\n    var index = -1,\n      length = path.length,\n      lastIndex = length - 1,\n      nested = object;\n    while (nested != null && ++index < length) {\n      var key = toKey(path[index]),\n        newValue = value;\n      if (key === \"__proto__\" || key === \"constructor\" || key === \"prototype\") {\n        return object;\n      }\n      if (index != lastIndex) {\n        var objValue = nested[key];\n        newValue = customizer ? customizer(objValue, key, nested) : void 0;\n        if (newValue === void 0) {\n          newValue = isObject(objValue) ? objValue : isIndex(path[index + 1]) ? [] : {};\n        }\n      }\n      assignValue(nested, key, newValue);\n      nested = nested[key];\n    }\n    return object;\n  }\n  function basePickBy(object, paths, predicate) {\n    var index = -1,\n      length = paths.length,\n      result = {};\n    while (++index < length) {\n      var path = paths[index],\n        value = baseGet(object, path);\n      if (predicate(value, path)) {\n        baseSet(result, castPath(path, object), value);\n      }\n    }\n    return result;\n  }\n  function pickBy(object, predicate) {\n    if (object == null) {\n      return {};\n    }\n    var props = arrayMap(getAllKeysIn(object), function (prop) {\n      return [prop];\n    });\n    predicate = baseIteratee(predicate);\n    return basePickBy(object, props, function (value, path) {\n      return predicate(value, path[0]);\n    });\n  }\n  function baseReduce(collection, iteratee, accumulator, initAccum, eachFunc) {\n    eachFunc(collection, function (value, index, collection2) {\n      accumulator = initAccum ? (initAccum = false, value) : iteratee(accumulator, value, index, collection2);\n    });\n    return accumulator;\n  }\n  function reduce(collection, iteratee, accumulator) {\n    var func = isArray$1(collection) ? arrayReduce : baseReduce,\n      initAccum = arguments.length < 3;\n    return func(collection, baseIteratee(iteratee), accumulator, initAccum, baseEach$1);\n  }\n  function reject(collection, predicate) {\n    var func = isArray$1(collection) ? arrayFilter : baseFilter;\n    return func(collection, negate(baseIteratee(predicate)));\n  }\n  function baseSome(collection, predicate) {\n    var result;\n    baseEach$1(collection, function (value, index, collection2) {\n      result = predicate(value, index, collection2);\n      return !result;\n    });\n    return !!result;\n  }\n  function some(collection, predicate, guard) {\n    var func = isArray$1(collection) ? arraySome : baseSome;\n    if (guard && isIterateeCall(collection, predicate, guard)) {\n      predicate = void 0;\n    }\n    return func(collection, baseIteratee(predicate));\n  }\n  var INFINITY = 1 / 0;\n  var createSet = !(Set$1 && 1 / setToArray(new Set$1([, -0]))[1] == INFINITY) ? noop : function (values2) {\n    return new Set$1(values2);\n  };\n  const createSet$1 = createSet;\n  var LARGE_ARRAY_SIZE = 200;\n  function baseUniq(array, iteratee, comparator) {\n    var index = -1,\n      includes2 = arrayIncludes,\n      length = array.length,\n      isCommon = true,\n      result = [],\n      seen = result;\n    if (comparator) {\n      isCommon = false;\n      includes2 = arrayIncludesWith;\n    } else if (length >= LARGE_ARRAY_SIZE) {\n      var set = iteratee ? null : createSet$1(array);\n      if (set) {\n        return setToArray(set);\n      }\n      isCommon = false;\n      includes2 = cacheHas;\n      seen = new SetCache();\n    } else {\n      seen = iteratee ? [] : result;\n    }\n    outer: while (++index < length) {\n      var value = array[index],\n        computed = iteratee ? iteratee(value) : value;\n      value = comparator || value !== 0 ? value : 0;\n      if (isCommon && computed === computed) {\n        var seenIndex = seen.length;\n        while (seenIndex--) {\n          if (seen[seenIndex] === computed) {\n            continue outer;\n          }\n        }\n        if (iteratee) {\n          seen.push(computed);\n        }\n        result.push(value);\n      } else if (!includes2(seen, computed, comparator)) {\n        if (seen !== result) {\n          seen.push(computed);\n        }\n        result.push(value);\n      }\n    }\n    return result;\n  }\n  function uniq(array) {\n    return array && array.length ? baseUniq(array) : [];\n  }\n  function PRINT_ERROR(msg) {\n    if (console && console.error) {\n      console.error(`Error: ${msg}`);\n    }\n  }\n  function PRINT_WARNING(msg) {\n    if (console && console.warn) {\n      console.warn(`Warning: ${msg}`);\n    }\n  }\n  function timer(func) {\n    const start = (/* @__PURE__ */new Date()).getTime();\n    const val = func();\n    const end = (/* @__PURE__ */new Date()).getTime();\n    const total = end - start;\n    return {\n      time: total,\n      value: val\n    };\n  }\n  function toFastProperties(toBecomeFast) {\n    function FakeConstructor() {}\n    FakeConstructor.prototype = toBecomeFast;\n    const fakeInstance = new FakeConstructor();\n    function fakeAccess() {\n      return typeof fakeInstance.bar;\n    }\n    fakeAccess();\n    fakeAccess();\n    return toBecomeFast;\n  }\n  function tokenLabel$1(tokType) {\n    if (hasTokenLabel$1(tokType)) {\n      return tokType.LABEL;\n    } else {\n      return tokType.name;\n    }\n  }\n  function hasTokenLabel$1(obj) {\n    return isString(obj.LABEL) && obj.LABEL !== \"\";\n  }\n  class AbstractProduction {\n    get definition() {\n      return this._definition;\n    }\n    set definition(value) {\n      this._definition = value;\n    }\n    constructor(_definition) {\n      this._definition = _definition;\n    }\n    accept(visitor) {\n      visitor.visit(this);\n      forEach(this.definition, prod => {\n        prod.accept(visitor);\n      });\n    }\n  }\n  class NonTerminal extends AbstractProduction {\n    constructor(options) {\n      super([]);\n      this.idx = 1;\n      assign$1(this, pickBy(options, v => v !== void 0));\n    }\n    set definition(definition) {}\n    get definition() {\n      if (this.referencedRule !== void 0) {\n        return this.referencedRule.definition;\n      }\n      return [];\n    }\n    accept(visitor) {\n      visitor.visit(this);\n    }\n  }\n  class Rule extends AbstractProduction {\n    constructor(options) {\n      super(options.definition);\n      this.orgText = \"\";\n      assign$1(this, pickBy(options, v => v !== void 0));\n    }\n  }\n  class Alternative extends AbstractProduction {\n    constructor(options) {\n      super(options.definition);\n      this.ignoreAmbiguities = false;\n      assign$1(this, pickBy(options, v => v !== void 0));\n    }\n  }\n  class Option extends AbstractProduction {\n    constructor(options) {\n      super(options.definition);\n      this.idx = 1;\n      assign$1(this, pickBy(options, v => v !== void 0));\n    }\n  }\n  class RepetitionMandatory extends AbstractProduction {\n    constructor(options) {\n      super(options.definition);\n      this.idx = 1;\n      assign$1(this, pickBy(options, v => v !== void 0));\n    }\n  }\n  class RepetitionMandatoryWithSeparator extends AbstractProduction {\n    constructor(options) {\n      super(options.definition);\n      this.idx = 1;\n      assign$1(this, pickBy(options, v => v !== void 0));\n    }\n  }\n  class Repetition extends AbstractProduction {\n    constructor(options) {\n      super(options.definition);\n      this.idx = 1;\n      assign$1(this, pickBy(options, v => v !== void 0));\n    }\n  }\n  class RepetitionWithSeparator extends AbstractProduction {\n    constructor(options) {\n      super(options.definition);\n      this.idx = 1;\n      assign$1(this, pickBy(options, v => v !== void 0));\n    }\n  }\n  class Alternation extends AbstractProduction {\n    get definition() {\n      return this._definition;\n    }\n    set definition(value) {\n      this._definition = value;\n    }\n    constructor(options) {\n      super(options.definition);\n      this.idx = 1;\n      this.ignoreAmbiguities = false;\n      this.hasPredicates = false;\n      assign$1(this, pickBy(options, v => v !== void 0));\n    }\n  }\n  class Terminal {\n    constructor(options) {\n      this.idx = 1;\n      assign$1(this, pickBy(options, v => v !== void 0));\n    }\n    accept(visitor) {\n      visitor.visit(this);\n    }\n  }\n  function serializeGrammar(topRules) {\n    return map(topRules, serializeProduction);\n  }\n  function serializeProduction(node) {\n    function convertDefinition(definition) {\n      return map(definition, serializeProduction);\n    }\n    if (node instanceof NonTerminal) {\n      const serializedNonTerminal = {\n        type: \"NonTerminal\",\n        name: node.nonTerminalName,\n        idx: node.idx\n      };\n      if (isString(node.label)) {\n        serializedNonTerminal.label = node.label;\n      }\n      return serializedNonTerminal;\n    } else if (node instanceof Alternative) {\n      return {\n        type: \"Alternative\",\n        definition: convertDefinition(node.definition)\n      };\n    } else if (node instanceof Option) {\n      return {\n        type: \"Option\",\n        idx: node.idx,\n        definition: convertDefinition(node.definition)\n      };\n    } else if (node instanceof RepetitionMandatory) {\n      return {\n        type: \"RepetitionMandatory\",\n        idx: node.idx,\n        definition: convertDefinition(node.definition)\n      };\n    } else if (node instanceof RepetitionMandatoryWithSeparator) {\n      return {\n        type: \"RepetitionMandatoryWithSeparator\",\n        idx: node.idx,\n        separator: serializeProduction(new Terminal({\n          terminalType: node.separator\n        })),\n        definition: convertDefinition(node.definition)\n      };\n    } else if (node instanceof RepetitionWithSeparator) {\n      return {\n        type: \"RepetitionWithSeparator\",\n        idx: node.idx,\n        separator: serializeProduction(new Terminal({\n          terminalType: node.separator\n        })),\n        definition: convertDefinition(node.definition)\n      };\n    } else if (node instanceof Repetition) {\n      return {\n        type: \"Repetition\",\n        idx: node.idx,\n        definition: convertDefinition(node.definition)\n      };\n    } else if (node instanceof Alternation) {\n      return {\n        type: \"Alternation\",\n        idx: node.idx,\n        definition: convertDefinition(node.definition)\n      };\n    } else if (node instanceof Terminal) {\n      const serializedTerminal = {\n        type: \"Terminal\",\n        name: node.terminalType.name,\n        label: tokenLabel$1(node.terminalType),\n        idx: node.idx\n      };\n      if (isString(node.label)) {\n        serializedTerminal.terminalLabel = node.label;\n      }\n      const pattern = node.terminalType.PATTERN;\n      if (node.terminalType.PATTERN) {\n        serializedTerminal.pattern = isRegExp$1(pattern) ? pattern.source : pattern;\n      }\n      return serializedTerminal;\n    } else if (node instanceof Rule) {\n      return {\n        type: \"Rule\",\n        name: node.name,\n        orgText: node.orgText,\n        definition: convertDefinition(node.definition)\n      };\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  }\n  class GAstVisitor {\n    visit(node) {\n      const nodeAny = node;\n      switch (nodeAny.constructor) {\n        case NonTerminal:\n          return this.visitNonTerminal(nodeAny);\n        case Alternative:\n          return this.visitAlternative(nodeAny);\n        case Option:\n          return this.visitOption(nodeAny);\n        case RepetitionMandatory:\n          return this.visitRepetitionMandatory(nodeAny);\n        case RepetitionMandatoryWithSeparator:\n          return this.visitRepetitionMandatoryWithSeparator(nodeAny);\n        case RepetitionWithSeparator:\n          return this.visitRepetitionWithSeparator(nodeAny);\n        case Repetition:\n          return this.visitRepetition(nodeAny);\n        case Alternation:\n          return this.visitAlternation(nodeAny);\n        case Terminal:\n          return this.visitTerminal(nodeAny);\n        case Rule:\n          return this.visitRule(nodeAny);\n        default:\n          throw Error(\"non exhaustive match\");\n      }\n    }\n    /* c8 ignore next */\n    visitNonTerminal(node) {}\n    /* c8 ignore next */\n    visitAlternative(node) {}\n    /* c8 ignore next */\n    visitOption(node) {}\n    /* c8 ignore next */\n    visitRepetition(node) {}\n    /* c8 ignore next */\n    visitRepetitionMandatory(node) {}\n    /* c8 ignore next 3 */\n    visitRepetitionMandatoryWithSeparator(node) {}\n    /* c8 ignore next */\n    visitRepetitionWithSeparator(node) {}\n    /* c8 ignore next */\n    visitAlternation(node) {}\n    /* c8 ignore next */\n    visitTerminal(node) {}\n    /* c8 ignore next */\n    visitRule(node) {}\n  }\n  function isSequenceProd(prod) {\n    return prod instanceof Alternative || prod instanceof Option || prod instanceof Repetition || prod instanceof RepetitionMandatory || prod instanceof RepetitionMandatoryWithSeparator || prod instanceof RepetitionWithSeparator || prod instanceof Terminal || prod instanceof Rule;\n  }\n  function isOptionalProd(prod, alreadyVisited = []) {\n    const isDirectlyOptional = prod instanceof Option || prod instanceof Repetition || prod instanceof RepetitionWithSeparator;\n    if (isDirectlyOptional) {\n      return true;\n    }\n    if (prod instanceof Alternation) {\n      return some(prod.definition, subProd => {\n        return isOptionalProd(subProd, alreadyVisited);\n      });\n    } else if (prod instanceof NonTerminal && includes(alreadyVisited, prod)) {\n      return false;\n    } else if (prod instanceof AbstractProduction) {\n      if (prod instanceof NonTerminal) {\n        alreadyVisited.push(prod);\n      }\n      return every(prod.definition, subProd => {\n        return isOptionalProd(subProd, alreadyVisited);\n      });\n    } else {\n      return false;\n    }\n  }\n  function isBranchingProd(prod) {\n    return prod instanceof Alternation;\n  }\n  function getProductionDslName(prod) {\n    if (prod instanceof NonTerminal) {\n      return \"SUBRULE\";\n    } else if (prod instanceof Option) {\n      return \"OPTION\";\n    } else if (prod instanceof Alternation) {\n      return \"OR\";\n    } else if (prod instanceof RepetitionMandatory) {\n      return \"AT_LEAST_ONE\";\n    } else if (prod instanceof RepetitionMandatoryWithSeparator) {\n      return \"AT_LEAST_ONE_SEP\";\n    } else if (prod instanceof RepetitionWithSeparator) {\n      return \"MANY_SEP\";\n    } else if (prod instanceof Repetition) {\n      return \"MANY\";\n    } else if (prod instanceof Terminal) {\n      return \"CONSUME\";\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  }\n  class RestWalker {\n    walk(prod, prevRest = []) {\n      forEach(prod.definition, (subProd, index) => {\n        const currRest = drop(prod.definition, index + 1);\n        if (subProd instanceof NonTerminal) {\n          this.walkProdRef(subProd, currRest, prevRest);\n        } else if (subProd instanceof Terminal) {\n          this.walkTerminal(subProd, currRest, prevRest);\n        } else if (subProd instanceof Alternative) {\n          this.walkFlat(subProd, currRest, prevRest);\n        } else if (subProd instanceof Option) {\n          this.walkOption(subProd, currRest, prevRest);\n        } else if (subProd instanceof RepetitionMandatory) {\n          this.walkAtLeastOne(subProd, currRest, prevRest);\n        } else if (subProd instanceof RepetitionMandatoryWithSeparator) {\n          this.walkAtLeastOneSep(subProd, currRest, prevRest);\n        } else if (subProd instanceof RepetitionWithSeparator) {\n          this.walkManySep(subProd, currRest, prevRest);\n        } else if (subProd instanceof Repetition) {\n          this.walkMany(subProd, currRest, prevRest);\n        } else if (subProd instanceof Alternation) {\n          this.walkOr(subProd, currRest, prevRest);\n        } else {\n          throw Error(\"non exhaustive match\");\n        }\n      });\n    }\n    walkTerminal(terminal, currRest, prevRest) {}\n    walkProdRef(refProd, currRest, prevRest) {}\n    walkFlat(flatProd, currRest, prevRest) {\n      const fullOrRest = currRest.concat(prevRest);\n      this.walk(flatProd, fullOrRest);\n    }\n    walkOption(optionProd, currRest, prevRest) {\n      const fullOrRest = currRest.concat(prevRest);\n      this.walk(optionProd, fullOrRest);\n    }\n    walkAtLeastOne(atLeastOneProd, currRest, prevRest) {\n      const fullAtLeastOneRest = [new Option({\n        definition: atLeastOneProd.definition\n      })].concat(currRest, prevRest);\n      this.walk(atLeastOneProd, fullAtLeastOneRest);\n    }\n    walkAtLeastOneSep(atLeastOneSepProd, currRest, prevRest) {\n      const fullAtLeastOneSepRest = restForRepetitionWithSeparator(atLeastOneSepProd, currRest, prevRest);\n      this.walk(atLeastOneSepProd, fullAtLeastOneSepRest);\n    }\n    walkMany(manyProd, currRest, prevRest) {\n      const fullManyRest = [new Option({\n        definition: manyProd.definition\n      })].concat(currRest, prevRest);\n      this.walk(manyProd, fullManyRest);\n    }\n    walkManySep(manySepProd, currRest, prevRest) {\n      const fullManySepRest = restForRepetitionWithSeparator(manySepProd, currRest, prevRest);\n      this.walk(manySepProd, fullManySepRest);\n    }\n    walkOr(orProd, currRest, prevRest) {\n      const fullOrRest = currRest.concat(prevRest);\n      forEach(orProd.definition, alt => {\n        const prodWrapper = new Alternative({\n          definition: [alt]\n        });\n        this.walk(prodWrapper, fullOrRest);\n      });\n    }\n  }\n  function restForRepetitionWithSeparator(repSepProd, currRest, prevRest) {\n    const repSepRest = [new Option({\n      definition: [new Terminal({\n        terminalType: repSepProd.separator\n      })].concat(repSepProd.definition)\n    })];\n    const fullRepSepRest = repSepRest.concat(currRest, prevRest);\n    return fullRepSepRest;\n  }\n  function first(prod) {\n    if (prod instanceof NonTerminal) {\n      return first(prod.referencedRule);\n    } else if (prod instanceof Terminal) {\n      return firstForTerminal(prod);\n    } else if (isSequenceProd(prod)) {\n      return firstForSequence(prod);\n    } else if (isBranchingProd(prod)) {\n      return firstForBranching(prod);\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  }\n  function firstForSequence(prod) {\n    let firstSet = [];\n    const seq = prod.definition;\n    let nextSubProdIdx = 0;\n    let hasInnerProdsRemaining = seq.length > nextSubProdIdx;\n    let currSubProd;\n    let isLastInnerProdOptional = true;\n    while (hasInnerProdsRemaining && isLastInnerProdOptional) {\n      currSubProd = seq[nextSubProdIdx];\n      isLastInnerProdOptional = isOptionalProd(currSubProd);\n      firstSet = firstSet.concat(first(currSubProd));\n      nextSubProdIdx = nextSubProdIdx + 1;\n      hasInnerProdsRemaining = seq.length > nextSubProdIdx;\n    }\n    return uniq(firstSet);\n  }\n  function firstForBranching(prod) {\n    const allAlternativesFirsts = map(prod.definition, innerProd => {\n      return first(innerProd);\n    });\n    return uniq(flatten(allAlternativesFirsts));\n  }\n  function firstForTerminal(terminal) {\n    return [terminal.terminalType];\n  }\n  const IN = \"_~IN~_\";\n  class ResyncFollowsWalker extends RestWalker {\n    constructor(topProd) {\n      super();\n      this.topProd = topProd;\n      this.follows = {};\n    }\n    startWalking() {\n      this.walk(this.topProd);\n      return this.follows;\n    }\n    walkTerminal(terminal, currRest, prevRest) {}\n    walkProdRef(refProd, currRest, prevRest) {\n      const followName = buildBetweenProdsFollowPrefix(refProd.referencedRule, refProd.idx) + this.topProd.name;\n      const fullRest = currRest.concat(prevRest);\n      const restProd = new Alternative({\n        definition: fullRest\n      });\n      const t_in_topProd_follows = first(restProd);\n      this.follows[followName] = t_in_topProd_follows;\n    }\n  }\n  function computeAllProdsFollows(topProductions) {\n    const reSyncFollows = {};\n    forEach(topProductions, topProd => {\n      const currRefsFollow = new ResyncFollowsWalker(topProd).startWalking();\n      assign$1(reSyncFollows, currRefsFollow);\n    });\n    return reSyncFollows;\n  }\n  function buildBetweenProdsFollowPrefix(inner, occurenceInParent) {\n    return inner.name + occurenceInParent + IN;\n  }\n  function cc(char) {\n    return char.charCodeAt(0);\n  }\n  function insertToSet(item, set) {\n    if (Array.isArray(item)) {\n      item.forEach(function (subItem) {\n        set.push(subItem);\n      });\n    } else {\n      set.push(item);\n    }\n  }\n  function addFlag(flagObj, flagKey) {\n    if (flagObj[flagKey] === true) {\n      throw \"duplicate flag \" + flagKey;\n    }\n    flagObj[flagKey];\n    flagObj[flagKey] = true;\n  }\n  function ASSERT_EXISTS(obj) {\n    if (obj === void 0) {\n      throw Error(\"Internal Error - Should never get here!\");\n    }\n    return true;\n  }\n  function ASSERT_NEVER_REACH_HERE() {\n    throw Error(\"Internal Error - Should never get here!\");\n  }\n  function isCharacter(obj) {\n    return obj[\"type\"] === \"Character\";\n  }\n  const digitsCharCodes = [];\n  for (let i = cc(\"0\"); i <= cc(\"9\"); i++) {\n    digitsCharCodes.push(i);\n  }\n  const wordCharCodes = [cc(\"_\")].concat(digitsCharCodes);\n  for (let i = cc(\"a\"); i <= cc(\"z\"); i++) {\n    wordCharCodes.push(i);\n  }\n  for (let i = cc(\"A\"); i <= cc(\"Z\"); i++) {\n    wordCharCodes.push(i);\n  }\n  const whitespaceCodes = [cc(\" \"), cc(\"\\f\"), cc(\"\\n\"), cc(\"\\r\"), cc(\"\t\"), cc(\"\\v\"), cc(\"\t\"), cc(\"\"), cc(\"\"), cc(\"\"), cc(\"\"), cc(\"\"), cc(\"\"), cc(\"\"), cc(\"\"), cc(\"\"), cc(\"\"), cc(\"\"), cc(\"\"), cc(\"\"), cc(\"\\u2028\"), cc(\"\\u2029\"), cc(\"\"), cc(\"\"), cc(\"\"), cc(\"\\uFEFF\")];\n  const hexDigitPattern = /[0-9a-fA-F]/;\n  const decimalPattern = /[0-9]/;\n  const decimalPatternNoZero = /[1-9]/;\n  class RegExpParser {\n    constructor() {\n      this.idx = 0;\n      this.input = \"\";\n      this.groupIdx = 0;\n    }\n    saveState() {\n      return {\n        idx: this.idx,\n        input: this.input,\n        groupIdx: this.groupIdx\n      };\n    }\n    restoreState(newState) {\n      this.idx = newState.idx;\n      this.input = newState.input;\n      this.groupIdx = newState.groupIdx;\n    }\n    pattern(input) {\n      this.idx = 0;\n      this.input = input;\n      this.groupIdx = 0;\n      this.consumeChar(\"/\");\n      const value = this.disjunction();\n      this.consumeChar(\"/\");\n      const flags = {\n        type: \"Flags\",\n        loc: {\n          begin: this.idx,\n          end: input.length\n        },\n        global: false,\n        ignoreCase: false,\n        multiLine: false,\n        unicode: false,\n        sticky: false\n      };\n      while (this.isRegExpFlag()) {\n        switch (this.popChar()) {\n          case \"g\":\n            addFlag(flags, \"global\");\n            break;\n          case \"i\":\n            addFlag(flags, \"ignoreCase\");\n            break;\n          case \"m\":\n            addFlag(flags, \"multiLine\");\n            break;\n          case \"u\":\n            addFlag(flags, \"unicode\");\n            break;\n          case \"y\":\n            addFlag(flags, \"sticky\");\n            break;\n        }\n      }\n      if (this.idx !== this.input.length) {\n        throw Error(\"Redundant input: \" + this.input.substring(this.idx));\n      }\n      return {\n        type: \"Pattern\",\n        flags,\n        value,\n        loc: this.loc(0)\n      };\n    }\n    disjunction() {\n      const alts = [];\n      const begin = this.idx;\n      alts.push(this.alternative());\n      while (this.peekChar() === \"|\") {\n        this.consumeChar(\"|\");\n        alts.push(this.alternative());\n      }\n      return {\n        type: \"Disjunction\",\n        value: alts,\n        loc: this.loc(begin)\n      };\n    }\n    alternative() {\n      const terms = [];\n      const begin = this.idx;\n      while (this.isTerm()) {\n        terms.push(this.term());\n      }\n      return {\n        type: \"Alternative\",\n        value: terms,\n        loc: this.loc(begin)\n      };\n    }\n    term() {\n      if (this.isAssertion()) {\n        return this.assertion();\n      } else {\n        return this.atom();\n      }\n    }\n    assertion() {\n      const begin = this.idx;\n      switch (this.popChar()) {\n        case \"^\":\n          return {\n            type: \"StartAnchor\",\n            loc: this.loc(begin)\n          };\n        case \"$\":\n          return {\n            type: \"EndAnchor\",\n            loc: this.loc(begin)\n          };\n        case \"\\\\\":\n          switch (this.popChar()) {\n            case \"b\":\n              return {\n                type: \"WordBoundary\",\n                loc: this.loc(begin)\n              };\n            case \"B\":\n              return {\n                type: \"NonWordBoundary\",\n                loc: this.loc(begin)\n              };\n          }\n          throw Error(\"Invalid Assertion Escape\");\n        case \"(\":\n          this.consumeChar(\"?\");\n          let type;\n          switch (this.popChar()) {\n            case \"=\":\n              type = \"Lookahead\";\n              break;\n            case \"!\":\n              type = \"NegativeLookahead\";\n              break;\n          }\n          ASSERT_EXISTS(type);\n          const disjunction = this.disjunction();\n          this.consumeChar(\")\");\n          return {\n            type,\n            value: disjunction,\n            loc: this.loc(begin)\n          };\n      }\n      return ASSERT_NEVER_REACH_HERE();\n    }\n    quantifier(isBacktracking = false) {\n      let range = void 0;\n      const begin = this.idx;\n      switch (this.popChar()) {\n        case \"*\":\n          range = {\n            atLeast: 0,\n            atMost: Infinity\n          };\n          break;\n        case \"+\":\n          range = {\n            atLeast: 1,\n            atMost: Infinity\n          };\n          break;\n        case \"?\":\n          range = {\n            atLeast: 0,\n            atMost: 1\n          };\n          break;\n        case \"{\":\n          const atLeast = this.integerIncludingZero();\n          switch (this.popChar()) {\n            case \"}\":\n              range = {\n                atLeast,\n                atMost: atLeast\n              };\n              break;\n            case \",\":\n              let atMost;\n              if (this.isDigit()) {\n                atMost = this.integerIncludingZero();\n                range = {\n                  atLeast,\n                  atMost\n                };\n              } else {\n                range = {\n                  atLeast,\n                  atMost: Infinity\n                };\n              }\n              this.consumeChar(\"}\");\n              break;\n          }\n          if (isBacktracking === true && range === void 0) {\n            return void 0;\n          }\n          ASSERT_EXISTS(range);\n          break;\n      }\n      if (isBacktracking === true && range === void 0) {\n        return void 0;\n      }\n      if (ASSERT_EXISTS(range)) {\n        if (this.peekChar(0) === \"?\") {\n          this.consumeChar(\"?\");\n          range.greedy = false;\n        } else {\n          range.greedy = true;\n        }\n        range.type = \"Quantifier\";\n        range.loc = this.loc(begin);\n        return range;\n      }\n    }\n    atom() {\n      let atom;\n      const begin = this.idx;\n      switch (this.peekChar()) {\n        case \".\":\n          atom = this.dotAll();\n          break;\n        case \"\\\\\":\n          atom = this.atomEscape();\n          break;\n        case \"[\":\n          atom = this.characterClass();\n          break;\n        case \"(\":\n          atom = this.group();\n          break;\n      }\n      if (atom === void 0 && this.isPatternCharacter()) {\n        atom = this.patternCharacter();\n      }\n      if (ASSERT_EXISTS(atom)) {\n        atom.loc = this.loc(begin);\n        if (this.isQuantifier()) {\n          atom.quantifier = this.quantifier();\n        }\n        return atom;\n      }\n    }\n    dotAll() {\n      this.consumeChar(\".\");\n      return {\n        type: \"Set\",\n        complement: true,\n        value: [cc(\"\\n\"), cc(\"\\r\"), cc(\"\\u2028\"), cc(\"\\u2029\")]\n      };\n    }\n    atomEscape() {\n      this.consumeChar(\"\\\\\");\n      switch (this.peekChar()) {\n        case \"1\":\n        case \"2\":\n        case \"3\":\n        case \"4\":\n        case \"5\":\n        case \"6\":\n        case \"7\":\n        case \"8\":\n        case \"9\":\n          return this.decimalEscapeAtom();\n        case \"d\":\n        case \"D\":\n        case \"s\":\n        case \"S\":\n        case \"w\":\n        case \"W\":\n          return this.characterClassEscape();\n        case \"f\":\n        case \"n\":\n        case \"r\":\n        case \"t\":\n        case \"v\":\n          return this.controlEscapeAtom();\n        case \"c\":\n          return this.controlLetterEscapeAtom();\n        case \"0\":\n          return this.nulCharacterAtom();\n        case \"x\":\n          return this.hexEscapeSequenceAtom();\n        case \"u\":\n          return this.regExpUnicodeEscapeSequenceAtom();\n        default:\n          return this.identityEscapeAtom();\n      }\n    }\n    decimalEscapeAtom() {\n      const value = this.positiveInteger();\n      return {\n        type: \"GroupBackReference\",\n        value\n      };\n    }\n    characterClassEscape() {\n      let set;\n      let complement = false;\n      switch (this.popChar()) {\n        case \"d\":\n          set = digitsCharCodes;\n          break;\n        case \"D\":\n          set = digitsCharCodes;\n          complement = true;\n          break;\n        case \"s\":\n          set = whitespaceCodes;\n          break;\n        case \"S\":\n          set = whitespaceCodes;\n          complement = true;\n          break;\n        case \"w\":\n          set = wordCharCodes;\n          break;\n        case \"W\":\n          set = wordCharCodes;\n          complement = true;\n          break;\n      }\n      if (ASSERT_EXISTS(set)) {\n        return {\n          type: \"Set\",\n          value: set,\n          complement\n        };\n      }\n    }\n    controlEscapeAtom() {\n      let escapeCode;\n      switch (this.popChar()) {\n        case \"f\":\n          escapeCode = cc(\"\\f\");\n          break;\n        case \"n\":\n          escapeCode = cc(\"\\n\");\n          break;\n        case \"r\":\n          escapeCode = cc(\"\\r\");\n          break;\n        case \"t\":\n          escapeCode = cc(\"\t\");\n          break;\n        case \"v\":\n          escapeCode = cc(\"\\v\");\n          break;\n      }\n      if (ASSERT_EXISTS(escapeCode)) {\n        return {\n          type: \"Character\",\n          value: escapeCode\n        };\n      }\n    }\n    controlLetterEscapeAtom() {\n      this.consumeChar(\"c\");\n      const letter = this.popChar();\n      if (/[a-zA-Z]/.test(letter) === false) {\n        throw Error(\"Invalid \");\n      }\n      const letterCode = letter.toUpperCase().charCodeAt(0) - 64;\n      return {\n        type: \"Character\",\n        value: letterCode\n      };\n    }\n    nulCharacterAtom() {\n      this.consumeChar(\"0\");\n      return {\n        type: \"Character\",\n        value: cc(\"\\0\")\n      };\n    }\n    hexEscapeSequenceAtom() {\n      this.consumeChar(\"x\");\n      return this.parseHexDigits(2);\n    }\n    regExpUnicodeEscapeSequenceAtom() {\n      this.consumeChar(\"u\");\n      return this.parseHexDigits(4);\n    }\n    identityEscapeAtom() {\n      const escapedChar = this.popChar();\n      return {\n        type: \"Character\",\n        value: cc(escapedChar)\n      };\n    }\n    classPatternCharacterAtom() {\n      switch (this.peekChar()) {\n        case \"\\n\":\n        case \"\\r\":\n        case \"\\u2028\":\n        case \"\\u2029\":\n        case \"\\\\\":\n        case \"]\":\n          throw Error(\"TBD\");\n        default:\n          const nextChar = this.popChar();\n          return {\n            type: \"Character\",\n            value: cc(nextChar)\n          };\n      }\n    }\n    characterClass() {\n      const set = [];\n      let complement = false;\n      this.consumeChar(\"[\");\n      if (this.peekChar(0) === \"^\") {\n        this.consumeChar(\"^\");\n        complement = true;\n      }\n      while (this.isClassAtom()) {\n        const from = this.classAtom();\n        from.type === \"Character\";\n        if (isCharacter(from) && this.isRangeDash()) {\n          this.consumeChar(\"-\");\n          const to = this.classAtom();\n          to.type === \"Character\";\n          if (isCharacter(to)) {\n            if (to.value < from.value) {\n              throw Error(\"Range out of order in character class\");\n            }\n            set.push({\n              from: from.value,\n              to: to.value\n            });\n          } else {\n            insertToSet(from.value, set);\n            set.push(cc(\"-\"));\n            insertToSet(to.value, set);\n          }\n        } else {\n          insertToSet(from.value, set);\n        }\n      }\n      this.consumeChar(\"]\");\n      return {\n        type: \"Set\",\n        complement,\n        value: set\n      };\n    }\n    classAtom() {\n      switch (this.peekChar()) {\n        case \"]\":\n        case \"\\n\":\n        case \"\\r\":\n        case \"\\u2028\":\n        case \"\\u2029\":\n          throw Error(\"TBD\");\n        case \"\\\\\":\n          return this.classEscape();\n        default:\n          return this.classPatternCharacterAtom();\n      }\n    }\n    classEscape() {\n      this.consumeChar(\"\\\\\");\n      switch (this.peekChar()) {\n        case \"b\":\n          this.consumeChar(\"b\");\n          return {\n            type: \"Character\",\n            value: cc(\"\\b\")\n          };\n        case \"d\":\n        case \"D\":\n        case \"s\":\n        case \"S\":\n        case \"w\":\n        case \"W\":\n          return this.characterClassEscape();\n        case \"f\":\n        case \"n\":\n        case \"r\":\n        case \"t\":\n        case \"v\":\n          return this.controlEscapeAtom();\n        case \"c\":\n          return this.controlLetterEscapeAtom();\n        case \"0\":\n          return this.nulCharacterAtom();\n        case \"x\":\n          return this.hexEscapeSequenceAtom();\n        case \"u\":\n          return this.regExpUnicodeEscapeSequenceAtom();\n        default:\n          return this.identityEscapeAtom();\n      }\n    }\n    group() {\n      let capturing = true;\n      this.consumeChar(\"(\");\n      switch (this.peekChar(0)) {\n        case \"?\":\n          this.consumeChar(\"?\");\n          this.consumeChar(\":\");\n          capturing = false;\n          break;\n        default:\n          this.groupIdx++;\n          break;\n      }\n      const value = this.disjunction();\n      this.consumeChar(\")\");\n      const groupAst = {\n        type: \"Group\",\n        capturing,\n        value\n      };\n      if (capturing) {\n        groupAst[\"idx\"] = this.groupIdx;\n      }\n      return groupAst;\n    }\n    positiveInteger() {\n      let number = this.popChar();\n      if (decimalPatternNoZero.test(number) === false) {\n        throw Error(\"Expecting a positive integer\");\n      }\n      while (decimalPattern.test(this.peekChar(0))) {\n        number += this.popChar();\n      }\n      return parseInt(number, 10);\n    }\n    integerIncludingZero() {\n      let number = this.popChar();\n      if (decimalPattern.test(number) === false) {\n        throw Error(\"Expecting an integer\");\n      }\n      while (decimalPattern.test(this.peekChar(0))) {\n        number += this.popChar();\n      }\n      return parseInt(number, 10);\n    }\n    patternCharacter() {\n      const nextChar = this.popChar();\n      switch (nextChar) {\n        case \"\\n\":\n        case \"\\r\":\n        case \"\\u2028\":\n        case \"\\u2029\":\n        case \"^\":\n        case \"$\":\n        case \"\\\\\":\n        case \".\":\n        case \"*\":\n        case \"+\":\n        case \"?\":\n        case \"(\":\n        case \")\":\n        case \"[\":\n        case \"|\":\n          throw Error(\"TBD\");\n        default:\n          return {\n            type: \"Character\",\n            value: cc(nextChar)\n          };\n      }\n    }\n    isRegExpFlag() {\n      switch (this.peekChar(0)) {\n        case \"g\":\n        case \"i\":\n        case \"m\":\n        case \"u\":\n        case \"y\":\n          return true;\n        default:\n          return false;\n      }\n    }\n    isRangeDash() {\n      return this.peekChar() === \"-\" && this.isClassAtom(1);\n    }\n    isDigit() {\n      return decimalPattern.test(this.peekChar(0));\n    }\n    isClassAtom(howMuch = 0) {\n      switch (this.peekChar(howMuch)) {\n        case \"]\":\n        case \"\\n\":\n        case \"\\r\":\n        case \"\\u2028\":\n        case \"\\u2029\":\n          return false;\n        default:\n          return true;\n      }\n    }\n    isTerm() {\n      return this.isAtom() || this.isAssertion();\n    }\n    isAtom() {\n      if (this.isPatternCharacter()) {\n        return true;\n      }\n      switch (this.peekChar(0)) {\n        case \".\":\n        case \"\\\\\":\n        case \"[\":\n        case \"(\":\n          return true;\n        default:\n          return false;\n      }\n    }\n    isAssertion() {\n      switch (this.peekChar(0)) {\n        case \"^\":\n        case \"$\":\n          return true;\n        case \"\\\\\":\n          switch (this.peekChar(1)) {\n            case \"b\":\n            case \"B\":\n              return true;\n            default:\n              return false;\n          }\n        case \"(\":\n          return this.peekChar(1) === \"?\" && (this.peekChar(2) === \"=\" || this.peekChar(2) === \"!\");\n        default:\n          return false;\n      }\n    }\n    isQuantifier() {\n      const prevState = this.saveState();\n      try {\n        return this.quantifier(true) !== void 0;\n      } catch (e) {\n        return false;\n      } finally {\n        this.restoreState(prevState);\n      }\n    }\n    isPatternCharacter() {\n      switch (this.peekChar()) {\n        case \"^\":\n        case \"$\":\n        case \"\\\\\":\n        case \".\":\n        case \"*\":\n        case \"+\":\n        case \"?\":\n        case \"(\":\n        case \")\":\n        case \"[\":\n        case \"|\":\n        case \"/\":\n        case \"\\n\":\n        case \"\\r\":\n        case \"\\u2028\":\n        case \"\\u2029\":\n          return false;\n        default:\n          return true;\n      }\n    }\n    parseHexDigits(howMany) {\n      let hexString = \"\";\n      for (let i = 0; i < howMany; i++) {\n        const hexChar = this.popChar();\n        if (hexDigitPattern.test(hexChar) === false) {\n          throw Error(\"Expecting a HexDecimal digits\");\n        }\n        hexString += hexChar;\n      }\n      const charCode = parseInt(hexString, 16);\n      return {\n        type: \"Character\",\n        value: charCode\n      };\n    }\n    peekChar(howMuch = 0) {\n      return this.input[this.idx + howMuch];\n    }\n    popChar() {\n      const nextChar = this.peekChar(0);\n      this.consumeChar(void 0);\n      return nextChar;\n    }\n    consumeChar(char) {\n      if (char !== void 0 && this.input[this.idx] !== char) {\n        throw Error(\"Expected: '\" + char + \"' but found: '\" + this.input[this.idx] + \"' at offset: \" + this.idx);\n      }\n      if (this.idx >= this.input.length) {\n        throw Error(\"Unexpected end of input\");\n      }\n      this.idx++;\n    }\n    loc(begin) {\n      return {\n        begin,\n        end: this.idx\n      };\n    }\n  }\n  class BaseRegExpVisitor {\n    visitChildren(node) {\n      for (const key in node) {\n        const child = node[key];\n        if (node.hasOwnProperty(key)) {\n          if (child.type !== void 0) {\n            this.visit(child);\n          } else if (Array.isArray(child)) {\n            child.forEach(subChild => {\n              this.visit(subChild);\n            }, this);\n          }\n        }\n      }\n    }\n    visit(node) {\n      switch (node.type) {\n        case \"Pattern\":\n          this.visitPattern(node);\n          break;\n        case \"Flags\":\n          this.visitFlags(node);\n          break;\n        case \"Disjunction\":\n          this.visitDisjunction(node);\n          break;\n        case \"Alternative\":\n          this.visitAlternative(node);\n          break;\n        case \"StartAnchor\":\n          this.visitStartAnchor(node);\n          break;\n        case \"EndAnchor\":\n          this.visitEndAnchor(node);\n          break;\n        case \"WordBoundary\":\n          this.visitWordBoundary(node);\n          break;\n        case \"NonWordBoundary\":\n          this.visitNonWordBoundary(node);\n          break;\n        case \"Lookahead\":\n          this.visitLookahead(node);\n          break;\n        case \"NegativeLookahead\":\n          this.visitNegativeLookahead(node);\n          break;\n        case \"Character\":\n          this.visitCharacter(node);\n          break;\n        case \"Set\":\n          this.visitSet(node);\n          break;\n        case \"Group\":\n          this.visitGroup(node);\n          break;\n        case \"GroupBackReference\":\n          this.visitGroupBackReference(node);\n          break;\n        case \"Quantifier\":\n          this.visitQuantifier(node);\n          break;\n      }\n      this.visitChildren(node);\n    }\n    visitPattern(node) {}\n    visitFlags(node) {}\n    visitDisjunction(node) {}\n    visitAlternative(node) {}\n    // Assertion\n    visitStartAnchor(node) {}\n    visitEndAnchor(node) {}\n    visitWordBoundary(node) {}\n    visitNonWordBoundary(node) {}\n    visitLookahead(node) {}\n    visitNegativeLookahead(node) {}\n    // atoms\n    visitCharacter(node) {}\n    visitSet(node) {}\n    visitGroup(node) {}\n    visitGroupBackReference(node) {}\n    visitQuantifier(node) {}\n  }\n  let regExpAstCache = {};\n  const regExpParser = new RegExpParser();\n  function getRegExpAst(regExp) {\n    const regExpStr = regExp.toString();\n    if (regExpAstCache.hasOwnProperty(regExpStr)) {\n      return regExpAstCache[regExpStr];\n    } else {\n      const regExpAst = regExpParser.pattern(regExpStr);\n      regExpAstCache[regExpStr] = regExpAst;\n      return regExpAst;\n    }\n  }\n  function clearRegExpParserCache() {\n    regExpAstCache = {};\n  }\n  const complementErrorMessage = \"Complement Sets are not supported for first char optimization\";\n  const failedOptimizationPrefixMsg = 'Unable to use \"first char\" lexer optimizations:\\n';\n  function getOptimizedStartCodesIndices(regExp, ensureOptimizations = false) {\n    try {\n      const ast = getRegExpAst(regExp);\n      const firstChars = firstCharOptimizedIndices(ast.value, {}, ast.flags.ignoreCase);\n      return firstChars;\n    } catch (e) {\n      if (e.message === complementErrorMessage) {\n        if (ensureOptimizations) {\n          PRINT_WARNING(`${failedOptimizationPrefixMsg}\tUnable to optimize: < ${regExp.toString()} >\n\tComplement Sets cannot be automatically optimized.\n\tThis will disable the lexer's first char optimizations.\n\tSee: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#COMPLEMENT for details.`);\n        }\n      } else {\n        let msgSuffix = \"\";\n        if (ensureOptimizations) {\n          msgSuffix = \"\\n\tThis will disable the lexer's first char optimizations.\\n\tSee: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#REGEXP_PARSING for details.\";\n        }\n        PRINT_ERROR(`${failedOptimizationPrefixMsg}\n\tFailed parsing: < ${regExp.toString()} >\n\tUsing the @chevrotain/regexp-to-ast library\n\tPlease open an issue at: https://github.com/chevrotain/chevrotain/issues` + msgSuffix);\n      }\n    }\n    return [];\n  }\n  function firstCharOptimizedIndices(ast, result, ignoreCase) {\n    switch (ast.type) {\n      case \"Disjunction\":\n        for (let i = 0; i < ast.value.length; i++) {\n          firstCharOptimizedIndices(ast.value[i], result, ignoreCase);\n        }\n        break;\n      case \"Alternative\":\n        const terms = ast.value;\n        for (let i = 0; i < terms.length; i++) {\n          const term = terms[i];\n          switch (term.type) {\n            case \"EndAnchor\":\n            case \"GroupBackReference\":\n            case \"Lookahead\":\n            case \"NegativeLookahead\":\n            case \"StartAnchor\":\n            case \"WordBoundary\":\n            case \"NonWordBoundary\":\n              continue;\n          }\n          const atom = term;\n          switch (atom.type) {\n            case \"Character\":\n              addOptimizedIdxToResult(atom.value, result, ignoreCase);\n              break;\n            case \"Set\":\n              if (atom.complement === true) {\n                throw Error(complementErrorMessage);\n              }\n              forEach(atom.value, code => {\n                if (typeof code === \"number\") {\n                  addOptimizedIdxToResult(code, result, ignoreCase);\n                } else {\n                  const range = code;\n                  if (ignoreCase === true) {\n                    for (let rangeCode = range.from; rangeCode <= range.to; rangeCode++) {\n                      addOptimizedIdxToResult(rangeCode, result, ignoreCase);\n                    }\n                  } else {\n                    for (let rangeCode = range.from; rangeCode <= range.to && rangeCode < minOptimizationVal; rangeCode++) {\n                      addOptimizedIdxToResult(rangeCode, result, ignoreCase);\n                    }\n                    if (range.to >= minOptimizationVal) {\n                      const minUnOptVal = range.from >= minOptimizationVal ? range.from : minOptimizationVal;\n                      const maxUnOptVal = range.to;\n                      const minOptIdx = charCodeToOptimizedIndex(minUnOptVal);\n                      const maxOptIdx = charCodeToOptimizedIndex(maxUnOptVal);\n                      for (let currOptIdx = minOptIdx; currOptIdx <= maxOptIdx; currOptIdx++) {\n                        result[currOptIdx] = currOptIdx;\n                      }\n                    }\n                  }\n                }\n              });\n              break;\n            case \"Group\":\n              firstCharOptimizedIndices(atom.value, result, ignoreCase);\n              break;\n            default:\n              throw Error(\"Non Exhaustive Match\");\n          }\n          const isOptionalQuantifier = atom.quantifier !== void 0 && atom.quantifier.atLeast === 0;\n          if (\n          // A group may be optional due to empty contents /(?:)/\n          // or if everything inside it is optional /((a)?)/\n          atom.type === \"Group\" && isWholeOptional(atom) === false ||\n          // If this term is not a group it may only be optional if it has an optional quantifier\n          atom.type !== \"Group\" && isOptionalQuantifier === false) {\n            break;\n          }\n        }\n        break;\n      default:\n        throw Error(\"non exhaustive match!\");\n    }\n    return values(result);\n  }\n  function addOptimizedIdxToResult(code, result, ignoreCase) {\n    const optimizedCharIdx = charCodeToOptimizedIndex(code);\n    result[optimizedCharIdx] = optimizedCharIdx;\n    if (ignoreCase === true) {\n      handleIgnoreCase(code, result);\n    }\n  }\n  function handleIgnoreCase(code, result) {\n    const char = String.fromCharCode(code);\n    const upperChar = char.toUpperCase();\n    if (upperChar !== char) {\n      const optimizedCharIdx = charCodeToOptimizedIndex(upperChar.charCodeAt(0));\n      result[optimizedCharIdx] = optimizedCharIdx;\n    } else {\n      const lowerChar = char.toLowerCase();\n      if (lowerChar !== char) {\n        const optimizedCharIdx = charCodeToOptimizedIndex(lowerChar.charCodeAt(0));\n        result[optimizedCharIdx] = optimizedCharIdx;\n      }\n    }\n  }\n  function findCode(setNode, targetCharCodes) {\n    return find$1(setNode.value, codeOrRange => {\n      if (typeof codeOrRange === \"number\") {\n        return includes(targetCharCodes, codeOrRange);\n      } else {\n        const range = codeOrRange;\n        return find$1(targetCharCodes, targetCode => range.from <= targetCode && targetCode <= range.to) !== void 0;\n      }\n    });\n  }\n  function isWholeOptional(ast) {\n    const quantifier = ast.quantifier;\n    if (quantifier && quantifier.atLeast === 0) {\n      return true;\n    }\n    if (!ast.value) {\n      return false;\n    }\n    return isArray$1(ast.value) ? every(ast.value, isWholeOptional) : isWholeOptional(ast.value);\n  }\n  class CharCodeFinder extends BaseRegExpVisitor {\n    constructor(targetCharCodes) {\n      super();\n      this.targetCharCodes = targetCharCodes;\n      this.found = false;\n    }\n    visitChildren(node) {\n      if (this.found === true) {\n        return;\n      }\n      switch (node.type) {\n        case \"Lookahead\":\n          this.visitLookahead(node);\n          return;\n        case \"NegativeLookahead\":\n          this.visitNegativeLookahead(node);\n          return;\n      }\n      super.visitChildren(node);\n    }\n    visitCharacter(node) {\n      if (includes(this.targetCharCodes, node.value)) {\n        this.found = true;\n      }\n    }\n    visitSet(node) {\n      if (node.complement) {\n        if (findCode(node, this.targetCharCodes) === void 0) {\n          this.found = true;\n        }\n      } else {\n        if (findCode(node, this.targetCharCodes) !== void 0) {\n          this.found = true;\n        }\n      }\n    }\n  }\n  function canMatchCharCode(charCodes, pattern) {\n    if (pattern instanceof RegExp) {\n      const ast = getRegExpAst(pattern);\n      const charCodeFinder = new CharCodeFinder(charCodes);\n      charCodeFinder.visit(ast);\n      return charCodeFinder.found;\n    } else {\n      return find$1(pattern, char => {\n        return includes(charCodes, char.charCodeAt(0));\n      }) !== void 0;\n    }\n  }\n  const PATTERN = \"PATTERN\";\n  const DEFAULT_MODE = \"defaultMode\";\n  const MODES = \"modes\";\n  let SUPPORT_STICKY = typeof new RegExp(\"(?:)\").sticky === \"boolean\";\n  function analyzeTokenTypes(tokenTypes, options) {\n    options = defaults$1(options, {\n      useSticky: SUPPORT_STICKY,\n      debug: false,\n      safeMode: false,\n      positionTracking: \"full\",\n      lineTerminatorCharacters: [\"\\r\", \"\\n\"],\n      tracer: (msg, action) => action()\n    });\n    const tracer = options.tracer;\n    tracer(\"initCharCodeToOptimizedIndexMap\", () => {\n      initCharCodeToOptimizedIndexMap();\n    });\n    let onlyRelevantTypes;\n    tracer(\"Reject Lexer.NA\", () => {\n      onlyRelevantTypes = reject(tokenTypes, currType => {\n        return currType[PATTERN] === Lexer2.NA;\n      });\n    });\n    let hasCustom = false;\n    let allTransformedPatterns;\n    tracer(\"Transform Patterns\", () => {\n      hasCustom = false;\n      allTransformedPatterns = map(onlyRelevantTypes, currType => {\n        const currPattern = currType[PATTERN];\n        if (isRegExp$1(currPattern)) {\n          const regExpSource = currPattern.source;\n          if (regExpSource.length === 1 &&\n          // only these regExp meta characters which can appear in a length one regExp\n          regExpSource !== \"^\" && regExpSource !== \"$\" && regExpSource !== \".\" && !currPattern.ignoreCase) {\n            return regExpSource;\n          } else if (regExpSource.length === 2 && regExpSource[0] === \"\\\\\" &&\n          // not a meta character\n          !includes([\"d\", \"D\", \"s\", \"S\", \"t\", \"r\", \"n\", \"t\", \"0\", \"c\", \"b\", \"B\", \"f\", \"v\", \"w\", \"W\"], regExpSource[1])) {\n            return regExpSource[1];\n          } else {\n            return options.useSticky ? addStickyFlag(currPattern) : addStartOfInput(currPattern);\n          }\n        } else if (isFunction(currPattern)) {\n          hasCustom = true;\n          return {\n            exec: currPattern\n          };\n        } else if (typeof currPattern === \"object\") {\n          hasCustom = true;\n          return currPattern;\n        } else if (typeof currPattern === \"string\") {\n          if (currPattern.length === 1) {\n            return currPattern;\n          } else {\n            const escapedRegExpString = currPattern.replace(/[\\\\^$.*+?()[\\]{}|]/g, \"\\\\$&\");\n            const wrappedRegExp = new RegExp(escapedRegExpString);\n            return options.useSticky ? addStickyFlag(wrappedRegExp) : addStartOfInput(wrappedRegExp);\n          }\n        } else {\n          throw Error(\"non exhaustive match\");\n        }\n      });\n    });\n    let patternIdxToType;\n    let patternIdxToGroup;\n    let patternIdxToLongerAltIdxArr;\n    let patternIdxToPushMode;\n    let patternIdxToPopMode;\n    tracer(\"misc mapping\", () => {\n      patternIdxToType = map(onlyRelevantTypes, currType => currType.tokenTypeIdx);\n      patternIdxToGroup = map(onlyRelevantTypes, clazz => {\n        const groupName = clazz.GROUP;\n        if (groupName === Lexer2.SKIPPED) {\n          return void 0;\n        } else if (isString(groupName)) {\n          return groupName;\n        } else if (isUndefined(groupName)) {\n          return false;\n        } else {\n          throw Error(\"non exhaustive match\");\n        }\n      });\n      patternIdxToLongerAltIdxArr = map(onlyRelevantTypes, clazz => {\n        const longerAltType = clazz.LONGER_ALT;\n        if (longerAltType) {\n          const longerAltIdxArr = isArray$1(longerAltType) ? map(longerAltType, type => indexOf(onlyRelevantTypes, type)) : [indexOf(onlyRelevantTypes, longerAltType)];\n          return longerAltIdxArr;\n        }\n      });\n      patternIdxToPushMode = map(onlyRelevantTypes, clazz => clazz.PUSH_MODE);\n      patternIdxToPopMode = map(onlyRelevantTypes, clazz => has(clazz, \"POP_MODE\"));\n    });\n    let patternIdxToCanLineTerminator;\n    tracer(\"Line Terminator Handling\", () => {\n      const lineTerminatorCharCodes = getCharCodes(options.lineTerminatorCharacters);\n      patternIdxToCanLineTerminator = map(onlyRelevantTypes, tokType => false);\n      if (options.positionTracking !== \"onlyOffset\") {\n        patternIdxToCanLineTerminator = map(onlyRelevantTypes, tokType => {\n          if (has(tokType, \"LINE_BREAKS\")) {\n            return !!tokType.LINE_BREAKS;\n          } else {\n            return checkLineBreaksIssues(tokType, lineTerminatorCharCodes) === false && canMatchCharCode(lineTerminatorCharCodes, tokType.PATTERN);\n          }\n        });\n      }\n    });\n    let patternIdxToIsCustom;\n    let patternIdxToShort;\n    let emptyGroups;\n    let patternIdxToConfig;\n    tracer(\"Misc Mapping #2\", () => {\n      patternIdxToIsCustom = map(onlyRelevantTypes, isCustomPattern);\n      patternIdxToShort = map(allTransformedPatterns, isShortPattern);\n      emptyGroups = reduce(onlyRelevantTypes, (acc, clazz) => {\n        const groupName = clazz.GROUP;\n        if (isString(groupName) && !(groupName === Lexer2.SKIPPED)) {\n          acc[groupName] = [];\n        }\n        return acc;\n      }, {});\n      patternIdxToConfig = map(allTransformedPatterns, (x, idx) => {\n        return {\n          pattern: allTransformedPatterns[idx],\n          longerAlt: patternIdxToLongerAltIdxArr[idx],\n          canLineTerminator: patternIdxToCanLineTerminator[idx],\n          isCustom: patternIdxToIsCustom[idx],\n          short: patternIdxToShort[idx],\n          group: patternIdxToGroup[idx],\n          push: patternIdxToPushMode[idx],\n          pop: patternIdxToPopMode[idx],\n          tokenTypeIdx: patternIdxToType[idx],\n          tokenType: onlyRelevantTypes[idx]\n        };\n      });\n    });\n    let canBeOptimized = true;\n    let charCodeToPatternIdxToConfig = [];\n    if (!options.safeMode) {\n      tracer(\"First Char Optimization\", () => {\n        charCodeToPatternIdxToConfig = reduce(onlyRelevantTypes, (result, currTokType, idx) => {\n          if (typeof currTokType.PATTERN === \"string\") {\n            const charCode = currTokType.PATTERN.charCodeAt(0);\n            const optimizedIdx = charCodeToOptimizedIndex(charCode);\n            addToMapOfArrays(result, optimizedIdx, patternIdxToConfig[idx]);\n          } else if (isArray$1(currTokType.START_CHARS_HINT)) {\n            let lastOptimizedIdx;\n            forEach(currTokType.START_CHARS_HINT, charOrInt => {\n              const charCode = typeof charOrInt === \"string\" ? charOrInt.charCodeAt(0) : charOrInt;\n              const currOptimizedIdx = charCodeToOptimizedIndex(charCode);\n              if (lastOptimizedIdx !== currOptimizedIdx) {\n                lastOptimizedIdx = currOptimizedIdx;\n                addToMapOfArrays(result, currOptimizedIdx, patternIdxToConfig[idx]);\n              }\n            });\n          } else if (isRegExp$1(currTokType.PATTERN)) {\n            if (currTokType.PATTERN.unicode) {\n              canBeOptimized = false;\n              if (options.ensureOptimizations) {\n                PRINT_ERROR(`${failedOptimizationPrefixMsg}\tUnable to analyze < ${currTokType.PATTERN.toString()} > pattern.\n\tThe regexp unicode flag is not currently supported by the regexp-to-ast library.\n\tThis will disable the lexer's first char optimizations.\n\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNICODE_OPTIMIZE`);\n              }\n            } else {\n              const optimizedCodes = getOptimizedStartCodesIndices(currTokType.PATTERN, options.ensureOptimizations);\n              if (isEmpty(optimizedCodes)) {\n                canBeOptimized = false;\n              }\n              forEach(optimizedCodes, code => {\n                addToMapOfArrays(result, code, patternIdxToConfig[idx]);\n              });\n            }\n          } else {\n            if (options.ensureOptimizations) {\n              PRINT_ERROR(`${failedOptimizationPrefixMsg}\tTokenType: <${currTokType.name}> is using a custom token pattern without providing <start_chars_hint> parameter.\n\tThis will disable the lexer's first char optimizations.\n\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_OPTIMIZE`);\n            }\n            canBeOptimized = false;\n          }\n          return result;\n        }, []);\n      });\n    }\n    return {\n      emptyGroups,\n      patternIdxToConfig,\n      charCodeToPatternIdxToConfig,\n      hasCustom,\n      canBeOptimized\n    };\n  }\n  function validatePatterns(tokenTypes, validModesNames) {\n    let errors = [];\n    const missingResult = findMissingPatterns(tokenTypes);\n    errors = errors.concat(missingResult.errors);\n    const invalidResult = findInvalidPatterns(missingResult.valid);\n    const validTokenTypes = invalidResult.valid;\n    errors = errors.concat(invalidResult.errors);\n    errors = errors.concat(validateRegExpPattern(validTokenTypes));\n    errors = errors.concat(findInvalidGroupType(validTokenTypes));\n    errors = errors.concat(findModesThatDoNotExist(validTokenTypes, validModesNames));\n    errors = errors.concat(findUnreachablePatterns(validTokenTypes));\n    return errors;\n  }\n  function validateRegExpPattern(tokenTypes) {\n    let errors = [];\n    const withRegExpPatterns = filter(tokenTypes, currTokType => isRegExp$1(currTokType[PATTERN]));\n    errors = errors.concat(findEndOfInputAnchor(withRegExpPatterns));\n    errors = errors.concat(findStartOfInputAnchor(withRegExpPatterns));\n    errors = errors.concat(findUnsupportedFlags(withRegExpPatterns));\n    errors = errors.concat(findDuplicatePatterns(withRegExpPatterns));\n    errors = errors.concat(findEmptyMatchRegExps(withRegExpPatterns));\n    return errors;\n  }\n  function findMissingPatterns(tokenTypes) {\n    const tokenTypesWithMissingPattern = filter(tokenTypes, currType => {\n      return !has(currType, PATTERN);\n    });\n    const errors = map(tokenTypesWithMissingPattern, currType => {\n      return {\n        message: \"Token Type: ->\" + currType.name + \"<- missing static 'PATTERN' property\",\n        type: LexerDefinitionErrorType.MISSING_PATTERN,\n        tokenTypes: [currType]\n      };\n    });\n    const valid = difference$1(tokenTypes, tokenTypesWithMissingPattern);\n    return {\n      errors,\n      valid\n    };\n  }\n  function findInvalidPatterns(tokenTypes) {\n    const tokenTypesWithInvalidPattern = filter(tokenTypes, currType => {\n      const pattern = currType[PATTERN];\n      return !isRegExp$1(pattern) && !isFunction(pattern) && !has(pattern, \"exec\") && !isString(pattern);\n    });\n    const errors = map(tokenTypesWithInvalidPattern, currType => {\n      return {\n        message: \"Token Type: ->\" + currType.name + \"<- static 'PATTERN' can only be a RegExp, a Function matching the {CustomPatternMatcherFunc} type or an Object matching the {ICustomPattern} interface.\",\n        type: LexerDefinitionErrorType.INVALID_PATTERN,\n        tokenTypes: [currType]\n      };\n    });\n    const valid = difference$1(tokenTypes, tokenTypesWithInvalidPattern);\n    return {\n      errors,\n      valid\n    };\n  }\n  const end_of_input = /[^\\\\][$]/;\n  function findEndOfInputAnchor(tokenTypes) {\n    class EndAnchorFinder extends BaseRegExpVisitor {\n      constructor() {\n        super(...arguments);\n        this.found = false;\n      }\n      visitEndAnchor(node) {\n        this.found = true;\n      }\n    }\n    const invalidRegex = filter(tokenTypes, currType => {\n      const pattern = currType.PATTERN;\n      try {\n        const regexpAst = getRegExpAst(pattern);\n        const endAnchorVisitor = new EndAnchorFinder();\n        endAnchorVisitor.visit(regexpAst);\n        return endAnchorVisitor.found;\n      } catch (e) {\n        return end_of_input.test(pattern.source);\n      }\n    });\n    const errors = map(invalidRegex, currType => {\n      return {\n        message: \"Unexpected RegExp Anchor Error:\\n\tToken Type: ->\" + currType.name + \"<- static 'PATTERN' cannot contain end of input anchor '$'\\n\tSee chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\tfor details.\",\n        type: LexerDefinitionErrorType.EOI_ANCHOR_FOUND,\n        tokenTypes: [currType]\n      };\n    });\n    return errors;\n  }\n  function findEmptyMatchRegExps(tokenTypes) {\n    const matchesEmptyString = filter(tokenTypes, currType => {\n      const pattern = currType.PATTERN;\n      return pattern.test(\"\");\n    });\n    const errors = map(matchesEmptyString, currType => {\n      return {\n        message: \"Token Type: ->\" + currType.name + \"<- static 'PATTERN' must not match an empty string\",\n        type: LexerDefinitionErrorType.EMPTY_MATCH_PATTERN,\n        tokenTypes: [currType]\n      };\n    });\n    return errors;\n  }\n  const start_of_input = /[^\\\\[][\\^]|^\\^/;\n  function findStartOfInputAnchor(tokenTypes) {\n    class StartAnchorFinder extends BaseRegExpVisitor {\n      constructor() {\n        super(...arguments);\n        this.found = false;\n      }\n      visitStartAnchor(node) {\n        this.found = true;\n      }\n    }\n    const invalidRegex = filter(tokenTypes, currType => {\n      const pattern = currType.PATTERN;\n      try {\n        const regexpAst = getRegExpAst(pattern);\n        const startAnchorVisitor = new StartAnchorFinder();\n        startAnchorVisitor.visit(regexpAst);\n        return startAnchorVisitor.found;\n      } catch (e) {\n        return start_of_input.test(pattern.source);\n      }\n    });\n    const errors = map(invalidRegex, currType => {\n      return {\n        message: \"Unexpected RegExp Anchor Error:\\n\tToken Type: ->\" + currType.name + \"<- static 'PATTERN' cannot contain start of input anchor '^'\\n\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\tfor details.\",\n        type: LexerDefinitionErrorType.SOI_ANCHOR_FOUND,\n        tokenTypes: [currType]\n      };\n    });\n    return errors;\n  }\n  function findUnsupportedFlags(tokenTypes) {\n    const invalidFlags = filter(tokenTypes, currType => {\n      const pattern = currType[PATTERN];\n      return pattern instanceof RegExp && (pattern.multiline || pattern.global);\n    });\n    const errors = map(invalidFlags, currType => {\n      return {\n        message: \"Token Type: ->\" + currType.name + \"<- static 'PATTERN' may NOT contain global('g') or multiline('m')\",\n        type: LexerDefinitionErrorType.UNSUPPORTED_FLAGS_FOUND,\n        tokenTypes: [currType]\n      };\n    });\n    return errors;\n  }\n  function findDuplicatePatterns(tokenTypes) {\n    const found = [];\n    let identicalPatterns = map(tokenTypes, outerType => {\n      return reduce(tokenTypes, (result, innerType) => {\n        if (outerType.PATTERN.source === innerType.PATTERN.source && !includes(found, innerType) && innerType.PATTERN !== Lexer2.NA) {\n          found.push(innerType);\n          result.push(innerType);\n          return result;\n        }\n        return result;\n      }, []);\n    });\n    identicalPatterns = compact(identicalPatterns);\n    const duplicatePatterns = filter(identicalPatterns, currIdenticalSet => {\n      return currIdenticalSet.length > 1;\n    });\n    const errors = map(duplicatePatterns, setOfIdentical => {\n      const tokenTypeNames = map(setOfIdentical, currType => {\n        return currType.name;\n      });\n      const dupPatternSrc = head(setOfIdentical).PATTERN;\n      return {\n        message: `The same RegExp pattern ->${dupPatternSrc}<-has been used in all of the following Token Types: ${tokenTypeNames.join(\", \")} <-`,\n        type: LexerDefinitionErrorType.DUPLICATE_PATTERNS_FOUND,\n        tokenTypes: setOfIdentical\n      };\n    });\n    return errors;\n  }\n  function findInvalidGroupType(tokenTypes) {\n    const invalidTypes = filter(tokenTypes, clazz => {\n      if (!has(clazz, \"GROUP\")) {\n        return false;\n      }\n      const group = clazz.GROUP;\n      return group !== Lexer2.SKIPPED && group !== Lexer2.NA && !isString(group);\n    });\n    const errors = map(invalidTypes, currType => {\n      return {\n        message: \"Token Type: ->\" + currType.name + \"<- static 'GROUP' can only be Lexer.SKIPPED/Lexer.NA/A String\",\n        type: LexerDefinitionErrorType.INVALID_GROUP_TYPE_FOUND,\n        tokenTypes: [currType]\n      };\n    });\n    return errors;\n  }\n  function findModesThatDoNotExist(tokenTypes, validModes) {\n    const invalidModes = filter(tokenTypes, clazz => {\n      return clazz.PUSH_MODE !== void 0 && !includes(validModes, clazz.PUSH_MODE);\n    });\n    const errors = map(invalidModes, tokType => {\n      const msg = `Token Type: ->${tokType.name}<- static 'PUSH_MODE' value cannot refer to a Lexer Mode ->${tokType.PUSH_MODE}<-which does not exist`;\n      return {\n        message: msg,\n        type: LexerDefinitionErrorType.PUSH_MODE_DOES_NOT_EXIST,\n        tokenTypes: [tokType]\n      };\n    });\n    return errors;\n  }\n  function findUnreachablePatterns(tokenTypes) {\n    const errors = [];\n    const canBeTested = reduce(tokenTypes, (result, tokType, idx) => {\n      const pattern = tokType.PATTERN;\n      if (pattern === Lexer2.NA) {\n        return result;\n      }\n      if (isString(pattern)) {\n        result.push({\n          str: pattern,\n          idx,\n          tokenType: tokType\n        });\n      } else if (isRegExp$1(pattern) && noMetaChar(pattern)) {\n        result.push({\n          str: pattern.source,\n          idx,\n          tokenType: tokType\n        });\n      }\n      return result;\n    }, []);\n    forEach(tokenTypes, (tokType, testIdx) => {\n      forEach(canBeTested, ({\n        str,\n        idx,\n        tokenType\n      }) => {\n        if (testIdx < idx && testTokenType(str, tokType.PATTERN)) {\n          const msg = `Token: ->${tokenType.name}<- can never be matched.\nBecause it appears AFTER the Token Type ->${tokType.name}<-in the lexer's definition.\nSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNREACHABLE`;\n          errors.push({\n            message: msg,\n            type: LexerDefinitionErrorType.UNREACHABLE_PATTERN,\n            tokenTypes: [tokType, tokenType]\n          });\n        }\n      });\n    });\n    return errors;\n  }\n  function testTokenType(str, pattern) {\n    if (isRegExp$1(pattern)) {\n      const regExpArray = pattern.exec(str);\n      return regExpArray !== null && regExpArray.index === 0;\n    } else if (isFunction(pattern)) {\n      return pattern(str, 0, [], {});\n    } else if (has(pattern, \"exec\")) {\n      return pattern.exec(str, 0, [], {});\n    } else if (typeof pattern === \"string\") {\n      return pattern === str;\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  }\n  function noMetaChar(regExp) {\n    const metaChars = [\".\", \"\\\\\", \"[\", \"]\", \"|\", \"^\", \"$\", \"(\", \")\", \"?\", \"*\", \"+\", \"{\"];\n    return find$1(metaChars, char => regExp.source.indexOf(char) !== -1) === void 0;\n  }\n  function addStartOfInput(pattern) {\n    const flags = pattern.ignoreCase ? \"i\" : \"\";\n    return new RegExp(`^(?:${pattern.source})`, flags);\n  }\n  function addStickyFlag(pattern) {\n    const flags = pattern.ignoreCase ? \"iy\" : \"y\";\n    return new RegExp(`${pattern.source}`, flags);\n  }\n  function performRuntimeChecks(lexerDefinition, trackLines, lineTerminatorCharacters) {\n    const errors = [];\n    if (!has(lexerDefinition, DEFAULT_MODE)) {\n      errors.push({\n        message: \"A MultiMode Lexer cannot be initialized without a <\" + DEFAULT_MODE + \"> property in its definition\\n\",\n        type: LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\n      });\n    }\n    if (!has(lexerDefinition, MODES)) {\n      errors.push({\n        message: \"A MultiMode Lexer cannot be initialized without a <\" + MODES + \"> property in its definition\\n\",\n        type: LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\n      });\n    }\n    if (has(lexerDefinition, MODES) && has(lexerDefinition, DEFAULT_MODE) && !has(lexerDefinition.modes, lexerDefinition.defaultMode)) {\n      errors.push({\n        message: `A MultiMode Lexer cannot be initialized with a ${DEFAULT_MODE}: <${lexerDefinition.defaultMode}>which does not exist\n`,\n        type: LexerDefinitionErrorType.MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\n      });\n    }\n    if (has(lexerDefinition, MODES)) {\n      forEach(lexerDefinition.modes, (currModeValue, currModeName) => {\n        forEach(currModeValue, (currTokType, currIdx) => {\n          if (isUndefined(currTokType)) {\n            errors.push({\n              message: `A Lexer cannot be initialized using an undefined Token Type. Mode:<${currModeName}> at index: <${currIdx}>\n`,\n              type: LexerDefinitionErrorType.LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\n            });\n          } else if (has(currTokType, \"LONGER_ALT\")) {\n            const longerAlt = isArray$1(currTokType.LONGER_ALT) ? currTokType.LONGER_ALT : [currTokType.LONGER_ALT];\n            forEach(longerAlt, currLongerAlt => {\n              if (!isUndefined(currLongerAlt) && !includes(currModeValue, currLongerAlt)) {\n                errors.push({\n                  message: `A MultiMode Lexer cannot be initialized with a longer_alt <${currLongerAlt.name}> on token <${currTokType.name}> outside of mode <${currModeName}>\n`,\n                  type: LexerDefinitionErrorType.MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE\n                });\n              }\n            });\n          }\n        });\n      });\n    }\n    return errors;\n  }\n  function performWarningRuntimeChecks(lexerDefinition, trackLines, lineTerminatorCharacters) {\n    const warnings = [];\n    let hasAnyLineBreak = false;\n    const allTokenTypes = compact(flatten(values(lexerDefinition.modes)));\n    const concreteTokenTypes = reject(allTokenTypes, currType => currType[PATTERN] === Lexer2.NA);\n    const terminatorCharCodes = getCharCodes(lineTerminatorCharacters);\n    if (trackLines) {\n      forEach(concreteTokenTypes, tokType => {\n        const currIssue = checkLineBreaksIssues(tokType, terminatorCharCodes);\n        if (currIssue !== false) {\n          const message = buildLineBreakIssueMessage(tokType, currIssue);\n          const warningDescriptor = {\n            message,\n            type: currIssue.issue,\n            tokenType: tokType\n          };\n          warnings.push(warningDescriptor);\n        } else {\n          if (has(tokType, \"LINE_BREAKS\")) {\n            if (tokType.LINE_BREAKS === true) {\n              hasAnyLineBreak = true;\n            }\n          } else {\n            if (canMatchCharCode(terminatorCharCodes, tokType.PATTERN)) {\n              hasAnyLineBreak = true;\n            }\n          }\n        }\n      });\n    }\n    if (trackLines && !hasAnyLineBreak) {\n      warnings.push({\n        message: \"Warning: No LINE_BREAKS Found.\\n\tThis Lexer has been defined to track line and column information,\\n\tBut none of the Token Types can be identified as matching a line terminator.\\n\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#LINE_BREAKS \\n\tfor details.\",\n        type: LexerDefinitionErrorType.NO_LINE_BREAKS_FLAGS\n      });\n    }\n    return warnings;\n  }\n  function cloneEmptyGroups(emptyGroups) {\n    const clonedResult = {};\n    const groupKeys = keys(emptyGroups);\n    forEach(groupKeys, currKey => {\n      const currGroupValue = emptyGroups[currKey];\n      if (isArray$1(currGroupValue)) {\n        clonedResult[currKey] = [];\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    });\n    return clonedResult;\n  }\n  function isCustomPattern(tokenType) {\n    const pattern = tokenType.PATTERN;\n    if (isRegExp$1(pattern)) {\n      return false;\n    } else if (isFunction(pattern)) {\n      return true;\n    } else if (has(pattern, \"exec\")) {\n      return true;\n    } else if (isString(pattern)) {\n      return false;\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  }\n  function isShortPattern(pattern) {\n    if (isString(pattern) && pattern.length === 1) {\n      return pattern.charCodeAt(0);\n    } else {\n      return false;\n    }\n  }\n  const LineTerminatorOptimizedTester = {\n    // implements /\\n|\\r\\n?/g.test\n    test: function (text) {\n      const len = text.length;\n      for (let i = this.lastIndex; i < len; i++) {\n        const c = text.charCodeAt(i);\n        if (c === 10) {\n          this.lastIndex = i + 1;\n          return true;\n        } else if (c === 13) {\n          if (text.charCodeAt(i + 1) === 10) {\n            this.lastIndex = i + 2;\n          } else {\n            this.lastIndex = i + 1;\n          }\n          return true;\n        }\n      }\n      return false;\n    },\n    lastIndex: 0\n  };\n  function checkLineBreaksIssues(tokType, lineTerminatorCharCodes) {\n    if (has(tokType, \"LINE_BREAKS\")) {\n      return false;\n    } else {\n      if (isRegExp$1(tokType.PATTERN)) {\n        try {\n          canMatchCharCode(lineTerminatorCharCodes, tokType.PATTERN);\n        } catch (e) {\n          return {\n            issue: LexerDefinitionErrorType.IDENTIFY_TERMINATOR,\n            errMsg: e.message\n          };\n        }\n        return false;\n      } else if (isString(tokType.PATTERN)) {\n        return false;\n      } else if (isCustomPattern(tokType)) {\n        return {\n          issue: LexerDefinitionErrorType.CUSTOM_LINE_BREAK\n        };\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    }\n  }\n  function buildLineBreakIssueMessage(tokType, details) {\n    if (details.issue === LexerDefinitionErrorType.IDENTIFY_TERMINATOR) {\n      return `Warning: unable to identify line terminator usage in pattern.\n\tThe problem is in the <${tokType.name}> Token Type\n\t Root cause: ${details.errMsg}.\n\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#IDENTIFY_TERMINATOR`;\n    } else if (details.issue === LexerDefinitionErrorType.CUSTOM_LINE_BREAK) {\n      return `Warning: A Custom Token Pattern should specify the <line_breaks> option.\n\tThe problem is in the <${tokType.name}> Token Type\n\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_LINE_BREAK`;\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  }\n  function getCharCodes(charsOrCodes) {\n    const charCodes = map(charsOrCodes, numOrString => {\n      if (isString(numOrString)) {\n        return numOrString.charCodeAt(0);\n      } else {\n        return numOrString;\n      }\n    });\n    return charCodes;\n  }\n  function addToMapOfArrays(map2, key, value) {\n    if (map2[key] === void 0) {\n      map2[key] = [value];\n    } else {\n      map2[key].push(value);\n    }\n  }\n  const minOptimizationVal = 256;\n  let charCodeToOptimizedIdxMap = [];\n  function charCodeToOptimizedIndex(charCode) {\n    return charCode < minOptimizationVal ? charCode : charCodeToOptimizedIdxMap[charCode];\n  }\n  function initCharCodeToOptimizedIndexMap() {\n    if (isEmpty(charCodeToOptimizedIdxMap)) {\n      charCodeToOptimizedIdxMap = new Array(65536);\n      for (let i = 0; i < 65536; i++) {\n        charCodeToOptimizedIdxMap[i] = i > 255 ? 255 + ~~(i / 255) : i;\n      }\n    }\n  }\n  function tokenStructuredMatcher(tokInstance, tokConstructor) {\n    const instanceType = tokInstance.tokenTypeIdx;\n    if (instanceType === tokConstructor.tokenTypeIdx) {\n      return true;\n    } else {\n      return tokConstructor.isParent === true && tokConstructor.categoryMatchesMap[instanceType] === true;\n    }\n  }\n  function tokenStructuredMatcherNoCategories(token, tokType) {\n    return token.tokenTypeIdx === tokType.tokenTypeIdx;\n  }\n  let tokenShortNameIdx = 1;\n  const tokenIdxToClass = {};\n  function augmentTokenTypes(tokenTypes) {\n    const tokenTypesAndParents = expandCategories(tokenTypes);\n    assignTokenDefaultProps(tokenTypesAndParents);\n    assignCategoriesMapProp(tokenTypesAndParents);\n    assignCategoriesTokensProp(tokenTypesAndParents);\n    forEach(tokenTypesAndParents, tokType => {\n      tokType.isParent = tokType.categoryMatches.length > 0;\n    });\n  }\n  function expandCategories(tokenTypes) {\n    let result = clone(tokenTypes);\n    let categories = tokenTypes;\n    let searching = true;\n    while (searching) {\n      categories = compact(flatten(map(categories, currTokType => currTokType.CATEGORIES)));\n      const newCategories = difference$1(categories, result);\n      result = result.concat(newCategories);\n      if (isEmpty(newCategories)) {\n        searching = false;\n      } else {\n        categories = newCategories;\n      }\n    }\n    return result;\n  }\n  function assignTokenDefaultProps(tokenTypes) {\n    forEach(tokenTypes, currTokType => {\n      if (!hasShortKeyProperty(currTokType)) {\n        tokenIdxToClass[tokenShortNameIdx] = currTokType;\n        currTokType.tokenTypeIdx = tokenShortNameIdx++;\n      }\n      if (hasCategoriesProperty(currTokType) && !isArray$1(currTokType.CATEGORIES)) {\n        currTokType.CATEGORIES = [currTokType.CATEGORIES];\n      }\n      if (!hasCategoriesProperty(currTokType)) {\n        currTokType.CATEGORIES = [];\n      }\n      if (!hasExtendingTokensTypesProperty(currTokType)) {\n        currTokType.categoryMatches = [];\n      }\n      if (!hasExtendingTokensTypesMapProperty(currTokType)) {\n        currTokType.categoryMatchesMap = {};\n      }\n    });\n  }\n  function assignCategoriesTokensProp(tokenTypes) {\n    forEach(tokenTypes, currTokType => {\n      currTokType.categoryMatches = [];\n      forEach(currTokType.categoryMatchesMap, (val, key) => {\n        currTokType.categoryMatches.push(tokenIdxToClass[key].tokenTypeIdx);\n      });\n    });\n  }\n  function assignCategoriesMapProp(tokenTypes) {\n    forEach(tokenTypes, currTokType => {\n      singleAssignCategoriesToksMap([], currTokType);\n    });\n  }\n  function singleAssignCategoriesToksMap(path, nextNode) {\n    forEach(path, pathNode => {\n      nextNode.categoryMatchesMap[pathNode.tokenTypeIdx] = true;\n    });\n    forEach(nextNode.CATEGORIES, nextCategory => {\n      const newPath = path.concat(nextNode);\n      if (!includes(newPath, nextCategory)) {\n        singleAssignCategoriesToksMap(newPath, nextCategory);\n      }\n    });\n  }\n  function hasShortKeyProperty(tokType) {\n    return has(tokType, \"tokenTypeIdx\");\n  }\n  function hasCategoriesProperty(tokType) {\n    return has(tokType, \"CATEGORIES\");\n  }\n  function hasExtendingTokensTypesProperty(tokType) {\n    return has(tokType, \"categoryMatches\");\n  }\n  function hasExtendingTokensTypesMapProperty(tokType) {\n    return has(tokType, \"categoryMatchesMap\");\n  }\n  function isTokenType(tokType) {\n    return has(tokType, \"tokenTypeIdx\");\n  }\n  const defaultLexerErrorProvider = {\n    buildUnableToPopLexerModeMessage(token) {\n      return `Unable to pop Lexer Mode after encountering Token ->${token.image}<- The Mode Stack is empty`;\n    },\n    buildUnexpectedCharactersMessage(fullText, startOffset, length, line, column) {\n      return `unexpected character: ->${fullText.charAt(startOffset)}<- at offset: ${startOffset}, skipped ${length} characters.`;\n    }\n  };\n  var LexerDefinitionErrorType;\n  (function (LexerDefinitionErrorType2) {\n    LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"MISSING_PATTERN\"] = 0] = \"MISSING_PATTERN\";\n    LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"INVALID_PATTERN\"] = 1] = \"INVALID_PATTERN\";\n    LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"EOI_ANCHOR_FOUND\"] = 2] = \"EOI_ANCHOR_FOUND\";\n    LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"UNSUPPORTED_FLAGS_FOUND\"] = 3] = \"UNSUPPORTED_FLAGS_FOUND\";\n    LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"DUPLICATE_PATTERNS_FOUND\"] = 4] = \"DUPLICATE_PATTERNS_FOUND\";\n    LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"INVALID_GROUP_TYPE_FOUND\"] = 5] = \"INVALID_GROUP_TYPE_FOUND\";\n    LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"PUSH_MODE_DOES_NOT_EXIST\"] = 6] = \"PUSH_MODE_DOES_NOT_EXIST\";\n    LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\"] = 7] = \"MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\";\n    LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\"] = 8] = \"MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\";\n    LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\"] = 9] = \"MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\";\n    LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\"] = 10] = \"LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\";\n    LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"SOI_ANCHOR_FOUND\"] = 11] = \"SOI_ANCHOR_FOUND\";\n    LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"EMPTY_MATCH_PATTERN\"] = 12] = \"EMPTY_MATCH_PATTERN\";\n    LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"NO_LINE_BREAKS_FLAGS\"] = 13] = \"NO_LINE_BREAKS_FLAGS\";\n    LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"UNREACHABLE_PATTERN\"] = 14] = \"UNREACHABLE_PATTERN\";\n    LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"IDENTIFY_TERMINATOR\"] = 15] = \"IDENTIFY_TERMINATOR\";\n    LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"CUSTOM_LINE_BREAK\"] = 16] = \"CUSTOM_LINE_BREAK\";\n    LexerDefinitionErrorType2[LexerDefinitionErrorType2[\"MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE\"] = 17] = \"MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE\";\n  })(LexerDefinitionErrorType || (LexerDefinitionErrorType = {}));\n  const DEFAULT_LEXER_CONFIG = {\n    deferDefinitionErrorsHandling: false,\n    positionTracking: \"full\",\n    lineTerminatorsPattern: /\\n|\\r\\n?/g,\n    lineTerminatorCharacters: [\"\\n\", \"\\r\"],\n    ensureOptimizations: false,\n    safeMode: false,\n    errorMessageProvider: defaultLexerErrorProvider,\n    traceInitPerf: false,\n    skipValidations: false,\n    recoveryEnabled: true\n  };\n  Object.freeze(DEFAULT_LEXER_CONFIG);\n  class Lexer2 {\n    constructor(lexerDefinition, config = DEFAULT_LEXER_CONFIG) {\n      this.lexerDefinition = lexerDefinition;\n      this.lexerDefinitionErrors = [];\n      this.lexerDefinitionWarning = [];\n      this.patternIdxToConfig = {};\n      this.charCodeToPatternIdxToConfig = {};\n      this.modes = [];\n      this.emptyGroups = {};\n      this.trackStartLines = true;\n      this.trackEndLines = true;\n      this.hasCustom = false;\n      this.canModeBeOptimized = {};\n      this.TRACE_INIT = (phaseDesc, phaseImpl) => {\n        if (this.traceInitPerf === true) {\n          this.traceInitIndent++;\n          const indent = new Array(this.traceInitIndent + 1).join(\"\t\");\n          if (this.traceInitIndent < this.traceInitMaxIdent) {\n            console.log(`${indent}--> <${phaseDesc}>`);\n          }\n          const {\n            time,\n            value\n          } = timer(phaseImpl);\n          const traceMethod = time > 10 ? console.warn : console.log;\n          if (this.traceInitIndent < this.traceInitMaxIdent) {\n            traceMethod(`${indent}<-- <${phaseDesc}> time: ${time}ms`);\n          }\n          this.traceInitIndent--;\n          return value;\n        } else {\n          return phaseImpl();\n        }\n      };\n      if (typeof config === \"boolean\") {\n        throw Error(\"The second argument to the Lexer constructor is now an ILexerConfig Object.\\na boolean 2nd argument is no longer supported\");\n      }\n      this.config = assign$1({}, DEFAULT_LEXER_CONFIG, config);\n      const traceInitVal = this.config.traceInitPerf;\n      if (traceInitVal === true) {\n        this.traceInitMaxIdent = Infinity;\n        this.traceInitPerf = true;\n      } else if (typeof traceInitVal === \"number\") {\n        this.traceInitMaxIdent = traceInitVal;\n        this.traceInitPerf = true;\n      }\n      this.traceInitIndent = -1;\n      this.TRACE_INIT(\"Lexer Constructor\", () => {\n        let actualDefinition;\n        let hasOnlySingleMode = true;\n        this.TRACE_INIT(\"Lexer Config handling\", () => {\n          if (this.config.lineTerminatorsPattern === DEFAULT_LEXER_CONFIG.lineTerminatorsPattern) {\n            this.config.lineTerminatorsPattern = LineTerminatorOptimizedTester;\n          } else {\n            if (this.config.lineTerminatorCharacters === DEFAULT_LEXER_CONFIG.lineTerminatorCharacters) {\n              throw Error(\"Error: Missing <lineTerminatorCharacters> property on the Lexer config.\\n\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#MISSING_LINE_TERM_CHARS\");\n            }\n          }\n          if (config.safeMode && config.ensureOptimizations) {\n            throw Error('\"safeMode\" and \"ensureOptimizations\" flags are mutually exclusive.');\n          }\n          this.trackStartLines = /full|onlyStart/i.test(this.config.positionTracking);\n          this.trackEndLines = /full/i.test(this.config.positionTracking);\n          if (isArray$1(lexerDefinition)) {\n            actualDefinition = {\n              modes: {\n                defaultMode: clone(lexerDefinition)\n              },\n              defaultMode: DEFAULT_MODE\n            };\n          } else {\n            hasOnlySingleMode = false;\n            actualDefinition = clone(lexerDefinition);\n          }\n        });\n        if (this.config.skipValidations === false) {\n          this.TRACE_INIT(\"performRuntimeChecks\", () => {\n            this.lexerDefinitionErrors = this.lexerDefinitionErrors.concat(performRuntimeChecks(actualDefinition, this.trackStartLines, this.config.lineTerminatorCharacters));\n          });\n          this.TRACE_INIT(\"performWarningRuntimeChecks\", () => {\n            this.lexerDefinitionWarning = this.lexerDefinitionWarning.concat(performWarningRuntimeChecks(actualDefinition, this.trackStartLines, this.config.lineTerminatorCharacters));\n          });\n        }\n        actualDefinition.modes = actualDefinition.modes ? actualDefinition.modes : {};\n        forEach(actualDefinition.modes, (currModeValue, currModeName) => {\n          actualDefinition.modes[currModeName] = reject(currModeValue, currTokType => isUndefined(currTokType));\n        });\n        const allModeNames = keys(actualDefinition.modes);\n        forEach(actualDefinition.modes, (currModDef, currModName) => {\n          this.TRACE_INIT(`Mode: <${currModName}> processing`, () => {\n            this.modes.push(currModName);\n            if (this.config.skipValidations === false) {\n              this.TRACE_INIT(`validatePatterns`, () => {\n                this.lexerDefinitionErrors = this.lexerDefinitionErrors.concat(validatePatterns(currModDef, allModeNames));\n              });\n            }\n            if (isEmpty(this.lexerDefinitionErrors)) {\n              augmentTokenTypes(currModDef);\n              let currAnalyzeResult;\n              this.TRACE_INIT(`analyzeTokenTypes`, () => {\n                currAnalyzeResult = analyzeTokenTypes(currModDef, {\n                  lineTerminatorCharacters: this.config.lineTerminatorCharacters,\n                  positionTracking: config.positionTracking,\n                  ensureOptimizations: config.ensureOptimizations,\n                  safeMode: config.safeMode,\n                  tracer: this.TRACE_INIT\n                });\n              });\n              this.patternIdxToConfig[currModName] = currAnalyzeResult.patternIdxToConfig;\n              this.charCodeToPatternIdxToConfig[currModName] = currAnalyzeResult.charCodeToPatternIdxToConfig;\n              this.emptyGroups = assign$1({}, this.emptyGroups, currAnalyzeResult.emptyGroups);\n              this.hasCustom = currAnalyzeResult.hasCustom || this.hasCustom;\n              this.canModeBeOptimized[currModName] = currAnalyzeResult.canBeOptimized;\n            }\n          });\n        });\n        this.defaultMode = actualDefinition.defaultMode;\n        if (!isEmpty(this.lexerDefinitionErrors) && !this.config.deferDefinitionErrorsHandling) {\n          const allErrMessages = map(this.lexerDefinitionErrors, error => {\n            return error.message;\n          });\n          const allErrMessagesString = allErrMessages.join(\"-----------------------\\n\");\n          throw new Error(\"Errors detected in definition of Lexer:\\n\" + allErrMessagesString);\n        }\n        forEach(this.lexerDefinitionWarning, warningDescriptor => {\n          PRINT_WARNING(warningDescriptor.message);\n        });\n        this.TRACE_INIT(\"Choosing sub-methods implementations\", () => {\n          if (SUPPORT_STICKY) {\n            this.chopInput = identity;\n            this.match = this.matchWithTest;\n          } else {\n            this.updateLastIndex = noop;\n            this.match = this.matchWithExec;\n          }\n          if (hasOnlySingleMode) {\n            this.handleModes = noop;\n          }\n          if (this.trackStartLines === false) {\n            this.computeNewColumn = identity;\n          }\n          if (this.trackEndLines === false) {\n            this.updateTokenEndLineColumnLocation = noop;\n          }\n          if (/full/i.test(this.config.positionTracking)) {\n            this.createTokenInstance = this.createFullToken;\n          } else if (/onlyStart/i.test(this.config.positionTracking)) {\n            this.createTokenInstance = this.createStartOnlyToken;\n          } else if (/onlyOffset/i.test(this.config.positionTracking)) {\n            this.createTokenInstance = this.createOffsetOnlyToken;\n          } else {\n            throw Error(`Invalid <positionTracking> config option: \"${this.config.positionTracking}\"`);\n          }\n          if (this.hasCustom) {\n            this.addToken = this.addTokenUsingPush;\n            this.handlePayload = this.handlePayloadWithCustom;\n          } else {\n            this.addToken = this.addTokenUsingMemberAccess;\n            this.handlePayload = this.handlePayloadNoCustom;\n          }\n        });\n        this.TRACE_INIT(\"Failed Optimization Warnings\", () => {\n          const unOptimizedModes = reduce(this.canModeBeOptimized, (cannotBeOptimized, canBeOptimized, modeName) => {\n            if (canBeOptimized === false) {\n              cannotBeOptimized.push(modeName);\n            }\n            return cannotBeOptimized;\n          }, []);\n          if (config.ensureOptimizations && !isEmpty(unOptimizedModes)) {\n            throw Error(`Lexer Modes: < ${unOptimizedModes.join(\", \")} > cannot be optimized.\n\t Disable the \"ensureOptimizations\" lexer config flag to silently ignore this and run the lexer in an un-optimized mode.\n\t Or inspect the console log for details on how to resolve these issues.`);\n          }\n        });\n        this.TRACE_INIT(\"clearRegExpParserCache\", () => {\n          clearRegExpParserCache();\n        });\n        this.TRACE_INIT(\"toFastProperties\", () => {\n          toFastProperties(this);\n        });\n      });\n    }\n    tokenize(text, initialMode = this.defaultMode) {\n      if (!isEmpty(this.lexerDefinitionErrors)) {\n        const allErrMessages = map(this.lexerDefinitionErrors, error => {\n          return error.message;\n        });\n        const allErrMessagesString = allErrMessages.join(\"-----------------------\\n\");\n        throw new Error(\"Unable to Tokenize because Errors detected in definition of Lexer:\\n\" + allErrMessagesString);\n      }\n      return this.tokenizeInternal(text, initialMode);\n    }\n    // There is quite a bit of duplication between this and \"tokenizeInternalLazy\"\n    // This is intentional due to performance considerations.\n    // this method also used quite a bit of `!` none null assertions because it is too optimized\n    // for `tsc` to always understand it is \"safe\"\n    tokenizeInternal(text, initialMode) {\n      let i, j, k, matchAltImage, longerAlt, matchedImage, payload, altPayload, imageLength, group, tokType, newToken, errLength, msg, match;\n      const orgText = text;\n      const orgLength = orgText.length;\n      let offset = 0;\n      let matchedTokensIndex = 0;\n      const guessedNumberOfTokens = this.hasCustom ? 0 : Math.floor(text.length / 10);\n      const matchedTokens = new Array(guessedNumberOfTokens);\n      const errors = [];\n      let line = this.trackStartLines ? 1 : void 0;\n      let column = this.trackStartLines ? 1 : void 0;\n      const groups = cloneEmptyGroups(this.emptyGroups);\n      const trackLines = this.trackStartLines;\n      const lineTerminatorPattern = this.config.lineTerminatorsPattern;\n      let currModePatternsLength = 0;\n      let patternIdxToConfig = [];\n      let currCharCodeToPatternIdxToConfig = [];\n      const modeStack = [];\n      const emptyArray = [];\n      Object.freeze(emptyArray);\n      let getPossiblePatterns;\n      function getPossiblePatternsSlow() {\n        return patternIdxToConfig;\n      }\n      function getPossiblePatternsOptimized(charCode) {\n        const optimizedCharIdx = charCodeToOptimizedIndex(charCode);\n        const possiblePatterns = currCharCodeToPatternIdxToConfig[optimizedCharIdx];\n        if (possiblePatterns === void 0) {\n          return emptyArray;\n        } else {\n          return possiblePatterns;\n        }\n      }\n      const pop_mode = popToken => {\n        if (modeStack.length === 1 &&\n        // if we have both a POP_MODE and a PUSH_MODE this is in-fact a \"transition\"\n        // So no error should occur.\n        popToken.tokenType.PUSH_MODE === void 0) {\n          const msg2 = this.config.errorMessageProvider.buildUnableToPopLexerModeMessage(popToken);\n          errors.push({\n            offset: popToken.startOffset,\n            line: popToken.startLine,\n            column: popToken.startColumn,\n            length: popToken.image.length,\n            message: msg2\n          });\n        } else {\n          modeStack.pop();\n          const newMode = last(modeStack);\n          patternIdxToConfig = this.patternIdxToConfig[newMode];\n          currCharCodeToPatternIdxToConfig = this.charCodeToPatternIdxToConfig[newMode];\n          currModePatternsLength = patternIdxToConfig.length;\n          const modeCanBeOptimized = this.canModeBeOptimized[newMode] && this.config.safeMode === false;\n          if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n            getPossiblePatterns = getPossiblePatternsOptimized;\n          } else {\n            getPossiblePatterns = getPossiblePatternsSlow;\n          }\n        }\n      };\n      function push_mode(newMode) {\n        modeStack.push(newMode);\n        currCharCodeToPatternIdxToConfig = this.charCodeToPatternIdxToConfig[newMode];\n        patternIdxToConfig = this.patternIdxToConfig[newMode];\n        currModePatternsLength = patternIdxToConfig.length;\n        currModePatternsLength = patternIdxToConfig.length;\n        const modeCanBeOptimized = this.canModeBeOptimized[newMode] && this.config.safeMode === false;\n        if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n          getPossiblePatterns = getPossiblePatternsOptimized;\n        } else {\n          getPossiblePatterns = getPossiblePatternsSlow;\n        }\n      }\n      push_mode.call(this, initialMode);\n      let currConfig;\n      const recoveryEnabled = this.config.recoveryEnabled;\n      while (offset < orgLength) {\n        matchedImage = null;\n        const nextCharCode = orgText.charCodeAt(offset);\n        const chosenPatternIdxToConfig = getPossiblePatterns(nextCharCode);\n        const chosenPatternsLength = chosenPatternIdxToConfig.length;\n        for (i = 0; i < chosenPatternsLength; i++) {\n          currConfig = chosenPatternIdxToConfig[i];\n          const currPattern = currConfig.pattern;\n          payload = null;\n          const singleCharCode = currConfig.short;\n          if (singleCharCode !== false) {\n            if (nextCharCode === singleCharCode) {\n              matchedImage = currPattern;\n            }\n          } else if (currConfig.isCustom === true) {\n            match = currPattern.exec(orgText, offset, matchedTokens, groups);\n            if (match !== null) {\n              matchedImage = match[0];\n              if (match.payload !== void 0) {\n                payload = match.payload;\n              }\n            } else {\n              matchedImage = null;\n            }\n          } else {\n            this.updateLastIndex(currPattern, offset);\n            matchedImage = this.match(currPattern, text, offset);\n          }\n          if (matchedImage !== null) {\n            longerAlt = currConfig.longerAlt;\n            if (longerAlt !== void 0) {\n              const longerAltLength = longerAlt.length;\n              for (k = 0; k < longerAltLength; k++) {\n                const longerAltConfig = patternIdxToConfig[longerAlt[k]];\n                const longerAltPattern = longerAltConfig.pattern;\n                altPayload = null;\n                if (longerAltConfig.isCustom === true) {\n                  match = longerAltPattern.exec(orgText, offset, matchedTokens, groups);\n                  if (match !== null) {\n                    matchAltImage = match[0];\n                    if (match.payload !== void 0) {\n                      altPayload = match.payload;\n                    }\n                  } else {\n                    matchAltImage = null;\n                  }\n                } else {\n                  this.updateLastIndex(longerAltPattern, offset);\n                  matchAltImage = this.match(longerAltPattern, text, offset);\n                }\n                if (matchAltImage && matchAltImage.length > matchedImage.length) {\n                  matchedImage = matchAltImage;\n                  payload = altPayload;\n                  currConfig = longerAltConfig;\n                  break;\n                }\n              }\n            }\n            break;\n          }\n        }\n        if (matchedImage !== null) {\n          imageLength = matchedImage.length;\n          group = currConfig.group;\n          if (group !== void 0) {\n            tokType = currConfig.tokenTypeIdx;\n            newToken = this.createTokenInstance(matchedImage, offset, tokType, currConfig.tokenType, line, column, imageLength);\n            this.handlePayload(newToken, payload);\n            if (group === false) {\n              matchedTokensIndex = this.addToken(matchedTokens, matchedTokensIndex, newToken);\n            } else {\n              groups[group].push(newToken);\n            }\n          }\n          text = this.chopInput(text, imageLength);\n          offset = offset + imageLength;\n          column = this.computeNewColumn(column, imageLength);\n          if (trackLines === true && currConfig.canLineTerminator === true) {\n            let numOfLTsInMatch = 0;\n            let foundTerminator;\n            let lastLTEndOffset;\n            lineTerminatorPattern.lastIndex = 0;\n            do {\n              foundTerminator = lineTerminatorPattern.test(matchedImage);\n              if (foundTerminator === true) {\n                lastLTEndOffset = lineTerminatorPattern.lastIndex - 1;\n                numOfLTsInMatch++;\n              }\n            } while (foundTerminator === true);\n            if (numOfLTsInMatch !== 0) {\n              line = line + numOfLTsInMatch;\n              column = imageLength - lastLTEndOffset;\n              this.updateTokenEndLineColumnLocation(newToken, group, lastLTEndOffset, numOfLTsInMatch, line, column, imageLength);\n            }\n          }\n          this.handleModes(currConfig, pop_mode, push_mode, newToken);\n        } else {\n          const errorStartOffset = offset;\n          const errorLine = line;\n          const errorColumn = column;\n          let foundResyncPoint = recoveryEnabled === false;\n          while (foundResyncPoint === false && offset < orgLength) {\n            text = this.chopInput(text, 1);\n            offset++;\n            for (j = 0; j < currModePatternsLength; j++) {\n              const currConfig2 = patternIdxToConfig[j];\n              const currPattern = currConfig2.pattern;\n              const singleCharCode = currConfig2.short;\n              if (singleCharCode !== false) {\n                if (orgText.charCodeAt(offset) === singleCharCode) {\n                  foundResyncPoint = true;\n                }\n              } else if (currConfig2.isCustom === true) {\n                foundResyncPoint = currPattern.exec(orgText, offset, matchedTokens, groups) !== null;\n              } else {\n                this.updateLastIndex(currPattern, offset);\n                foundResyncPoint = currPattern.exec(text) !== null;\n              }\n              if (foundResyncPoint === true) {\n                break;\n              }\n            }\n          }\n          errLength = offset - errorStartOffset;\n          column = this.computeNewColumn(column, errLength);\n          msg = this.config.errorMessageProvider.buildUnexpectedCharactersMessage(orgText, errorStartOffset, errLength, errorLine, errorColumn);\n          errors.push({\n            offset: errorStartOffset,\n            line: errorLine,\n            column: errorColumn,\n            length: errLength,\n            message: msg\n          });\n          if (recoveryEnabled === false) {\n            break;\n          }\n        }\n      }\n      if (!this.hasCustom) {\n        matchedTokens.length = matchedTokensIndex;\n      }\n      return {\n        tokens: matchedTokens,\n        groups,\n        errors\n      };\n    }\n    handleModes(config, pop_mode, push_mode, newToken) {\n      if (config.pop === true) {\n        const pushMode = config.push;\n        pop_mode(newToken);\n        if (pushMode !== void 0) {\n          push_mode.call(this, pushMode);\n        }\n      } else if (config.push !== void 0) {\n        push_mode.call(this, config.push);\n      }\n    }\n    chopInput(text, length) {\n      return text.substring(length);\n    }\n    updateLastIndex(regExp, newLastIndex) {\n      regExp.lastIndex = newLastIndex;\n    }\n    // TODO: decrease this under 600 characters? inspect stripping comments option in TSC compiler\n    updateTokenEndLineColumnLocation(newToken, group, lastLTIdx, numOfLTsInMatch, line, column, imageLength) {\n      let lastCharIsLT, fixForEndingInLT;\n      if (group !== void 0) {\n        lastCharIsLT = lastLTIdx === imageLength - 1;\n        fixForEndingInLT = lastCharIsLT ? -1 : 0;\n        if (!(numOfLTsInMatch === 1 && lastCharIsLT === true)) {\n          newToken.endLine = line + fixForEndingInLT;\n          newToken.endColumn = column - 1 + -fixForEndingInLT;\n        }\n      }\n    }\n    computeNewColumn(oldColumn, imageLength) {\n      return oldColumn + imageLength;\n    }\n    createOffsetOnlyToken(image, startOffset, tokenTypeIdx, tokenType) {\n      return {\n        image,\n        startOffset,\n        tokenTypeIdx,\n        tokenType\n      };\n    }\n    createStartOnlyToken(image, startOffset, tokenTypeIdx, tokenType, startLine, startColumn) {\n      return {\n        image,\n        startOffset,\n        startLine,\n        startColumn,\n        tokenTypeIdx,\n        tokenType\n      };\n    }\n    createFullToken(image, startOffset, tokenTypeIdx, tokenType, startLine, startColumn, imageLength) {\n      return {\n        image,\n        startOffset,\n        endOffset: startOffset + imageLength - 1,\n        startLine,\n        endLine: startLine,\n        startColumn,\n        endColumn: startColumn + imageLength - 1,\n        tokenTypeIdx,\n        tokenType\n      };\n    }\n    addTokenUsingPush(tokenVector, index, tokenToAdd) {\n      tokenVector.push(tokenToAdd);\n      return index;\n    }\n    addTokenUsingMemberAccess(tokenVector, index, tokenToAdd) {\n      tokenVector[index] = tokenToAdd;\n      index++;\n      return index;\n    }\n    handlePayloadNoCustom(token, payload) {}\n    handlePayloadWithCustom(token, payload) {\n      if (payload !== null) {\n        token.payload = payload;\n      }\n    }\n    matchWithTest(pattern, text, offset) {\n      const found = pattern.test(text);\n      if (found === true) {\n        return text.substring(offset, pattern.lastIndex);\n      }\n      return null;\n    }\n    matchWithExec(pattern, text) {\n      const regExpArray = pattern.exec(text);\n      return regExpArray !== null ? regExpArray[0] : null;\n    }\n  }\n  Lexer2.SKIPPED = \"This marks a skipped Token pattern, this means each token identified by it willbe consumed and then thrown into oblivion, this can be used to for example to completely ignore whitespace.\";\n  Lexer2.NA = /NOT_APPLICABLE/;\n  function tokenLabel(tokType) {\n    if (hasTokenLabel(tokType)) {\n      return tokType.LABEL;\n    } else {\n      return tokType.name;\n    }\n  }\n  function hasTokenLabel(obj) {\n    return isString(obj.LABEL) && obj.LABEL !== \"\";\n  }\n  const PARENT = \"parent\";\n  const CATEGORIES = \"categories\";\n  const LABEL = \"label\";\n  const GROUP = \"group\";\n  const PUSH_MODE = \"push_mode\";\n  const POP_MODE = \"pop_mode\";\n  const LONGER_ALT = \"longer_alt\";\n  const LINE_BREAKS = \"line_breaks\";\n  const START_CHARS_HINT = \"start_chars_hint\";\n  function createToken2(config) {\n    return createTokenInternal(config);\n  }\n  function createTokenInternal(config) {\n    const pattern = config.pattern;\n    const tokenType = {};\n    tokenType.name = config.name;\n    if (!isUndefined(pattern)) {\n      tokenType.PATTERN = pattern;\n    }\n    if (has(config, PARENT)) {\n      throw \"The parent property is no longer supported.\\nSee: https://github.com/chevrotain/chevrotain/issues/564#issuecomment-349062346 for details.\";\n    }\n    if (has(config, CATEGORIES)) {\n      tokenType.CATEGORIES = config[CATEGORIES];\n    }\n    augmentTokenTypes([tokenType]);\n    if (has(config, LABEL)) {\n      tokenType.LABEL = config[LABEL];\n    }\n    if (has(config, GROUP)) {\n      tokenType.GROUP = config[GROUP];\n    }\n    if (has(config, POP_MODE)) {\n      tokenType.POP_MODE = config[POP_MODE];\n    }\n    if (has(config, PUSH_MODE)) {\n      tokenType.PUSH_MODE = config[PUSH_MODE];\n    }\n    if (has(config, LONGER_ALT)) {\n      tokenType.LONGER_ALT = config[LONGER_ALT];\n    }\n    if (has(config, LINE_BREAKS)) {\n      tokenType.LINE_BREAKS = config[LINE_BREAKS];\n    }\n    if (has(config, START_CHARS_HINT)) {\n      tokenType.START_CHARS_HINT = config[START_CHARS_HINT];\n    }\n    return tokenType;\n  }\n  const EOF = createToken2({\n    name: \"EOF\",\n    pattern: Lexer2.NA\n  });\n  augmentTokenTypes([EOF]);\n  function createTokenInstance(tokType, image, startOffset, endOffset, startLine, endLine, startColumn, endColumn) {\n    return {\n      image,\n      startOffset,\n      endOffset,\n      startLine,\n      endLine,\n      startColumn,\n      endColumn,\n      tokenTypeIdx: tokType.tokenTypeIdx,\n      tokenType: tokType\n    };\n  }\n  function tokenMatcher(token, tokType) {\n    return tokenStructuredMatcher(token, tokType);\n  }\n  const defaultParserErrorProvider = {\n    buildMismatchTokenMessage({\n      expected,\n      actual,\n      previous,\n      ruleName\n    }) {\n      const hasLabel = hasTokenLabel(expected);\n      const expectedMsg = hasLabel ? `--> ${tokenLabel(expected)} <--` : `token of type --> ${expected.name} <--`;\n      const msg = `Expecting ${expectedMsg} but found --> '${actual.image}' <--`;\n      return msg;\n    },\n    buildNotAllInputParsedMessage({\n      firstRedundant,\n      ruleName\n    }) {\n      return \"Redundant input, expecting EOF but found: \" + firstRedundant.image;\n    },\n    buildNoViableAltMessage({\n      expectedPathsPerAlt,\n      actual,\n      previous,\n      customUserDescription,\n      ruleName\n    }) {\n      const errPrefix = \"Expecting: \";\n      const actualText = head(actual).image;\n      const errSuffix = \"\\nbut found: '\" + actualText + \"'\";\n      if (customUserDescription) {\n        return errPrefix + customUserDescription + errSuffix;\n      } else {\n        const allLookAheadPaths = reduce(expectedPathsPerAlt, (result, currAltPaths) => result.concat(currAltPaths), []);\n        const nextValidTokenSequences = map(allLookAheadPaths, currPath => `[${map(currPath, currTokenType => tokenLabel(currTokenType)).join(\", \")}]`);\n        const nextValidSequenceItems = map(nextValidTokenSequences, (itemMsg, idx) => `  ${idx + 1}. ${itemMsg}`);\n        const calculatedDescription = `one of these possible Token sequences:\n${nextValidSequenceItems.join(\"\\n\")}`;\n        return errPrefix + calculatedDescription + errSuffix;\n      }\n    },\n    buildEarlyExitMessage({\n      expectedIterationPaths,\n      actual,\n      customUserDescription,\n      ruleName\n    }) {\n      const errPrefix = \"Expecting: \";\n      const actualText = head(actual).image;\n      const errSuffix = \"\\nbut found: '\" + actualText + \"'\";\n      if (customUserDescription) {\n        return errPrefix + customUserDescription + errSuffix;\n      } else {\n        const nextValidTokenSequences = map(expectedIterationPaths, currPath => `[${map(currPath, currTokenType => tokenLabel(currTokenType)).join(\",\")}]`);\n        const calculatedDescription = `expecting at least one iteration which starts with one of these possible Token sequences::\n  <${nextValidTokenSequences.join(\" ,\")}>`;\n        return errPrefix + calculatedDescription + errSuffix;\n      }\n    }\n  };\n  Object.freeze(defaultParserErrorProvider);\n  const defaultGrammarResolverErrorProvider = {\n    buildRuleNotFoundError(topLevelRule, undefinedRule) {\n      const msg = \"Invalid grammar, reference to a rule which is not defined: ->\" + undefinedRule.nonTerminalName + \"<-\\ninside top level rule: ->\" + topLevelRule.name + \"<-\";\n      return msg;\n    }\n  };\n  const defaultGrammarValidatorErrorProvider = {\n    buildDuplicateFoundError(topLevelRule, duplicateProds) {\n      function getExtraProductionArgument2(prod) {\n        if (prod instanceof Terminal) {\n          return prod.terminalType.name;\n        } else if (prod instanceof NonTerminal) {\n          return prod.nonTerminalName;\n        } else {\n          return \"\";\n        }\n      }\n      const topLevelName = topLevelRule.name;\n      const duplicateProd = head(duplicateProds);\n      const index = duplicateProd.idx;\n      const dslName = getProductionDslName(duplicateProd);\n      const extraArgument = getExtraProductionArgument2(duplicateProd);\n      const hasExplicitIndex = index > 0;\n      let msg = `->${dslName}${hasExplicitIndex ? index : \"\"}<- ${extraArgument ? `with argument: ->${extraArgument}<-` : \"\"}\n                  appears more than once (${duplicateProds.length} times) in the top level rule: ->${topLevelName}<-.                  \n                  For further details see: https://chevrotain.io/docs/FAQ.html#NUMERICAL_SUFFIXES \n                  `;\n      msg = msg.replace(/[ \\t]+/g, \" \");\n      msg = msg.replace(/\\s\\s+/g, \"\\n\");\n      return msg;\n    },\n    buildNamespaceConflictError(rule) {\n      const errMsg = `Namespace conflict found in grammar.\nThe grammar has both a Terminal(Token) and a Non-Terminal(Rule) named: <${rule.name}>.\nTo resolve this make sure each Terminal and Non-Terminal names are unique\nThis is easy to accomplish by using the convention that Terminal names start with an uppercase letter\nand Non-Terminal names start with a lower case letter.`;\n      return errMsg;\n    },\n    buildAlternationPrefixAmbiguityError(options) {\n      const pathMsg = map(options.prefixPath, currTok => tokenLabel(currTok)).join(\", \");\n      const occurrence = options.alternation.idx === 0 ? \"\" : options.alternation.idx;\n      const errMsg = `Ambiguous alternatives: <${options.ambiguityIndices.join(\" ,\")}> due to common lookahead prefix\nin <OR${occurrence}> inside <${options.topLevelRule.name}> Rule,\n<${pathMsg}> may appears as a prefix path in all these alternatives.\nSee: https://chevrotain.io/docs/guide/resolving_grammar_errors.html#COMMON_PREFIX\nFor Further details.`;\n      return errMsg;\n    },\n    buildAlternationAmbiguityError(options) {\n      const pathMsg = map(options.prefixPath, currtok => tokenLabel(currtok)).join(\", \");\n      const occurrence = options.alternation.idx === 0 ? \"\" : options.alternation.idx;\n      let currMessage = `Ambiguous Alternatives Detected: <${options.ambiguityIndices.join(\" ,\")}> in <OR${occurrence}> inside <${options.topLevelRule.name}> Rule,\n<${pathMsg}> may appears as a prefix path in all these alternatives.\n`;\n      currMessage = currMessage + `See: https://chevrotain.io/docs/guide/resolving_grammar_errors.html#AMBIGUOUS_ALTERNATIVES\nFor Further details.`;\n      return currMessage;\n    },\n    buildEmptyRepetitionError(options) {\n      let dslName = getProductionDslName(options.repetition);\n      if (options.repetition.idx !== 0) {\n        dslName += options.repetition.idx;\n      }\n      const errMsg = `The repetition <${dslName}> within Rule <${options.topLevelRule.name}> can never consume any tokens.\nThis could lead to an infinite loop.`;\n      return errMsg;\n    },\n    // TODO: remove - `errors_public` from nyc.config.js exclude\n    //       once this method is fully removed from this file\n    buildTokenNameError(options) {\n      return \"deprecated\";\n    },\n    buildEmptyAlternationError(options) {\n      const errMsg = `Ambiguous empty alternative: <${options.emptyChoiceIdx + 1}> in <OR${options.alternation.idx}> inside <${options.topLevelRule.name}> Rule.\nOnly the last alternative may be an empty alternative.`;\n      return errMsg;\n    },\n    buildTooManyAlternativesError(options) {\n      const errMsg = `An Alternation cannot have more than 256 alternatives:\n<OR${options.alternation.idx}> inside <${options.topLevelRule.name}> Rule.\n has ${options.alternation.definition.length + 1} alternatives.`;\n      return errMsg;\n    },\n    buildLeftRecursionError(options) {\n      const ruleName = options.topLevelRule.name;\n      const pathNames = map(options.leftRecursionPath, currRule => currRule.name);\n      const leftRecursivePath = `${ruleName} --> ${pathNames.concat([ruleName]).join(\" --> \")}`;\n      const errMsg = `Left Recursion found in grammar.\nrule: <${ruleName}> can be invoked from itself (directly or indirectly)\nwithout consuming any Tokens. The grammar path that causes this is: \n ${leftRecursivePath}\n To fix this refactor your grammar to remove the left recursion.\nsee: https://en.wikipedia.org/wiki/LL_parser#Left_factoring.`;\n      return errMsg;\n    },\n    // TODO: remove - `errors_public` from nyc.config.js exclude\n    //       once this method is fully removed from this file\n    buildInvalidRuleNameError(options) {\n      return \"deprecated\";\n    },\n    buildDuplicateRuleNameError(options) {\n      let ruleName;\n      if (options.topLevelRule instanceof Rule) {\n        ruleName = options.topLevelRule.name;\n      } else {\n        ruleName = options.topLevelRule;\n      }\n      const errMsg = `Duplicate definition, rule: ->${ruleName}<- is already defined in the grammar: ->${options.grammarName}<-`;\n      return errMsg;\n    }\n  };\n  function resolveGrammar$1(topLevels, errMsgProvider) {\n    const refResolver = new GastRefResolverVisitor(topLevels, errMsgProvider);\n    refResolver.resolveRefs();\n    return refResolver.errors;\n  }\n  class GastRefResolverVisitor extends GAstVisitor {\n    constructor(nameToTopRule, errMsgProvider) {\n      super();\n      this.nameToTopRule = nameToTopRule;\n      this.errMsgProvider = errMsgProvider;\n      this.errors = [];\n    }\n    resolveRefs() {\n      forEach(values(this.nameToTopRule), prod => {\n        this.currTopLevel = prod;\n        prod.accept(this);\n      });\n    }\n    visitNonTerminal(node) {\n      const ref = this.nameToTopRule[node.nonTerminalName];\n      if (!ref) {\n        const msg = this.errMsgProvider.buildRuleNotFoundError(this.currTopLevel, node);\n        this.errors.push({\n          message: msg,\n          type: ParserDefinitionErrorType.UNRESOLVED_SUBRULE_REF,\n          ruleName: this.currTopLevel.name,\n          unresolvedRefName: node.nonTerminalName\n        });\n      } else {\n        node.referencedRule = ref;\n      }\n    }\n  }\n  class AbstractNextPossibleTokensWalker extends RestWalker {\n    constructor(topProd, path) {\n      super();\n      this.topProd = topProd;\n      this.path = path;\n      this.possibleTokTypes = [];\n      this.nextProductionName = \"\";\n      this.nextProductionOccurrence = 0;\n      this.found = false;\n      this.isAtEndOfPath = false;\n    }\n    startWalking() {\n      this.found = false;\n      if (this.path.ruleStack[0] !== this.topProd.name) {\n        throw Error(\"The path does not start with the walker's top Rule!\");\n      }\n      this.ruleStack = clone(this.path.ruleStack).reverse();\n      this.occurrenceStack = clone(this.path.occurrenceStack).reverse();\n      this.ruleStack.pop();\n      this.occurrenceStack.pop();\n      this.updateExpectedNext();\n      this.walk(this.topProd);\n      return this.possibleTokTypes;\n    }\n    walk(prod, prevRest = []) {\n      if (!this.found) {\n        super.walk(prod, prevRest);\n      }\n    }\n    walkProdRef(refProd, currRest, prevRest) {\n      if (refProd.referencedRule.name === this.nextProductionName && refProd.idx === this.nextProductionOccurrence) {\n        const fullRest = currRest.concat(prevRest);\n        this.updateExpectedNext();\n        this.walk(refProd.referencedRule, fullRest);\n      }\n    }\n    updateExpectedNext() {\n      if (isEmpty(this.ruleStack)) {\n        this.nextProductionName = \"\";\n        this.nextProductionOccurrence = 0;\n        this.isAtEndOfPath = true;\n      } else {\n        this.nextProductionName = this.ruleStack.pop();\n        this.nextProductionOccurrence = this.occurrenceStack.pop();\n      }\n    }\n  }\n  class NextAfterTokenWalker extends AbstractNextPossibleTokensWalker {\n    constructor(topProd, path) {\n      super(topProd, path);\n      this.path = path;\n      this.nextTerminalName = \"\";\n      this.nextTerminalOccurrence = 0;\n      this.nextTerminalName = this.path.lastTok.name;\n      this.nextTerminalOccurrence = this.path.lastTokOccurrence;\n    }\n    walkTerminal(terminal, currRest, prevRest) {\n      if (this.isAtEndOfPath && terminal.terminalType.name === this.nextTerminalName && terminal.idx === this.nextTerminalOccurrence && !this.found) {\n        const fullRest = currRest.concat(prevRest);\n        const restProd = new Alternative({\n          definition: fullRest\n        });\n        this.possibleTokTypes = first(restProd);\n        this.found = true;\n      }\n    }\n  }\n  class AbstractNextTerminalAfterProductionWalker extends RestWalker {\n    constructor(topRule, occurrence) {\n      super();\n      this.topRule = topRule;\n      this.occurrence = occurrence;\n      this.result = {\n        token: void 0,\n        occurrence: void 0,\n        isEndOfRule: void 0\n      };\n    }\n    startWalking() {\n      this.walk(this.topRule);\n      return this.result;\n    }\n  }\n  class NextTerminalAfterManyWalker extends AbstractNextTerminalAfterProductionWalker {\n    walkMany(manyProd, currRest, prevRest) {\n      if (manyProd.idx === this.occurrence) {\n        const firstAfterMany = head(currRest.concat(prevRest));\n        this.result.isEndOfRule = firstAfterMany === void 0;\n        if (firstAfterMany instanceof Terminal) {\n          this.result.token = firstAfterMany.terminalType;\n          this.result.occurrence = firstAfterMany.idx;\n        }\n      } else {\n        super.walkMany(manyProd, currRest, prevRest);\n      }\n    }\n  }\n  class NextTerminalAfterManySepWalker extends AbstractNextTerminalAfterProductionWalker {\n    walkManySep(manySepProd, currRest, prevRest) {\n      if (manySepProd.idx === this.occurrence) {\n        const firstAfterManySep = head(currRest.concat(prevRest));\n        this.result.isEndOfRule = firstAfterManySep === void 0;\n        if (firstAfterManySep instanceof Terminal) {\n          this.result.token = firstAfterManySep.terminalType;\n          this.result.occurrence = firstAfterManySep.idx;\n        }\n      } else {\n        super.walkManySep(manySepProd, currRest, prevRest);\n      }\n    }\n  }\n  class NextTerminalAfterAtLeastOneWalker extends AbstractNextTerminalAfterProductionWalker {\n    walkAtLeastOne(atLeastOneProd, currRest, prevRest) {\n      if (atLeastOneProd.idx === this.occurrence) {\n        const firstAfterAtLeastOne = head(currRest.concat(prevRest));\n        this.result.isEndOfRule = firstAfterAtLeastOne === void 0;\n        if (firstAfterAtLeastOne instanceof Terminal) {\n          this.result.token = firstAfterAtLeastOne.terminalType;\n          this.result.occurrence = firstAfterAtLeastOne.idx;\n        }\n      } else {\n        super.walkAtLeastOne(atLeastOneProd, currRest, prevRest);\n      }\n    }\n  }\n  class NextTerminalAfterAtLeastOneSepWalker extends AbstractNextTerminalAfterProductionWalker {\n    walkAtLeastOneSep(atleastOneSepProd, currRest, prevRest) {\n      if (atleastOneSepProd.idx === this.occurrence) {\n        const firstAfterfirstAfterAtLeastOneSep = head(currRest.concat(prevRest));\n        this.result.isEndOfRule = firstAfterfirstAfterAtLeastOneSep === void 0;\n        if (firstAfterfirstAfterAtLeastOneSep instanceof Terminal) {\n          this.result.token = firstAfterfirstAfterAtLeastOneSep.terminalType;\n          this.result.occurrence = firstAfterfirstAfterAtLeastOneSep.idx;\n        }\n      } else {\n        super.walkAtLeastOneSep(atleastOneSepProd, currRest, prevRest);\n      }\n    }\n  }\n  function possiblePathsFrom(targetDef, maxLength, currPath = []) {\n    currPath = clone(currPath);\n    let result = [];\n    let i = 0;\n    function remainingPathWith(nextDef) {\n      return nextDef.concat(drop(targetDef, i + 1));\n    }\n    function getAlternativesForProd(definition) {\n      const alternatives = possiblePathsFrom(remainingPathWith(definition), maxLength, currPath);\n      return result.concat(alternatives);\n    }\n    while (currPath.length < maxLength && i < targetDef.length) {\n      const prod = targetDef[i];\n      if (prod instanceof Alternative) {\n        return getAlternativesForProd(prod.definition);\n      } else if (prod instanceof NonTerminal) {\n        return getAlternativesForProd(prod.definition);\n      } else if (prod instanceof Option) {\n        result = getAlternativesForProd(prod.definition);\n      } else if (prod instanceof RepetitionMandatory) {\n        const newDef = prod.definition.concat([new Repetition({\n          definition: prod.definition\n        })]);\n        return getAlternativesForProd(newDef);\n      } else if (prod instanceof RepetitionMandatoryWithSeparator) {\n        const newDef = [new Alternative({\n          definition: prod.definition\n        }), new Repetition({\n          definition: [new Terminal({\n            terminalType: prod.separator\n          })].concat(prod.definition)\n        })];\n        return getAlternativesForProd(newDef);\n      } else if (prod instanceof RepetitionWithSeparator) {\n        const newDef = prod.definition.concat([new Repetition({\n          definition: [new Terminal({\n            terminalType: prod.separator\n          })].concat(prod.definition)\n        })]);\n        result = getAlternativesForProd(newDef);\n      } else if (prod instanceof Repetition) {\n        const newDef = prod.definition.concat([new Repetition({\n          definition: prod.definition\n        })]);\n        result = getAlternativesForProd(newDef);\n      } else if (prod instanceof Alternation) {\n        forEach(prod.definition, currAlt => {\n          if (isEmpty(currAlt.definition) === false) {\n            result = getAlternativesForProd(currAlt.definition);\n          }\n        });\n        return result;\n      } else if (prod instanceof Terminal) {\n        currPath.push(prod.terminalType);\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n      i++;\n    }\n    result.push({\n      partialPath: currPath,\n      suffixDef: drop(targetDef, i)\n    });\n    return result;\n  }\n  function nextPossibleTokensAfter(initialDef, tokenVector, tokMatcher, maxLookAhead) {\n    const EXIT_NON_TERMINAL = \"EXIT_NONE_TERMINAL\";\n    const EXIT_NON_TERMINAL_ARR = [EXIT_NON_TERMINAL];\n    const EXIT_ALTERNATIVE = \"EXIT_ALTERNATIVE\";\n    let foundCompletePath = false;\n    const tokenVectorLength = tokenVector.length;\n    const minimalAlternativesIndex = tokenVectorLength - maxLookAhead - 1;\n    const result = [];\n    const possiblePaths = [];\n    possiblePaths.push({\n      idx: -1,\n      def: initialDef,\n      ruleStack: [],\n      occurrenceStack: []\n    });\n    while (!isEmpty(possiblePaths)) {\n      const currPath = possiblePaths.pop();\n      if (currPath === EXIT_ALTERNATIVE) {\n        if (foundCompletePath && last(possiblePaths).idx <= minimalAlternativesIndex) {\n          possiblePaths.pop();\n        }\n        continue;\n      }\n      const currDef = currPath.def;\n      const currIdx = currPath.idx;\n      const currRuleStack = currPath.ruleStack;\n      const currOccurrenceStack = currPath.occurrenceStack;\n      if (isEmpty(currDef)) {\n        continue;\n      }\n      const prod = currDef[0];\n      if (prod === EXIT_NON_TERMINAL) {\n        const nextPath = {\n          idx: currIdx,\n          def: drop(currDef),\n          ruleStack: dropRight(currRuleStack),\n          occurrenceStack: dropRight(currOccurrenceStack)\n        };\n        possiblePaths.push(nextPath);\n      } else if (prod instanceof Terminal) {\n        if (currIdx < tokenVectorLength - 1) {\n          const nextIdx = currIdx + 1;\n          const actualToken = tokenVector[nextIdx];\n          if (tokMatcher(actualToken, prod.terminalType)) {\n            const nextPath = {\n              idx: nextIdx,\n              def: drop(currDef),\n              ruleStack: currRuleStack,\n              occurrenceStack: currOccurrenceStack\n            };\n            possiblePaths.push(nextPath);\n          }\n        } else if (currIdx === tokenVectorLength - 1) {\n          result.push({\n            nextTokenType: prod.terminalType,\n            nextTokenOccurrence: prod.idx,\n            ruleStack: currRuleStack,\n            occurrenceStack: currOccurrenceStack\n          });\n          foundCompletePath = true;\n        } else {\n          throw Error(\"non exhaustive match\");\n        }\n      } else if (prod instanceof NonTerminal) {\n        const newRuleStack = clone(currRuleStack);\n        newRuleStack.push(prod.nonTerminalName);\n        const newOccurrenceStack = clone(currOccurrenceStack);\n        newOccurrenceStack.push(prod.idx);\n        const nextPath = {\n          idx: currIdx,\n          def: prod.definition.concat(EXIT_NON_TERMINAL_ARR, drop(currDef)),\n          ruleStack: newRuleStack,\n          occurrenceStack: newOccurrenceStack\n        };\n        possiblePaths.push(nextPath);\n      } else if (prod instanceof Option) {\n        const nextPathWithout = {\n          idx: currIdx,\n          def: drop(currDef),\n          ruleStack: currRuleStack,\n          occurrenceStack: currOccurrenceStack\n        };\n        possiblePaths.push(nextPathWithout);\n        possiblePaths.push(EXIT_ALTERNATIVE);\n        const nextPathWith = {\n          idx: currIdx,\n          def: prod.definition.concat(drop(currDef)),\n          ruleStack: currRuleStack,\n          occurrenceStack: currOccurrenceStack\n        };\n        possiblePaths.push(nextPathWith);\n      } else if (prod instanceof RepetitionMandatory) {\n        const secondIteration = new Repetition({\n          definition: prod.definition,\n          idx: prod.idx\n        });\n        const nextDef = prod.definition.concat([secondIteration], drop(currDef));\n        const nextPath = {\n          idx: currIdx,\n          def: nextDef,\n          ruleStack: currRuleStack,\n          occurrenceStack: currOccurrenceStack\n        };\n        possiblePaths.push(nextPath);\n      } else if (prod instanceof RepetitionMandatoryWithSeparator) {\n        const separatorGast = new Terminal({\n          terminalType: prod.separator\n        });\n        const secondIteration = new Repetition({\n          definition: [separatorGast].concat(prod.definition),\n          idx: prod.idx\n        });\n        const nextDef = prod.definition.concat([secondIteration], drop(currDef));\n        const nextPath = {\n          idx: currIdx,\n          def: nextDef,\n          ruleStack: currRuleStack,\n          occurrenceStack: currOccurrenceStack\n        };\n        possiblePaths.push(nextPath);\n      } else if (prod instanceof RepetitionWithSeparator) {\n        const nextPathWithout = {\n          idx: currIdx,\n          def: drop(currDef),\n          ruleStack: currRuleStack,\n          occurrenceStack: currOccurrenceStack\n        };\n        possiblePaths.push(nextPathWithout);\n        possiblePaths.push(EXIT_ALTERNATIVE);\n        const separatorGast = new Terminal({\n          terminalType: prod.separator\n        });\n        const nthRepetition = new Repetition({\n          definition: [separatorGast].concat(prod.definition),\n          idx: prod.idx\n        });\n        const nextDef = prod.definition.concat([nthRepetition], drop(currDef));\n        const nextPathWith = {\n          idx: currIdx,\n          def: nextDef,\n          ruleStack: currRuleStack,\n          occurrenceStack: currOccurrenceStack\n        };\n        possiblePaths.push(nextPathWith);\n      } else if (prod instanceof Repetition) {\n        const nextPathWithout = {\n          idx: currIdx,\n          def: drop(currDef),\n          ruleStack: currRuleStack,\n          occurrenceStack: currOccurrenceStack\n        };\n        possiblePaths.push(nextPathWithout);\n        possiblePaths.push(EXIT_ALTERNATIVE);\n        const nthRepetition = new Repetition({\n          definition: prod.definition,\n          idx: prod.idx\n        });\n        const nextDef = prod.definition.concat([nthRepetition], drop(currDef));\n        const nextPathWith = {\n          idx: currIdx,\n          def: nextDef,\n          ruleStack: currRuleStack,\n          occurrenceStack: currOccurrenceStack\n        };\n        possiblePaths.push(nextPathWith);\n      } else if (prod instanceof Alternation) {\n        for (let i = prod.definition.length - 1; i >= 0; i--) {\n          const currAlt = prod.definition[i];\n          const currAltPath = {\n            idx: currIdx,\n            def: currAlt.definition.concat(drop(currDef)),\n            ruleStack: currRuleStack,\n            occurrenceStack: currOccurrenceStack\n          };\n          possiblePaths.push(currAltPath);\n          possiblePaths.push(EXIT_ALTERNATIVE);\n        }\n      } else if (prod instanceof Alternative) {\n        possiblePaths.push({\n          idx: currIdx,\n          def: prod.definition.concat(drop(currDef)),\n          ruleStack: currRuleStack,\n          occurrenceStack: currOccurrenceStack\n        });\n      } else if (prod instanceof Rule) {\n        possiblePaths.push(expandTopLevelRule(prod, currIdx, currRuleStack, currOccurrenceStack));\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    }\n    return result;\n  }\n  function expandTopLevelRule(topRule, currIdx, currRuleStack, currOccurrenceStack) {\n    const newRuleStack = clone(currRuleStack);\n    newRuleStack.push(topRule.name);\n    const newCurrOccurrenceStack = clone(currOccurrenceStack);\n    newCurrOccurrenceStack.push(1);\n    return {\n      idx: currIdx,\n      def: topRule.definition,\n      ruleStack: newRuleStack,\n      occurrenceStack: newCurrOccurrenceStack\n    };\n  }\n  var PROD_TYPE;\n  (function (PROD_TYPE2) {\n    PROD_TYPE2[PROD_TYPE2[\"OPTION\"] = 0] = \"OPTION\";\n    PROD_TYPE2[PROD_TYPE2[\"REPETITION\"] = 1] = \"REPETITION\";\n    PROD_TYPE2[PROD_TYPE2[\"REPETITION_MANDATORY\"] = 2] = \"REPETITION_MANDATORY\";\n    PROD_TYPE2[PROD_TYPE2[\"REPETITION_MANDATORY_WITH_SEPARATOR\"] = 3] = \"REPETITION_MANDATORY_WITH_SEPARATOR\";\n    PROD_TYPE2[PROD_TYPE2[\"REPETITION_WITH_SEPARATOR\"] = 4] = \"REPETITION_WITH_SEPARATOR\";\n    PROD_TYPE2[PROD_TYPE2[\"ALTERNATION\"] = 5] = \"ALTERNATION\";\n  })(PROD_TYPE || (PROD_TYPE = {}));\n  function getProdType(prod) {\n    if (prod instanceof Option || prod === \"Option\") {\n      return PROD_TYPE.OPTION;\n    } else if (prod instanceof Repetition || prod === \"Repetition\") {\n      return PROD_TYPE.REPETITION;\n    } else if (prod instanceof RepetitionMandatory || prod === \"RepetitionMandatory\") {\n      return PROD_TYPE.REPETITION_MANDATORY;\n    } else if (prod instanceof RepetitionMandatoryWithSeparator || prod === \"RepetitionMandatoryWithSeparator\") {\n      return PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR;\n    } else if (prod instanceof RepetitionWithSeparator || prod === \"RepetitionWithSeparator\") {\n      return PROD_TYPE.REPETITION_WITH_SEPARATOR;\n    } else if (prod instanceof Alternation || prod === \"Alternation\") {\n      return PROD_TYPE.ALTERNATION;\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  }\n  function buildLookaheadFuncForOr(occurrence, ruleGrammar, maxLookahead, hasPredicates, dynamicTokensEnabled, laFuncBuilder) {\n    const lookAheadPaths = getLookaheadPathsForOr(occurrence, ruleGrammar, maxLookahead);\n    const tokenMatcher2 = areTokenCategoriesNotUsed(lookAheadPaths) ? tokenStructuredMatcherNoCategories : tokenStructuredMatcher;\n    return laFuncBuilder(lookAheadPaths, hasPredicates, tokenMatcher2, dynamicTokensEnabled);\n  }\n  function buildLookaheadFuncForOptionalProd(occurrence, ruleGrammar, k, dynamicTokensEnabled, prodType, lookaheadBuilder) {\n    const lookAheadPaths = getLookaheadPathsForOptionalProd(occurrence, ruleGrammar, prodType, k);\n    const tokenMatcher2 = areTokenCategoriesNotUsed(lookAheadPaths) ? tokenStructuredMatcherNoCategories : tokenStructuredMatcher;\n    return lookaheadBuilder(lookAheadPaths[0], tokenMatcher2, dynamicTokensEnabled);\n  }\n  function buildAlternativesLookAheadFunc(alts, hasPredicates, tokenMatcher2, dynamicTokensEnabled) {\n    const numOfAlts = alts.length;\n    const areAllOneTokenLookahead = every(alts, currAlt => {\n      return every(currAlt, currPath => {\n        return currPath.length === 1;\n      });\n    });\n    if (hasPredicates) {\n      return function (orAlts) {\n        const predicates = map(orAlts, currAlt => currAlt.GATE);\n        for (let t = 0; t < numOfAlts; t++) {\n          const currAlt = alts[t];\n          const currNumOfPaths = currAlt.length;\n          const currPredicate = predicates[t];\n          if (currPredicate !== void 0 && currPredicate.call(this) === false) {\n            continue;\n          }\n          nextPath: for (let j = 0; j < currNumOfPaths; j++) {\n            const currPath = currAlt[j];\n            const currPathLength = currPath.length;\n            for (let i = 0; i < currPathLength; i++) {\n              const nextToken = this.LA(i + 1);\n              if (tokenMatcher2(nextToken, currPath[i]) === false) {\n                continue nextPath;\n              }\n            }\n            return t;\n          }\n        }\n        return void 0;\n      };\n    } else if (areAllOneTokenLookahead && !dynamicTokensEnabled) {\n      const singleTokenAlts = map(alts, currAlt => {\n        return flatten(currAlt);\n      });\n      const choiceToAlt = reduce(singleTokenAlts, (result, currAlt, idx) => {\n        forEach(currAlt, currTokType => {\n          if (!has(result, currTokType.tokenTypeIdx)) {\n            result[currTokType.tokenTypeIdx] = idx;\n          }\n          forEach(currTokType.categoryMatches, currExtendingType => {\n            if (!has(result, currExtendingType)) {\n              result[currExtendingType] = idx;\n            }\n          });\n        });\n        return result;\n      }, {});\n      return function () {\n        const nextToken = this.LA(1);\n        return choiceToAlt[nextToken.tokenTypeIdx];\n      };\n    } else {\n      return function () {\n        for (let t = 0; t < numOfAlts; t++) {\n          const currAlt = alts[t];\n          const currNumOfPaths = currAlt.length;\n          nextPath: for (let j = 0; j < currNumOfPaths; j++) {\n            const currPath = currAlt[j];\n            const currPathLength = currPath.length;\n            for (let i = 0; i < currPathLength; i++) {\n              const nextToken = this.LA(i + 1);\n              if (tokenMatcher2(nextToken, currPath[i]) === false) {\n                continue nextPath;\n              }\n            }\n            return t;\n          }\n        }\n        return void 0;\n      };\n    }\n  }\n  function buildSingleAlternativeLookaheadFunction(alt, tokenMatcher2, dynamicTokensEnabled) {\n    const areAllOneTokenLookahead = every(alt, currPath => {\n      return currPath.length === 1;\n    });\n    const numOfPaths = alt.length;\n    if (areAllOneTokenLookahead && !dynamicTokensEnabled) {\n      const singleTokensTypes = flatten(alt);\n      if (singleTokensTypes.length === 1 && isEmpty(singleTokensTypes[0].categoryMatches)) {\n        const expectedTokenType = singleTokensTypes[0];\n        const expectedTokenUniqueKey = expectedTokenType.tokenTypeIdx;\n        return function () {\n          return this.LA(1).tokenTypeIdx === expectedTokenUniqueKey;\n        };\n      } else {\n        const choiceToAlt = reduce(singleTokensTypes, (result, currTokType, idx) => {\n          result[currTokType.tokenTypeIdx] = true;\n          forEach(currTokType.categoryMatches, currExtendingType => {\n            result[currExtendingType] = true;\n          });\n          return result;\n        }, []);\n        return function () {\n          const nextToken = this.LA(1);\n          return choiceToAlt[nextToken.tokenTypeIdx] === true;\n        };\n      }\n    } else {\n      return function () {\n        nextPath: for (let j = 0; j < numOfPaths; j++) {\n          const currPath = alt[j];\n          const currPathLength = currPath.length;\n          for (let i = 0; i < currPathLength; i++) {\n            const nextToken = this.LA(i + 1);\n            if (tokenMatcher2(nextToken, currPath[i]) === false) {\n              continue nextPath;\n            }\n          }\n          return true;\n        }\n        return false;\n      };\n    }\n  }\n  class RestDefinitionFinderWalker extends RestWalker {\n    constructor(topProd, targetOccurrence, targetProdType) {\n      super();\n      this.topProd = topProd;\n      this.targetOccurrence = targetOccurrence;\n      this.targetProdType = targetProdType;\n    }\n    startWalking() {\n      this.walk(this.topProd);\n      return this.restDef;\n    }\n    checkIsTarget(node, expectedProdType, currRest, prevRest) {\n      if (node.idx === this.targetOccurrence && this.targetProdType === expectedProdType) {\n        this.restDef = currRest.concat(prevRest);\n        return true;\n      }\n      return false;\n    }\n    walkOption(optionProd, currRest, prevRest) {\n      if (!this.checkIsTarget(optionProd, PROD_TYPE.OPTION, currRest, prevRest)) {\n        super.walkOption(optionProd, currRest, prevRest);\n      }\n    }\n    walkAtLeastOne(atLeastOneProd, currRest, prevRest) {\n      if (!this.checkIsTarget(atLeastOneProd, PROD_TYPE.REPETITION_MANDATORY, currRest, prevRest)) {\n        super.walkOption(atLeastOneProd, currRest, prevRest);\n      }\n    }\n    walkAtLeastOneSep(atLeastOneSepProd, currRest, prevRest) {\n      if (!this.checkIsTarget(atLeastOneSepProd, PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR, currRest, prevRest)) {\n        super.walkOption(atLeastOneSepProd, currRest, prevRest);\n      }\n    }\n    walkMany(manyProd, currRest, prevRest) {\n      if (!this.checkIsTarget(manyProd, PROD_TYPE.REPETITION, currRest, prevRest)) {\n        super.walkOption(manyProd, currRest, prevRest);\n      }\n    }\n    walkManySep(manySepProd, currRest, prevRest) {\n      if (!this.checkIsTarget(manySepProd, PROD_TYPE.REPETITION_WITH_SEPARATOR, currRest, prevRest)) {\n        super.walkOption(manySepProd, currRest, prevRest);\n      }\n    }\n  }\n  class InsideDefinitionFinderVisitor extends GAstVisitor {\n    constructor(targetOccurrence, targetProdType, targetRef) {\n      super();\n      this.targetOccurrence = targetOccurrence;\n      this.targetProdType = targetProdType;\n      this.targetRef = targetRef;\n      this.result = [];\n    }\n    checkIsTarget(node, expectedProdName) {\n      if (node.idx === this.targetOccurrence && this.targetProdType === expectedProdName && (this.targetRef === void 0 || node === this.targetRef)) {\n        this.result = node.definition;\n      }\n    }\n    visitOption(node) {\n      this.checkIsTarget(node, PROD_TYPE.OPTION);\n    }\n    visitRepetition(node) {\n      this.checkIsTarget(node, PROD_TYPE.REPETITION);\n    }\n    visitRepetitionMandatory(node) {\n      this.checkIsTarget(node, PROD_TYPE.REPETITION_MANDATORY);\n    }\n    visitRepetitionMandatoryWithSeparator(node) {\n      this.checkIsTarget(node, PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR);\n    }\n    visitRepetitionWithSeparator(node) {\n      this.checkIsTarget(node, PROD_TYPE.REPETITION_WITH_SEPARATOR);\n    }\n    visitAlternation(node) {\n      this.checkIsTarget(node, PROD_TYPE.ALTERNATION);\n    }\n  }\n  function initializeArrayOfArrays(size) {\n    const result = new Array(size);\n    for (let i = 0; i < size; i++) {\n      result[i] = [];\n    }\n    return result;\n  }\n  function pathToHashKeys(path) {\n    let keys2 = [\"\"];\n    for (let i = 0; i < path.length; i++) {\n      const tokType = path[i];\n      const longerKeys = [];\n      for (let j = 0; j < keys2.length; j++) {\n        const currShorterKey = keys2[j];\n        longerKeys.push(currShorterKey + \"_\" + tokType.tokenTypeIdx);\n        for (let t = 0; t < tokType.categoryMatches.length; t++) {\n          const categoriesKeySuffix = \"_\" + tokType.categoryMatches[t];\n          longerKeys.push(currShorterKey + categoriesKeySuffix);\n        }\n      }\n      keys2 = longerKeys;\n    }\n    return keys2;\n  }\n  function isUniquePrefixHash(altKnownPathsKeys, searchPathKeys, idx) {\n    for (let currAltIdx = 0; currAltIdx < altKnownPathsKeys.length; currAltIdx++) {\n      if (currAltIdx === idx) {\n        continue;\n      }\n      const otherAltKnownPathsKeys = altKnownPathsKeys[currAltIdx];\n      for (let searchIdx = 0; searchIdx < searchPathKeys.length; searchIdx++) {\n        const searchKey = searchPathKeys[searchIdx];\n        if (otherAltKnownPathsKeys[searchKey] === true) {\n          return false;\n        }\n      }\n    }\n    return true;\n  }\n  function lookAheadSequenceFromAlternatives(altsDefs, k) {\n    const partialAlts = map(altsDefs, currAlt => possiblePathsFrom([currAlt], 1));\n    const finalResult = initializeArrayOfArrays(partialAlts.length);\n    const altsHashes = map(partialAlts, currAltPaths => {\n      const dict = {};\n      forEach(currAltPaths, item => {\n        const keys2 = pathToHashKeys(item.partialPath);\n        forEach(keys2, currKey => {\n          dict[currKey] = true;\n        });\n      });\n      return dict;\n    });\n    let newData = partialAlts;\n    for (let pathLength = 1; pathLength <= k; pathLength++) {\n      const currDataset = newData;\n      newData = initializeArrayOfArrays(currDataset.length);\n      for (let altIdx = 0; altIdx < currDataset.length; altIdx++) {\n        const currAltPathsAndSuffixes = currDataset[altIdx];\n        for (let currPathIdx = 0; currPathIdx < currAltPathsAndSuffixes.length; currPathIdx++) {\n          const currPathPrefix = currAltPathsAndSuffixes[currPathIdx].partialPath;\n          const suffixDef = currAltPathsAndSuffixes[currPathIdx].suffixDef;\n          const prefixKeys = pathToHashKeys(currPathPrefix);\n          const isUnique = isUniquePrefixHash(altsHashes, prefixKeys, altIdx);\n          if (isUnique || isEmpty(suffixDef) || currPathPrefix.length === k) {\n            const currAltResult = finalResult[altIdx];\n            if (containsPath(currAltResult, currPathPrefix) === false) {\n              currAltResult.push(currPathPrefix);\n              for (let j = 0; j < prefixKeys.length; j++) {\n                const currKey = prefixKeys[j];\n                altsHashes[altIdx][currKey] = true;\n              }\n            }\n          } else {\n            const newPartialPathsAndSuffixes = possiblePathsFrom(suffixDef, pathLength + 1, currPathPrefix);\n            newData[altIdx] = newData[altIdx].concat(newPartialPathsAndSuffixes);\n            forEach(newPartialPathsAndSuffixes, item => {\n              const prefixKeys2 = pathToHashKeys(item.partialPath);\n              forEach(prefixKeys2, key => {\n                altsHashes[altIdx][key] = true;\n              });\n            });\n          }\n        }\n      }\n    }\n    return finalResult;\n  }\n  function getLookaheadPathsForOr(occurrence, ruleGrammar, k, orProd) {\n    const visitor = new InsideDefinitionFinderVisitor(occurrence, PROD_TYPE.ALTERNATION, orProd);\n    ruleGrammar.accept(visitor);\n    return lookAheadSequenceFromAlternatives(visitor.result, k);\n  }\n  function getLookaheadPathsForOptionalProd(occurrence, ruleGrammar, prodType, k) {\n    const insideDefVisitor = new InsideDefinitionFinderVisitor(occurrence, prodType);\n    ruleGrammar.accept(insideDefVisitor);\n    const insideDef = insideDefVisitor.result;\n    const afterDefWalker = new RestDefinitionFinderWalker(ruleGrammar, occurrence, prodType);\n    const afterDef = afterDefWalker.startWalking();\n    const insideFlat = new Alternative({\n      definition: insideDef\n    });\n    const afterFlat = new Alternative({\n      definition: afterDef\n    });\n    return lookAheadSequenceFromAlternatives([insideFlat, afterFlat], k);\n  }\n  function containsPath(alternative, searchPath) {\n    compareOtherPath: for (let i = 0; i < alternative.length; i++) {\n      const otherPath = alternative[i];\n      if (otherPath.length !== searchPath.length) {\n        continue;\n      }\n      for (let j = 0; j < otherPath.length; j++) {\n        const searchTok = searchPath[j];\n        const otherTok = otherPath[j];\n        const matchingTokens = searchTok === otherTok || otherTok.categoryMatchesMap[searchTok.tokenTypeIdx] !== void 0;\n        if (matchingTokens === false) {\n          continue compareOtherPath;\n        }\n      }\n      return true;\n    }\n    return false;\n  }\n  function isStrictPrefixOfPath(prefix, other) {\n    return prefix.length < other.length && every(prefix, (tokType, idx) => {\n      const otherTokType = other[idx];\n      return tokType === otherTokType || otherTokType.categoryMatchesMap[tokType.tokenTypeIdx];\n    });\n  }\n  function areTokenCategoriesNotUsed(lookAheadPaths) {\n    return every(lookAheadPaths, singleAltPaths => every(singleAltPaths, singlePath => every(singlePath, token => isEmpty(token.categoryMatches))));\n  }\n  function validateLookahead(options) {\n    const lookaheadValidationErrorMessages = options.lookaheadStrategy.validate({\n      rules: options.rules,\n      tokenTypes: options.tokenTypes,\n      grammarName: options.grammarName\n    });\n    return map(lookaheadValidationErrorMessages, errorMessage => Object.assign({\n      type: ParserDefinitionErrorType.CUSTOM_LOOKAHEAD_VALIDATION\n    }, errorMessage));\n  }\n  function validateGrammar$1(topLevels, tokenTypes, errMsgProvider, grammarName) {\n    const duplicateErrors = flatMap(topLevels, currTopLevel => validateDuplicateProductions(currTopLevel, errMsgProvider));\n    const termsNamespaceConflictErrors = checkTerminalAndNoneTerminalsNameSpace(topLevels, tokenTypes, errMsgProvider);\n    const tooManyAltsErrors = flatMap(topLevels, curRule => validateTooManyAlts(curRule, errMsgProvider));\n    const duplicateRulesError = flatMap(topLevels, curRule => validateRuleDoesNotAlreadyExist(curRule, topLevels, grammarName, errMsgProvider));\n    return duplicateErrors.concat(termsNamespaceConflictErrors, tooManyAltsErrors, duplicateRulesError);\n  }\n  function validateDuplicateProductions(topLevelRule, errMsgProvider) {\n    const collectorVisitor2 = new OccurrenceValidationCollector();\n    topLevelRule.accept(collectorVisitor2);\n    const allRuleProductions = collectorVisitor2.allProductions;\n    const productionGroups = groupBy$1(allRuleProductions, identifyProductionForDuplicates);\n    const duplicates = pickBy(productionGroups, currGroup => {\n      return currGroup.length > 1;\n    });\n    const errors = map(values(duplicates), currDuplicates => {\n      const firstProd = head(currDuplicates);\n      const msg = errMsgProvider.buildDuplicateFoundError(topLevelRule, currDuplicates);\n      const dslName = getProductionDslName(firstProd);\n      const defError = {\n        message: msg,\n        type: ParserDefinitionErrorType.DUPLICATE_PRODUCTIONS,\n        ruleName: topLevelRule.name,\n        dslName,\n        occurrence: firstProd.idx\n      };\n      const param = getExtraProductionArgument(firstProd);\n      if (param) {\n        defError.parameter = param;\n      }\n      return defError;\n    });\n    return errors;\n  }\n  function identifyProductionForDuplicates(prod) {\n    return `${getProductionDslName(prod)}_#_${prod.idx}_#_${getExtraProductionArgument(prod)}`;\n  }\n  function getExtraProductionArgument(prod) {\n    if (prod instanceof Terminal) {\n      return prod.terminalType.name;\n    } else if (prod instanceof NonTerminal) {\n      return prod.nonTerminalName;\n    } else {\n      return \"\";\n    }\n  }\n  class OccurrenceValidationCollector extends GAstVisitor {\n    constructor() {\n      super(...arguments);\n      this.allProductions = [];\n    }\n    visitNonTerminal(subrule) {\n      this.allProductions.push(subrule);\n    }\n    visitOption(option) {\n      this.allProductions.push(option);\n    }\n    visitRepetitionWithSeparator(manySep) {\n      this.allProductions.push(manySep);\n    }\n    visitRepetitionMandatory(atLeastOne) {\n      this.allProductions.push(atLeastOne);\n    }\n    visitRepetitionMandatoryWithSeparator(atLeastOneSep) {\n      this.allProductions.push(atLeastOneSep);\n    }\n    visitRepetition(many) {\n      this.allProductions.push(many);\n    }\n    visitAlternation(or) {\n      this.allProductions.push(or);\n    }\n    visitTerminal(terminal) {\n      this.allProductions.push(terminal);\n    }\n  }\n  function validateRuleDoesNotAlreadyExist(rule, allRules, className, errMsgProvider) {\n    const errors = [];\n    const occurrences = reduce(allRules, (result, curRule) => {\n      if (curRule.name === rule.name) {\n        return result + 1;\n      }\n      return result;\n    }, 0);\n    if (occurrences > 1) {\n      const errMsg = errMsgProvider.buildDuplicateRuleNameError({\n        topLevelRule: rule,\n        grammarName: className\n      });\n      errors.push({\n        message: errMsg,\n        type: ParserDefinitionErrorType.DUPLICATE_RULE_NAME,\n        ruleName: rule.name\n      });\n    }\n    return errors;\n  }\n  function validateRuleIsOverridden(ruleName, definedRulesNames, className) {\n    const errors = [];\n    let errMsg;\n    if (!includes(definedRulesNames, ruleName)) {\n      errMsg = `Invalid rule override, rule: ->${ruleName}<- cannot be overridden in the grammar: ->${className}<-as it is not defined in any of the super grammars `;\n      errors.push({\n        message: errMsg,\n        type: ParserDefinitionErrorType.INVALID_RULE_OVERRIDE,\n        ruleName\n      });\n    }\n    return errors;\n  }\n  function validateNoLeftRecursion(topRule, currRule, errMsgProvider, path = []) {\n    const errors = [];\n    const nextNonTerminals = getFirstNoneTerminal(currRule.definition);\n    if (isEmpty(nextNonTerminals)) {\n      return [];\n    } else {\n      const ruleName = topRule.name;\n      const foundLeftRecursion = includes(nextNonTerminals, topRule);\n      if (foundLeftRecursion) {\n        errors.push({\n          message: errMsgProvider.buildLeftRecursionError({\n            topLevelRule: topRule,\n            leftRecursionPath: path\n          }),\n          type: ParserDefinitionErrorType.LEFT_RECURSION,\n          ruleName\n        });\n      }\n      const validNextSteps = difference$1(nextNonTerminals, path.concat([topRule]));\n      const errorsFromNextSteps = flatMap(validNextSteps, currRefRule => {\n        const newPath = clone(path);\n        newPath.push(currRefRule);\n        return validateNoLeftRecursion(topRule, currRefRule, errMsgProvider, newPath);\n      });\n      return errors.concat(errorsFromNextSteps);\n    }\n  }\n  function getFirstNoneTerminal(definition) {\n    let result = [];\n    if (isEmpty(definition)) {\n      return result;\n    }\n    const firstProd = head(definition);\n    if (firstProd instanceof NonTerminal) {\n      result.push(firstProd.referencedRule);\n    } else if (firstProd instanceof Alternative || firstProd instanceof Option || firstProd instanceof RepetitionMandatory || firstProd instanceof RepetitionMandatoryWithSeparator || firstProd instanceof RepetitionWithSeparator || firstProd instanceof Repetition) {\n      result = result.concat(getFirstNoneTerminal(firstProd.definition));\n    } else if (firstProd instanceof Alternation) {\n      result = flatten(map(firstProd.definition, currSubDef => getFirstNoneTerminal(currSubDef.definition)));\n    } else if (firstProd instanceof Terminal) ;else {\n      throw Error(\"non exhaustive match\");\n    }\n    const isFirstOptional = isOptionalProd(firstProd);\n    const hasMore = definition.length > 1;\n    if (isFirstOptional && hasMore) {\n      const rest = drop(definition);\n      return result.concat(getFirstNoneTerminal(rest));\n    } else {\n      return result;\n    }\n  }\n  class OrCollector extends GAstVisitor {\n    constructor() {\n      super(...arguments);\n      this.alternations = [];\n    }\n    visitAlternation(node) {\n      this.alternations.push(node);\n    }\n  }\n  function validateEmptyOrAlternative(topLevelRule, errMsgProvider) {\n    const orCollector = new OrCollector();\n    topLevelRule.accept(orCollector);\n    const ors = orCollector.alternations;\n    const errors = flatMap(ors, currOr => {\n      const exceptLast = dropRight(currOr.definition);\n      return flatMap(exceptLast, (currAlternative, currAltIdx) => {\n        const possibleFirstInAlt = nextPossibleTokensAfter([currAlternative], [], tokenStructuredMatcher, 1);\n        if (isEmpty(possibleFirstInAlt)) {\n          return [{\n            message: errMsgProvider.buildEmptyAlternationError({\n              topLevelRule,\n              alternation: currOr,\n              emptyChoiceIdx: currAltIdx\n            }),\n            type: ParserDefinitionErrorType.NONE_LAST_EMPTY_ALT,\n            ruleName: topLevelRule.name,\n            occurrence: currOr.idx,\n            alternative: currAltIdx + 1\n          }];\n        } else {\n          return [];\n        }\n      });\n    });\n    return errors;\n  }\n  function validateAmbiguousAlternationAlternatives(topLevelRule, globalMaxLookahead, errMsgProvider) {\n    const orCollector = new OrCollector();\n    topLevelRule.accept(orCollector);\n    let ors = orCollector.alternations;\n    ors = reject(ors, currOr => currOr.ignoreAmbiguities === true);\n    const errors = flatMap(ors, currOr => {\n      const currOccurrence = currOr.idx;\n      const actualMaxLookahead = currOr.maxLookahead || globalMaxLookahead;\n      const alternatives = getLookaheadPathsForOr(currOccurrence, topLevelRule, actualMaxLookahead, currOr);\n      const altsAmbiguityErrors = checkAlternativesAmbiguities(alternatives, currOr, topLevelRule, errMsgProvider);\n      const altsPrefixAmbiguityErrors = checkPrefixAlternativesAmbiguities(alternatives, currOr, topLevelRule, errMsgProvider);\n      return altsAmbiguityErrors.concat(altsPrefixAmbiguityErrors);\n    });\n    return errors;\n  }\n  class RepetitionCollector extends GAstVisitor {\n    constructor() {\n      super(...arguments);\n      this.allProductions = [];\n    }\n    visitRepetitionWithSeparator(manySep) {\n      this.allProductions.push(manySep);\n    }\n    visitRepetitionMandatory(atLeastOne) {\n      this.allProductions.push(atLeastOne);\n    }\n    visitRepetitionMandatoryWithSeparator(atLeastOneSep) {\n      this.allProductions.push(atLeastOneSep);\n    }\n    visitRepetition(many) {\n      this.allProductions.push(many);\n    }\n  }\n  function validateTooManyAlts(topLevelRule, errMsgProvider) {\n    const orCollector = new OrCollector();\n    topLevelRule.accept(orCollector);\n    const ors = orCollector.alternations;\n    const errors = flatMap(ors, currOr => {\n      if (currOr.definition.length > 255) {\n        return [{\n          message: errMsgProvider.buildTooManyAlternativesError({\n            topLevelRule,\n            alternation: currOr\n          }),\n          type: ParserDefinitionErrorType.TOO_MANY_ALTS,\n          ruleName: topLevelRule.name,\n          occurrence: currOr.idx\n        }];\n      } else {\n        return [];\n      }\n    });\n    return errors;\n  }\n  function validateSomeNonEmptyLookaheadPath(topLevelRules, maxLookahead, errMsgProvider) {\n    const errors = [];\n    forEach(topLevelRules, currTopRule => {\n      const collectorVisitor2 = new RepetitionCollector();\n      currTopRule.accept(collectorVisitor2);\n      const allRuleProductions = collectorVisitor2.allProductions;\n      forEach(allRuleProductions, currProd => {\n        const prodType = getProdType(currProd);\n        const actualMaxLookahead = currProd.maxLookahead || maxLookahead;\n        const currOccurrence = currProd.idx;\n        const paths = getLookaheadPathsForOptionalProd(currOccurrence, currTopRule, prodType, actualMaxLookahead);\n        const pathsInsideProduction = paths[0];\n        if (isEmpty(flatten(pathsInsideProduction))) {\n          const errMsg = errMsgProvider.buildEmptyRepetitionError({\n            topLevelRule: currTopRule,\n            repetition: currProd\n          });\n          errors.push({\n            message: errMsg,\n            type: ParserDefinitionErrorType.NO_NON_EMPTY_LOOKAHEAD,\n            ruleName: currTopRule.name\n          });\n        }\n      });\n    });\n    return errors;\n  }\n  function checkAlternativesAmbiguities(alternatives, alternation, rule, errMsgProvider) {\n    const foundAmbiguousPaths = [];\n    const identicalAmbiguities = reduce(alternatives, (result, currAlt, currAltIdx) => {\n      if (alternation.definition[currAltIdx].ignoreAmbiguities === true) {\n        return result;\n      }\n      forEach(currAlt, currPath => {\n        const altsCurrPathAppearsIn = [currAltIdx];\n        forEach(alternatives, (currOtherAlt, currOtherAltIdx) => {\n          if (currAltIdx !== currOtherAltIdx && containsPath(currOtherAlt, currPath) &&\n          // ignore (skip) ambiguities with this \"other\" alternative\n          alternation.definition[currOtherAltIdx].ignoreAmbiguities !== true) {\n            altsCurrPathAppearsIn.push(currOtherAltIdx);\n          }\n        });\n        if (altsCurrPathAppearsIn.length > 1 && !containsPath(foundAmbiguousPaths, currPath)) {\n          foundAmbiguousPaths.push(currPath);\n          result.push({\n            alts: altsCurrPathAppearsIn,\n            path: currPath\n          });\n        }\n      });\n      return result;\n    }, []);\n    const currErrors = map(identicalAmbiguities, currAmbDescriptor => {\n      const ambgIndices = map(currAmbDescriptor.alts, currAltIdx => currAltIdx + 1);\n      const currMessage = errMsgProvider.buildAlternationAmbiguityError({\n        topLevelRule: rule,\n        alternation,\n        ambiguityIndices: ambgIndices,\n        prefixPath: currAmbDescriptor.path\n      });\n      return {\n        message: currMessage,\n        type: ParserDefinitionErrorType.AMBIGUOUS_ALTS,\n        ruleName: rule.name,\n        occurrence: alternation.idx,\n        alternatives: currAmbDescriptor.alts\n      };\n    });\n    return currErrors;\n  }\n  function checkPrefixAlternativesAmbiguities(alternatives, alternation, rule, errMsgProvider) {\n    const pathsAndIndices = reduce(alternatives, (result, currAlt, idx) => {\n      const currPathsAndIdx = map(currAlt, currPath => {\n        return {\n          idx,\n          path: currPath\n        };\n      });\n      return result.concat(currPathsAndIdx);\n    }, []);\n    const errors = compact(flatMap(pathsAndIndices, currPathAndIdx => {\n      const alternativeGast = alternation.definition[currPathAndIdx.idx];\n      if (alternativeGast.ignoreAmbiguities === true) {\n        return [];\n      }\n      const targetIdx = currPathAndIdx.idx;\n      const targetPath = currPathAndIdx.path;\n      const prefixAmbiguitiesPathsAndIndices = filter(pathsAndIndices, searchPathAndIdx => {\n        return (\n          // ignore (skip) ambiguities with this \"other\" alternative\n          alternation.definition[searchPathAndIdx.idx].ignoreAmbiguities !== true && searchPathAndIdx.idx < targetIdx &&\n          // checking for strict prefix because identical lookaheads\n          // will be be detected using a different validation.\n          isStrictPrefixOfPath(searchPathAndIdx.path, targetPath)\n        );\n      });\n      const currPathPrefixErrors = map(prefixAmbiguitiesPathsAndIndices, currAmbPathAndIdx => {\n        const ambgIndices = [currAmbPathAndIdx.idx + 1, targetIdx + 1];\n        const occurrence = alternation.idx === 0 ? \"\" : alternation.idx;\n        const message = errMsgProvider.buildAlternationPrefixAmbiguityError({\n          topLevelRule: rule,\n          alternation,\n          ambiguityIndices: ambgIndices,\n          prefixPath: currAmbPathAndIdx.path\n        });\n        return {\n          message,\n          type: ParserDefinitionErrorType.AMBIGUOUS_PREFIX_ALTS,\n          ruleName: rule.name,\n          occurrence,\n          alternatives: ambgIndices\n        };\n      });\n      return currPathPrefixErrors;\n    }));\n    return errors;\n  }\n  function checkTerminalAndNoneTerminalsNameSpace(topLevels, tokenTypes, errMsgProvider) {\n    const errors = [];\n    const tokenNames = map(tokenTypes, currToken => currToken.name);\n    forEach(topLevels, currRule => {\n      const currRuleName = currRule.name;\n      if (includes(tokenNames, currRuleName)) {\n        const errMsg = errMsgProvider.buildNamespaceConflictError(currRule);\n        errors.push({\n          message: errMsg,\n          type: ParserDefinitionErrorType.CONFLICT_TOKENS_RULES_NAMESPACE,\n          ruleName: currRuleName\n        });\n      }\n    });\n    return errors;\n  }\n  function resolveGrammar(options) {\n    const actualOptions = defaults$1(options, {\n      errMsgProvider: defaultGrammarResolverErrorProvider\n    });\n    const topRulesTable = {};\n    forEach(options.rules, rule => {\n      topRulesTable[rule.name] = rule;\n    });\n    return resolveGrammar$1(topRulesTable, actualOptions.errMsgProvider);\n  }\n  function validateGrammar(options) {\n    options = defaults$1(options, {\n      errMsgProvider: defaultGrammarValidatorErrorProvider\n    });\n    return validateGrammar$1(options.rules, options.tokenTypes, options.errMsgProvider, options.grammarName);\n  }\n  const MISMATCHED_TOKEN_EXCEPTION = \"MismatchedTokenException\";\n  const NO_VIABLE_ALT_EXCEPTION = \"NoViableAltException\";\n  const EARLY_EXIT_EXCEPTION = \"EarlyExitException\";\n  const NOT_ALL_INPUT_PARSED_EXCEPTION = \"NotAllInputParsedException\";\n  const RECOGNITION_EXCEPTION_NAMES = [MISMATCHED_TOKEN_EXCEPTION, NO_VIABLE_ALT_EXCEPTION, EARLY_EXIT_EXCEPTION, NOT_ALL_INPUT_PARSED_EXCEPTION];\n  Object.freeze(RECOGNITION_EXCEPTION_NAMES);\n  function isRecognitionException(error) {\n    return includes(RECOGNITION_EXCEPTION_NAMES, error.name);\n  }\n  class RecognitionException extends Error {\n    constructor(message, token) {\n      super(message);\n      this.token = token;\n      this.resyncedTokens = [];\n      Object.setPrototypeOf(this, new.target.prototype);\n      if (Error.captureStackTrace) {\n        Error.captureStackTrace(this, this.constructor);\n      }\n    }\n  }\n  class MismatchedTokenException extends RecognitionException {\n    constructor(message, token, previousToken) {\n      super(message, token);\n      this.previousToken = previousToken;\n      this.name = MISMATCHED_TOKEN_EXCEPTION;\n    }\n  }\n  class NoViableAltException extends RecognitionException {\n    constructor(message, token, previousToken) {\n      super(message, token);\n      this.previousToken = previousToken;\n      this.name = NO_VIABLE_ALT_EXCEPTION;\n    }\n  }\n  class NotAllInputParsedException extends RecognitionException {\n    constructor(message, token) {\n      super(message, token);\n      this.name = NOT_ALL_INPUT_PARSED_EXCEPTION;\n    }\n  }\n  class EarlyExitException extends RecognitionException {\n    constructor(message, token, previousToken) {\n      super(message, token);\n      this.previousToken = previousToken;\n      this.name = EARLY_EXIT_EXCEPTION;\n    }\n  }\n  const EOF_FOLLOW_KEY = {};\n  const IN_RULE_RECOVERY_EXCEPTION = \"InRuleRecoveryException\";\n  class InRuleRecoveryException extends Error {\n    constructor(message) {\n      super(message);\n      this.name = IN_RULE_RECOVERY_EXCEPTION;\n    }\n  }\n  class Recoverable {\n    initRecoverable(config) {\n      this.firstAfterRepMap = {};\n      this.resyncFollows = {};\n      this.recoveryEnabled = has(config, \"recoveryEnabled\") ? config.recoveryEnabled : DEFAULT_PARSER_CONFIG.recoveryEnabled;\n      if (this.recoveryEnabled) {\n        this.attemptInRepetitionRecovery = attemptInRepetitionRecovery;\n      }\n    }\n    getTokenToInsert(tokType) {\n      const tokToInsert = createTokenInstance(tokType, \"\", NaN, NaN, NaN, NaN, NaN, NaN);\n      tokToInsert.isInsertedInRecovery = true;\n      return tokToInsert;\n    }\n    canTokenTypeBeInsertedInRecovery(tokType) {\n      return true;\n    }\n    canTokenTypeBeDeletedInRecovery(tokType) {\n      return true;\n    }\n    tryInRepetitionRecovery(grammarRule, grammarRuleArgs, lookAheadFunc, expectedTokType) {\n      const reSyncTokType = this.findReSyncTokenType();\n      const savedLexerState = this.exportLexerState();\n      const resyncedTokens = [];\n      let passedResyncPoint = false;\n      const nextTokenWithoutResync = this.LA(1);\n      let currToken = this.LA(1);\n      const generateErrorMessage = () => {\n        const previousToken = this.LA(0);\n        const msg = this.errorMessageProvider.buildMismatchTokenMessage({\n          expected: expectedTokType,\n          actual: nextTokenWithoutResync,\n          previous: previousToken,\n          ruleName: this.getCurrRuleFullName()\n        });\n        const error = new MismatchedTokenException(msg, nextTokenWithoutResync, this.LA(0));\n        error.resyncedTokens = dropRight(resyncedTokens);\n        this.SAVE_ERROR(error);\n      };\n      while (!passedResyncPoint) {\n        if (this.tokenMatcher(currToken, expectedTokType)) {\n          generateErrorMessage();\n          return;\n        } else if (lookAheadFunc.call(this)) {\n          generateErrorMessage();\n          grammarRule.apply(this, grammarRuleArgs);\n          return;\n        } else if (this.tokenMatcher(currToken, reSyncTokType)) {\n          passedResyncPoint = true;\n        } else {\n          currToken = this.SKIP_TOKEN();\n          this.addToResyncTokens(currToken, resyncedTokens);\n        }\n      }\n      this.importLexerState(savedLexerState);\n    }\n    shouldInRepetitionRecoveryBeTried(expectTokAfterLastMatch, nextTokIdx, notStuck) {\n      if (notStuck === false) {\n        return false;\n      }\n      if (this.tokenMatcher(this.LA(1), expectTokAfterLastMatch)) {\n        return false;\n      }\n      if (this.isBackTracking()) {\n        return false;\n      }\n      if (this.canPerformInRuleRecovery(expectTokAfterLastMatch, this.getFollowsForInRuleRecovery(expectTokAfterLastMatch, nextTokIdx))) {\n        return false;\n      }\n      return true;\n    }\n    // Error Recovery functionality\n    getFollowsForInRuleRecovery(tokType, tokIdxInRule) {\n      const grammarPath = this.getCurrentGrammarPath(tokType, tokIdxInRule);\n      const follows = this.getNextPossibleTokenTypes(grammarPath);\n      return follows;\n    }\n    tryInRuleRecovery(expectedTokType, follows) {\n      if (this.canRecoverWithSingleTokenInsertion(expectedTokType, follows)) {\n        const tokToInsert = this.getTokenToInsert(expectedTokType);\n        return tokToInsert;\n      }\n      if (this.canRecoverWithSingleTokenDeletion(expectedTokType)) {\n        const nextTok = this.SKIP_TOKEN();\n        this.consumeToken();\n        return nextTok;\n      }\n      throw new InRuleRecoveryException(\"sad sad panda\");\n    }\n    canPerformInRuleRecovery(expectedToken, follows) {\n      return this.canRecoverWithSingleTokenInsertion(expectedToken, follows) || this.canRecoverWithSingleTokenDeletion(expectedToken);\n    }\n    canRecoverWithSingleTokenInsertion(expectedTokType, follows) {\n      if (!this.canTokenTypeBeInsertedInRecovery(expectedTokType)) {\n        return false;\n      }\n      if (isEmpty(follows)) {\n        return false;\n      }\n      const mismatchedTok = this.LA(1);\n      const isMisMatchedTokInFollows = find$1(follows, possibleFollowsTokType => {\n        return this.tokenMatcher(mismatchedTok, possibleFollowsTokType);\n      }) !== void 0;\n      return isMisMatchedTokInFollows;\n    }\n    canRecoverWithSingleTokenDeletion(expectedTokType) {\n      if (!this.canTokenTypeBeDeletedInRecovery(expectedTokType)) {\n        return false;\n      }\n      const isNextTokenWhatIsExpected = this.tokenMatcher(this.LA(2), expectedTokType);\n      return isNextTokenWhatIsExpected;\n    }\n    isInCurrentRuleReSyncSet(tokenTypeIdx) {\n      const followKey = this.getCurrFollowKey();\n      const currentRuleReSyncSet = this.getFollowSetFromFollowKey(followKey);\n      return includes(currentRuleReSyncSet, tokenTypeIdx);\n    }\n    findReSyncTokenType() {\n      const allPossibleReSyncTokTypes = this.flattenFollowSet();\n      let nextToken = this.LA(1);\n      let k = 2;\n      while (true) {\n        const foundMatch = find$1(allPossibleReSyncTokTypes, resyncTokType => {\n          const canMatch = tokenMatcher(nextToken, resyncTokType);\n          return canMatch;\n        });\n        if (foundMatch !== void 0) {\n          return foundMatch;\n        }\n        nextToken = this.LA(k);\n        k++;\n      }\n    }\n    getCurrFollowKey() {\n      if (this.RULE_STACK.length === 1) {\n        return EOF_FOLLOW_KEY;\n      }\n      const currRuleShortName = this.getLastExplicitRuleShortName();\n      const currRuleIdx = this.getLastExplicitRuleOccurrenceIndex();\n      const prevRuleShortName = this.getPreviousExplicitRuleShortName();\n      return {\n        ruleName: this.shortRuleNameToFullName(currRuleShortName),\n        idxInCallingRule: currRuleIdx,\n        inRule: this.shortRuleNameToFullName(prevRuleShortName)\n      };\n    }\n    buildFullFollowKeyStack() {\n      const explicitRuleStack = this.RULE_STACK;\n      const explicitOccurrenceStack = this.RULE_OCCURRENCE_STACK;\n      return map(explicitRuleStack, (ruleName, idx) => {\n        if (idx === 0) {\n          return EOF_FOLLOW_KEY;\n        }\n        return {\n          ruleName: this.shortRuleNameToFullName(ruleName),\n          idxInCallingRule: explicitOccurrenceStack[idx],\n          inRule: this.shortRuleNameToFullName(explicitRuleStack[idx - 1])\n        };\n      });\n    }\n    flattenFollowSet() {\n      const followStack = map(this.buildFullFollowKeyStack(), currKey => {\n        return this.getFollowSetFromFollowKey(currKey);\n      });\n      return flatten(followStack);\n    }\n    getFollowSetFromFollowKey(followKey) {\n      if (followKey === EOF_FOLLOW_KEY) {\n        return [EOF];\n      }\n      const followName = followKey.ruleName + followKey.idxInCallingRule + IN + followKey.inRule;\n      return this.resyncFollows[followName];\n    }\n    // It does not make any sense to include a virtual EOF token in the list of resynced tokens\n    // as EOF does not really exist and thus does not contain any useful information (line/column numbers)\n    addToResyncTokens(token, resyncTokens) {\n      if (!this.tokenMatcher(token, EOF)) {\n        resyncTokens.push(token);\n      }\n      return resyncTokens;\n    }\n    reSyncTo(tokType) {\n      const resyncedTokens = [];\n      let nextTok = this.LA(1);\n      while (this.tokenMatcher(nextTok, tokType) === false) {\n        nextTok = this.SKIP_TOKEN();\n        this.addToResyncTokens(nextTok, resyncedTokens);\n      }\n      return dropRight(resyncedTokens);\n    }\n    attemptInRepetitionRecovery(prodFunc, args, lookaheadFunc, dslMethodIdx, prodOccurrence, nextToksWalker, notStuck) {}\n    getCurrentGrammarPath(tokType, tokIdxInRule) {\n      const pathRuleStack = this.getHumanReadableRuleStack();\n      const pathOccurrenceStack = clone(this.RULE_OCCURRENCE_STACK);\n      const grammarPath = {\n        ruleStack: pathRuleStack,\n        occurrenceStack: pathOccurrenceStack,\n        lastTok: tokType,\n        lastTokOccurrence: tokIdxInRule\n      };\n      return grammarPath;\n    }\n    getHumanReadableRuleStack() {\n      return map(this.RULE_STACK, currShortName => this.shortRuleNameToFullName(currShortName));\n    }\n  }\n  function attemptInRepetitionRecovery(prodFunc, args, lookaheadFunc, dslMethodIdx, prodOccurrence, nextToksWalker, notStuck) {\n    const key = this.getKeyForAutomaticLookahead(dslMethodIdx, prodOccurrence);\n    let firstAfterRepInfo = this.firstAfterRepMap[key];\n    if (firstAfterRepInfo === void 0) {\n      const currRuleName = this.getCurrRuleFullName();\n      const ruleGrammar = this.getGAstProductions()[currRuleName];\n      const walker = new nextToksWalker(ruleGrammar, prodOccurrence);\n      firstAfterRepInfo = walker.startWalking();\n      this.firstAfterRepMap[key] = firstAfterRepInfo;\n    }\n    let expectTokAfterLastMatch = firstAfterRepInfo.token;\n    let nextTokIdx = firstAfterRepInfo.occurrence;\n    const isEndOfRule = firstAfterRepInfo.isEndOfRule;\n    if (this.RULE_STACK.length === 1 && isEndOfRule && expectTokAfterLastMatch === void 0) {\n      expectTokAfterLastMatch = EOF;\n      nextTokIdx = 1;\n    }\n    if (expectTokAfterLastMatch === void 0 || nextTokIdx === void 0) {\n      return;\n    }\n    if (this.shouldInRepetitionRecoveryBeTried(expectTokAfterLastMatch, nextTokIdx, notStuck)) {\n      this.tryInRepetitionRecovery(prodFunc, args, lookaheadFunc, expectTokAfterLastMatch);\n    }\n  }\n  const BITS_FOR_METHOD_TYPE = 4;\n  const BITS_FOR_OCCURRENCE_IDX = 8;\n  const OR_IDX = 1 << BITS_FOR_OCCURRENCE_IDX;\n  const OPTION_IDX = 2 << BITS_FOR_OCCURRENCE_IDX;\n  const MANY_IDX = 3 << BITS_FOR_OCCURRENCE_IDX;\n  const AT_LEAST_ONE_IDX = 4 << BITS_FOR_OCCURRENCE_IDX;\n  const MANY_SEP_IDX = 5 << BITS_FOR_OCCURRENCE_IDX;\n  const AT_LEAST_ONE_SEP_IDX = 6 << BITS_FOR_OCCURRENCE_IDX;\n  function getKeyForAutomaticLookahead(ruleIdx, dslMethodIdx, occurrence) {\n    return occurrence | dslMethodIdx | ruleIdx;\n  }\n  class LLkLookaheadStrategy {\n    constructor(options) {\n      var _a;\n      this.maxLookahead = (_a = options === null || options === void 0 ? void 0 : options.maxLookahead) !== null && _a !== void 0 ? _a : DEFAULT_PARSER_CONFIG.maxLookahead;\n    }\n    validate(options) {\n      const leftRecursionErrors = this.validateNoLeftRecursion(options.rules);\n      if (isEmpty(leftRecursionErrors)) {\n        const emptyAltErrors = this.validateEmptyOrAlternatives(options.rules);\n        const ambiguousAltsErrors = this.validateAmbiguousAlternationAlternatives(options.rules, this.maxLookahead);\n        const emptyRepetitionErrors = this.validateSomeNonEmptyLookaheadPath(options.rules, this.maxLookahead);\n        const allErrors = [...leftRecursionErrors, ...emptyAltErrors, ...ambiguousAltsErrors, ...emptyRepetitionErrors];\n        return allErrors;\n      }\n      return leftRecursionErrors;\n    }\n    validateNoLeftRecursion(rules) {\n      return flatMap(rules, currTopRule => validateNoLeftRecursion(currTopRule, currTopRule, defaultGrammarValidatorErrorProvider));\n    }\n    validateEmptyOrAlternatives(rules) {\n      return flatMap(rules, currTopRule => validateEmptyOrAlternative(currTopRule, defaultGrammarValidatorErrorProvider));\n    }\n    validateAmbiguousAlternationAlternatives(rules, maxLookahead) {\n      return flatMap(rules, currTopRule => validateAmbiguousAlternationAlternatives(currTopRule, maxLookahead, defaultGrammarValidatorErrorProvider));\n    }\n    validateSomeNonEmptyLookaheadPath(rules, maxLookahead) {\n      return validateSomeNonEmptyLookaheadPath(rules, maxLookahead, defaultGrammarValidatorErrorProvider);\n    }\n    buildLookaheadForAlternation(options) {\n      return buildLookaheadFuncForOr(options.prodOccurrence, options.rule, options.maxLookahead, options.hasPredicates, options.dynamicTokensEnabled, buildAlternativesLookAheadFunc);\n    }\n    buildLookaheadForOptional(options) {\n      return buildLookaheadFuncForOptionalProd(options.prodOccurrence, options.rule, options.maxLookahead, options.dynamicTokensEnabled, getProdType(options.prodType), buildSingleAlternativeLookaheadFunction);\n    }\n  }\n  class LooksAhead {\n    initLooksAhead(config) {\n      this.dynamicTokensEnabled = has(config, \"dynamicTokensEnabled\") ? config.dynamicTokensEnabled : DEFAULT_PARSER_CONFIG.dynamicTokensEnabled;\n      this.maxLookahead = has(config, \"maxLookahead\") ? config.maxLookahead : DEFAULT_PARSER_CONFIG.maxLookahead;\n      this.lookaheadStrategy = has(config, \"lookaheadStrategy\") ? config.lookaheadStrategy : new LLkLookaheadStrategy({\n        maxLookahead: this.maxLookahead\n      });\n      this.lookAheadFuncsCache = /* @__PURE__ */new Map();\n    }\n    preComputeLookaheadFunctions(rules) {\n      forEach(rules, currRule => {\n        this.TRACE_INIT(`${currRule.name} Rule Lookahead`, () => {\n          const {\n            alternation,\n            repetition,\n            option,\n            repetitionMandatory,\n            repetitionMandatoryWithSeparator,\n            repetitionWithSeparator\n          } = collectMethods(currRule);\n          forEach(alternation, currProd => {\n            const prodIdx = currProd.idx === 0 ? \"\" : currProd.idx;\n            this.TRACE_INIT(`${getProductionDslName(currProd)}${prodIdx}`, () => {\n              const laFunc = this.lookaheadStrategy.buildLookaheadForAlternation({\n                prodOccurrence: currProd.idx,\n                rule: currRule,\n                maxLookahead: currProd.maxLookahead || this.maxLookahead,\n                hasPredicates: currProd.hasPredicates,\n                dynamicTokensEnabled: this.dynamicTokensEnabled\n              });\n              const key = getKeyForAutomaticLookahead(this.fullRuleNameToShort[currRule.name], OR_IDX, currProd.idx);\n              this.setLaFuncCache(key, laFunc);\n            });\n          });\n          forEach(repetition, currProd => {\n            this.computeLookaheadFunc(currRule, currProd.idx, MANY_IDX, \"Repetition\", currProd.maxLookahead, getProductionDslName(currProd));\n          });\n          forEach(option, currProd => {\n            this.computeLookaheadFunc(currRule, currProd.idx, OPTION_IDX, \"Option\", currProd.maxLookahead, getProductionDslName(currProd));\n          });\n          forEach(repetitionMandatory, currProd => {\n            this.computeLookaheadFunc(currRule, currProd.idx, AT_LEAST_ONE_IDX, \"RepetitionMandatory\", currProd.maxLookahead, getProductionDslName(currProd));\n          });\n          forEach(repetitionMandatoryWithSeparator, currProd => {\n            this.computeLookaheadFunc(currRule, currProd.idx, AT_LEAST_ONE_SEP_IDX, \"RepetitionMandatoryWithSeparator\", currProd.maxLookahead, getProductionDslName(currProd));\n          });\n          forEach(repetitionWithSeparator, currProd => {\n            this.computeLookaheadFunc(currRule, currProd.idx, MANY_SEP_IDX, \"RepetitionWithSeparator\", currProd.maxLookahead, getProductionDslName(currProd));\n          });\n        });\n      });\n    }\n    computeLookaheadFunc(rule, prodOccurrence, prodKey, prodType, prodMaxLookahead, dslMethodName) {\n      this.TRACE_INIT(`${dslMethodName}${prodOccurrence === 0 ? \"\" : prodOccurrence}`, () => {\n        const laFunc = this.lookaheadStrategy.buildLookaheadForOptional({\n          prodOccurrence,\n          rule,\n          maxLookahead: prodMaxLookahead || this.maxLookahead,\n          dynamicTokensEnabled: this.dynamicTokensEnabled,\n          prodType\n        });\n        const key = getKeyForAutomaticLookahead(this.fullRuleNameToShort[rule.name], prodKey, prodOccurrence);\n        this.setLaFuncCache(key, laFunc);\n      });\n    }\n    // this actually returns a number, but it is always used as a string (object prop key)\n    getKeyForAutomaticLookahead(dslMethodIdx, occurrence) {\n      const currRuleShortName = this.getLastExplicitRuleShortName();\n      return getKeyForAutomaticLookahead(currRuleShortName, dslMethodIdx, occurrence);\n    }\n    getLaFuncFromCache(key) {\n      return this.lookAheadFuncsCache.get(key);\n    }\n    /* istanbul ignore next */\n    setLaFuncCache(key, value) {\n      this.lookAheadFuncsCache.set(key, value);\n    }\n  }\n  class DslMethodsCollectorVisitor extends GAstVisitor {\n    constructor() {\n      super(...arguments);\n      this.dslMethods = {\n        option: [],\n        alternation: [],\n        repetition: [],\n        repetitionWithSeparator: [],\n        repetitionMandatory: [],\n        repetitionMandatoryWithSeparator: []\n      };\n    }\n    reset() {\n      this.dslMethods = {\n        option: [],\n        alternation: [],\n        repetition: [],\n        repetitionWithSeparator: [],\n        repetitionMandatory: [],\n        repetitionMandatoryWithSeparator: []\n      };\n    }\n    visitOption(option) {\n      this.dslMethods.option.push(option);\n    }\n    visitRepetitionWithSeparator(manySep) {\n      this.dslMethods.repetitionWithSeparator.push(manySep);\n    }\n    visitRepetitionMandatory(atLeastOne) {\n      this.dslMethods.repetitionMandatory.push(atLeastOne);\n    }\n    visitRepetitionMandatoryWithSeparator(atLeastOneSep) {\n      this.dslMethods.repetitionMandatoryWithSeparator.push(atLeastOneSep);\n    }\n    visitRepetition(many) {\n      this.dslMethods.repetition.push(many);\n    }\n    visitAlternation(or) {\n      this.dslMethods.alternation.push(or);\n    }\n  }\n  const collectorVisitor = new DslMethodsCollectorVisitor();\n  function collectMethods(rule) {\n    collectorVisitor.reset();\n    rule.accept(collectorVisitor);\n    const dslMethods = collectorVisitor.dslMethods;\n    collectorVisitor.reset();\n    return dslMethods;\n  }\n  function setNodeLocationOnlyOffset(currNodeLocation, newLocationInfo) {\n    if (isNaN(currNodeLocation.startOffset) === true) {\n      currNodeLocation.startOffset = newLocationInfo.startOffset;\n      currNodeLocation.endOffset = newLocationInfo.endOffset;\n    } else if (currNodeLocation.endOffset < newLocationInfo.endOffset === true) {\n      currNodeLocation.endOffset = newLocationInfo.endOffset;\n    }\n  }\n  function setNodeLocationFull(currNodeLocation, newLocationInfo) {\n    if (isNaN(currNodeLocation.startOffset) === true) {\n      currNodeLocation.startOffset = newLocationInfo.startOffset;\n      currNodeLocation.startColumn = newLocationInfo.startColumn;\n      currNodeLocation.startLine = newLocationInfo.startLine;\n      currNodeLocation.endOffset = newLocationInfo.endOffset;\n      currNodeLocation.endColumn = newLocationInfo.endColumn;\n      currNodeLocation.endLine = newLocationInfo.endLine;\n    } else if (currNodeLocation.endOffset < newLocationInfo.endOffset === true) {\n      currNodeLocation.endOffset = newLocationInfo.endOffset;\n      currNodeLocation.endColumn = newLocationInfo.endColumn;\n      currNodeLocation.endLine = newLocationInfo.endLine;\n    }\n  }\n  function addTerminalToCst(node, token, tokenTypeName) {\n    if (node.children[tokenTypeName] === void 0) {\n      node.children[tokenTypeName] = [token];\n    } else {\n      node.children[tokenTypeName].push(token);\n    }\n  }\n  function addNoneTerminalToCst(node, ruleName, ruleResult) {\n    if (node.children[ruleName] === void 0) {\n      node.children[ruleName] = [ruleResult];\n    } else {\n      node.children[ruleName].push(ruleResult);\n    }\n  }\n  const NAME = \"name\";\n  function defineNameProp(obj, nameValue) {\n    Object.defineProperty(obj, NAME, {\n      enumerable: false,\n      configurable: true,\n      writable: false,\n      value: nameValue\n    });\n  }\n  function defaultVisit(ctx, param) {\n    const childrenNames = keys(ctx);\n    const childrenNamesLength = childrenNames.length;\n    for (let i = 0; i < childrenNamesLength; i++) {\n      const currChildName = childrenNames[i];\n      const currChildArray = ctx[currChildName];\n      const currChildArrayLength = currChildArray.length;\n      for (let j = 0; j < currChildArrayLength; j++) {\n        const currChild = currChildArray[j];\n        if (currChild.tokenTypeIdx === void 0) {\n          this[currChild.name](currChild.children, param);\n        }\n      }\n    }\n  }\n  function createBaseSemanticVisitorConstructor(grammarName, ruleNames) {\n    const derivedConstructor = function () {};\n    defineNameProp(derivedConstructor, grammarName + \"BaseSemantics\");\n    const semanticProto = {\n      visit: function (cstNode, param) {\n        if (isArray$1(cstNode)) {\n          cstNode = cstNode[0];\n        }\n        if (isUndefined(cstNode)) {\n          return void 0;\n        }\n        return this[cstNode.name](cstNode.children, param);\n      },\n      validateVisitor: function () {\n        const semanticDefinitionErrors = validateVisitor(this, ruleNames);\n        if (!isEmpty(semanticDefinitionErrors)) {\n          const errorMessages = map(semanticDefinitionErrors, currDefError => currDefError.msg);\n          throw Error(`Errors Detected in CST Visitor <${this.constructor.name}>:\n\t${errorMessages.join(\"\\n\\n\").replace(/\\n/g, \"\\n\t\")}`);\n        }\n      }\n    };\n    derivedConstructor.prototype = semanticProto;\n    derivedConstructor.prototype.constructor = derivedConstructor;\n    derivedConstructor._RULE_NAMES = ruleNames;\n    return derivedConstructor;\n  }\n  function createBaseVisitorConstructorWithDefaults(grammarName, ruleNames, baseConstructor) {\n    const derivedConstructor = function () {};\n    defineNameProp(derivedConstructor, grammarName + \"BaseSemanticsWithDefaults\");\n    const withDefaultsProto = Object.create(baseConstructor.prototype);\n    forEach(ruleNames, ruleName => {\n      withDefaultsProto[ruleName] = defaultVisit;\n    });\n    derivedConstructor.prototype = withDefaultsProto;\n    derivedConstructor.prototype.constructor = derivedConstructor;\n    return derivedConstructor;\n  }\n  var CstVisitorDefinitionError;\n  (function (CstVisitorDefinitionError2) {\n    CstVisitorDefinitionError2[CstVisitorDefinitionError2[\"REDUNDANT_METHOD\"] = 0] = \"REDUNDANT_METHOD\";\n    CstVisitorDefinitionError2[CstVisitorDefinitionError2[\"MISSING_METHOD\"] = 1] = \"MISSING_METHOD\";\n  })(CstVisitorDefinitionError || (CstVisitorDefinitionError = {}));\n  function validateVisitor(visitorInstance, ruleNames) {\n    const missingErrors = validateMissingCstMethods(visitorInstance, ruleNames);\n    return missingErrors;\n  }\n  function validateMissingCstMethods(visitorInstance, ruleNames) {\n    const missingRuleNames = filter(ruleNames, currRuleName => {\n      return isFunction(visitorInstance[currRuleName]) === false;\n    });\n    const errors = map(missingRuleNames, currRuleName => {\n      return {\n        msg: `Missing visitor method: <${currRuleName}> on ${visitorInstance.constructor.name} CST Visitor.`,\n        type: CstVisitorDefinitionError.MISSING_METHOD,\n        methodName: currRuleName\n      };\n    });\n    return compact(errors);\n  }\n  class TreeBuilder {\n    initTreeBuilder(config) {\n      this.CST_STACK = [];\n      this.outputCst = config.outputCst;\n      this.nodeLocationTracking = has(config, \"nodeLocationTracking\") ? config.nodeLocationTracking : DEFAULT_PARSER_CONFIG.nodeLocationTracking;\n      if (!this.outputCst) {\n        this.cstInvocationStateUpdate = noop;\n        this.cstFinallyStateUpdate = noop;\n        this.cstPostTerminal = noop;\n        this.cstPostNonTerminal = noop;\n        this.cstPostRule = noop;\n      } else {\n        if (/full/i.test(this.nodeLocationTracking)) {\n          if (this.recoveryEnabled) {\n            this.setNodeLocationFromToken = setNodeLocationFull;\n            this.setNodeLocationFromNode = setNodeLocationFull;\n            this.cstPostRule = noop;\n            this.setInitialNodeLocation = this.setInitialNodeLocationFullRecovery;\n          } else {\n            this.setNodeLocationFromToken = noop;\n            this.setNodeLocationFromNode = noop;\n            this.cstPostRule = this.cstPostRuleFull;\n            this.setInitialNodeLocation = this.setInitialNodeLocationFullRegular;\n          }\n        } else if (/onlyOffset/i.test(this.nodeLocationTracking)) {\n          if (this.recoveryEnabled) {\n            this.setNodeLocationFromToken = setNodeLocationOnlyOffset;\n            this.setNodeLocationFromNode = setNodeLocationOnlyOffset;\n            this.cstPostRule = noop;\n            this.setInitialNodeLocation = this.setInitialNodeLocationOnlyOffsetRecovery;\n          } else {\n            this.setNodeLocationFromToken = noop;\n            this.setNodeLocationFromNode = noop;\n            this.cstPostRule = this.cstPostRuleOnlyOffset;\n            this.setInitialNodeLocation = this.setInitialNodeLocationOnlyOffsetRegular;\n          }\n        } else if (/none/i.test(this.nodeLocationTracking)) {\n          this.setNodeLocationFromToken = noop;\n          this.setNodeLocationFromNode = noop;\n          this.cstPostRule = noop;\n          this.setInitialNodeLocation = noop;\n        } else {\n          throw Error(`Invalid <nodeLocationTracking> config option: \"${config.nodeLocationTracking}\"`);\n        }\n      }\n    }\n    setInitialNodeLocationOnlyOffsetRecovery(cstNode) {\n      cstNode.location = {\n        startOffset: NaN,\n        endOffset: NaN\n      };\n    }\n    setInitialNodeLocationOnlyOffsetRegular(cstNode) {\n      cstNode.location = {\n        // without error recovery the starting Location of a new CstNode is guaranteed\n        // To be the next Token's startOffset (for valid inputs).\n        // For invalid inputs there won't be any CSTOutput so this potential\n        // inaccuracy does not matter\n        startOffset: this.LA(1).startOffset,\n        endOffset: NaN\n      };\n    }\n    setInitialNodeLocationFullRecovery(cstNode) {\n      cstNode.location = {\n        startOffset: NaN,\n        startLine: NaN,\n        startColumn: NaN,\n        endOffset: NaN,\n        endLine: NaN,\n        endColumn: NaN\n      };\n    }\n    /**\n         *  @see setInitialNodeLocationOnlyOffsetRegular for explanation why this work\n    \n         * @param cstNode\n         */\n    setInitialNodeLocationFullRegular(cstNode) {\n      const nextToken = this.LA(1);\n      cstNode.location = {\n        startOffset: nextToken.startOffset,\n        startLine: nextToken.startLine,\n        startColumn: nextToken.startColumn,\n        endOffset: NaN,\n        endLine: NaN,\n        endColumn: NaN\n      };\n    }\n    cstInvocationStateUpdate(fullRuleName) {\n      const cstNode = {\n        name: fullRuleName,\n        children: /* @__PURE__ */Object.create(null)\n      };\n      this.setInitialNodeLocation(cstNode);\n      this.CST_STACK.push(cstNode);\n    }\n    cstFinallyStateUpdate() {\n      this.CST_STACK.pop();\n    }\n    cstPostRuleFull(ruleCstNode) {\n      const prevToken = this.LA(0);\n      const loc = ruleCstNode.location;\n      if (loc.startOffset <= prevToken.startOffset === true) {\n        loc.endOffset = prevToken.endOffset;\n        loc.endLine = prevToken.endLine;\n        loc.endColumn = prevToken.endColumn;\n      } else {\n        loc.startOffset = NaN;\n        loc.startLine = NaN;\n        loc.startColumn = NaN;\n      }\n    }\n    cstPostRuleOnlyOffset(ruleCstNode) {\n      const prevToken = this.LA(0);\n      const loc = ruleCstNode.location;\n      if (loc.startOffset <= prevToken.startOffset === true) {\n        loc.endOffset = prevToken.endOffset;\n      } else {\n        loc.startOffset = NaN;\n      }\n    }\n    cstPostTerminal(key, consumedToken) {\n      const rootCst = this.CST_STACK[this.CST_STACK.length - 1];\n      addTerminalToCst(rootCst, consumedToken, key);\n      this.setNodeLocationFromToken(rootCst.location, consumedToken);\n    }\n    cstPostNonTerminal(ruleCstResult, ruleName) {\n      const preCstNode = this.CST_STACK[this.CST_STACK.length - 1];\n      addNoneTerminalToCst(preCstNode, ruleName, ruleCstResult);\n      this.setNodeLocationFromNode(preCstNode.location, ruleCstResult.location);\n    }\n    getBaseCstVisitorConstructor() {\n      if (isUndefined(this.baseCstVisitorConstructor)) {\n        const newBaseCstVisitorConstructor = createBaseSemanticVisitorConstructor(this.className, keys(this.gastProductionsCache));\n        this.baseCstVisitorConstructor = newBaseCstVisitorConstructor;\n        return newBaseCstVisitorConstructor;\n      }\n      return this.baseCstVisitorConstructor;\n    }\n    getBaseCstVisitorConstructorWithDefaults() {\n      if (isUndefined(this.baseCstVisitorWithDefaultsConstructor)) {\n        const newConstructor = createBaseVisitorConstructorWithDefaults(this.className, keys(this.gastProductionsCache), this.getBaseCstVisitorConstructor());\n        this.baseCstVisitorWithDefaultsConstructor = newConstructor;\n        return newConstructor;\n      }\n      return this.baseCstVisitorWithDefaultsConstructor;\n    }\n    getLastExplicitRuleShortName() {\n      const ruleStack = this.RULE_STACK;\n      return ruleStack[ruleStack.length - 1];\n    }\n    getPreviousExplicitRuleShortName() {\n      const ruleStack = this.RULE_STACK;\n      return ruleStack[ruleStack.length - 2];\n    }\n    getLastExplicitRuleOccurrenceIndex() {\n      const occurrenceStack = this.RULE_OCCURRENCE_STACK;\n      return occurrenceStack[occurrenceStack.length - 1];\n    }\n  }\n  class LexerAdapter {\n    initLexerAdapter() {\n      this.tokVector = [];\n      this.tokVectorLength = 0;\n      this.currIdx = -1;\n    }\n    set input(newInput) {\n      if (this.selfAnalysisDone !== true) {\n        throw Error(`Missing <performSelfAnalysis> invocation at the end of the Parser's constructor.`);\n      }\n      this.reset();\n      this.tokVector = newInput;\n      this.tokVectorLength = newInput.length;\n    }\n    get input() {\n      return this.tokVector;\n    }\n    // skips a token and returns the next token\n    SKIP_TOKEN() {\n      if (this.currIdx <= this.tokVector.length - 2) {\n        this.consumeToken();\n        return this.LA(1);\n      } else {\n        return END_OF_FILE;\n      }\n    }\n    // Lexer (accessing Token vector) related methods which can be overridden to implement lazy lexers\n    // or lexers dependent on parser context.\n    LA(howMuch) {\n      const soughtIdx = this.currIdx + howMuch;\n      if (soughtIdx < 0 || this.tokVectorLength <= soughtIdx) {\n        return END_OF_FILE;\n      } else {\n        return this.tokVector[soughtIdx];\n      }\n    }\n    consumeToken() {\n      this.currIdx++;\n    }\n    exportLexerState() {\n      return this.currIdx;\n    }\n    importLexerState(newState) {\n      this.currIdx = newState;\n    }\n    resetLexerState() {\n      this.currIdx = -1;\n    }\n    moveToTerminatedState() {\n      this.currIdx = this.tokVector.length - 1;\n    }\n    getLexerPosition() {\n      return this.exportLexerState();\n    }\n  }\n  class RecognizerApi {\n    ACTION(impl) {\n      return impl.call(this);\n    }\n    consume(idx, tokType, options) {\n      return this.consumeInternal(tokType, idx, options);\n    }\n    subrule(idx, ruleToCall, options) {\n      return this.subruleInternal(ruleToCall, idx, options);\n    }\n    option(idx, actionORMethodDef) {\n      return this.optionInternal(actionORMethodDef, idx);\n    }\n    or(idx, altsOrOpts) {\n      return this.orInternal(altsOrOpts, idx);\n    }\n    many(idx, actionORMethodDef) {\n      return this.manyInternal(idx, actionORMethodDef);\n    }\n    atLeastOne(idx, actionORMethodDef) {\n      return this.atLeastOneInternal(idx, actionORMethodDef);\n    }\n    CONSUME(tokType, options) {\n      return this.consumeInternal(tokType, 0, options);\n    }\n    CONSUME1(tokType, options) {\n      return this.consumeInternal(tokType, 1, options);\n    }\n    CONSUME2(tokType, options) {\n      return this.consumeInternal(tokType, 2, options);\n    }\n    CONSUME3(tokType, options) {\n      return this.consumeInternal(tokType, 3, options);\n    }\n    CONSUME4(tokType, options) {\n      return this.consumeInternal(tokType, 4, options);\n    }\n    CONSUME5(tokType, options) {\n      return this.consumeInternal(tokType, 5, options);\n    }\n    CONSUME6(tokType, options) {\n      return this.consumeInternal(tokType, 6, options);\n    }\n    CONSUME7(tokType, options) {\n      return this.consumeInternal(tokType, 7, options);\n    }\n    CONSUME8(tokType, options) {\n      return this.consumeInternal(tokType, 8, options);\n    }\n    CONSUME9(tokType, options) {\n      return this.consumeInternal(tokType, 9, options);\n    }\n    SUBRULE(ruleToCall, options) {\n      return this.subruleInternal(ruleToCall, 0, options);\n    }\n    SUBRULE1(ruleToCall, options) {\n      return this.subruleInternal(ruleToCall, 1, options);\n    }\n    SUBRULE2(ruleToCall, options) {\n      return this.subruleInternal(ruleToCall, 2, options);\n    }\n    SUBRULE3(ruleToCall, options) {\n      return this.subruleInternal(ruleToCall, 3, options);\n    }\n    SUBRULE4(ruleToCall, options) {\n      return this.subruleInternal(ruleToCall, 4, options);\n    }\n    SUBRULE5(ruleToCall, options) {\n      return this.subruleInternal(ruleToCall, 5, options);\n    }\n    SUBRULE6(ruleToCall, options) {\n      return this.subruleInternal(ruleToCall, 6, options);\n    }\n    SUBRULE7(ruleToCall, options) {\n      return this.subruleInternal(ruleToCall, 7, options);\n    }\n    SUBRULE8(ruleToCall, options) {\n      return this.subruleInternal(ruleToCall, 8, options);\n    }\n    SUBRULE9(ruleToCall, options) {\n      return this.subruleInternal(ruleToCall, 9, options);\n    }\n    OPTION(actionORMethodDef) {\n      return this.optionInternal(actionORMethodDef, 0);\n    }\n    OPTION1(actionORMethodDef) {\n      return this.optionInternal(actionORMethodDef, 1);\n    }\n    OPTION2(actionORMethodDef) {\n      return this.optionInternal(actionORMethodDef, 2);\n    }\n    OPTION3(actionORMethodDef) {\n      return this.optionInternal(actionORMethodDef, 3);\n    }\n    OPTION4(actionORMethodDef) {\n      return this.optionInternal(actionORMethodDef, 4);\n    }\n    OPTION5(actionORMethodDef) {\n      return this.optionInternal(actionORMethodDef, 5);\n    }\n    OPTION6(actionORMethodDef) {\n      return this.optionInternal(actionORMethodDef, 6);\n    }\n    OPTION7(actionORMethodDef) {\n      return this.optionInternal(actionORMethodDef, 7);\n    }\n    OPTION8(actionORMethodDef) {\n      return this.optionInternal(actionORMethodDef, 8);\n    }\n    OPTION9(actionORMethodDef) {\n      return this.optionInternal(actionORMethodDef, 9);\n    }\n    OR(altsOrOpts) {\n      return this.orInternal(altsOrOpts, 0);\n    }\n    OR1(altsOrOpts) {\n      return this.orInternal(altsOrOpts, 1);\n    }\n    OR2(altsOrOpts) {\n      return this.orInternal(altsOrOpts, 2);\n    }\n    OR3(altsOrOpts) {\n      return this.orInternal(altsOrOpts, 3);\n    }\n    OR4(altsOrOpts) {\n      return this.orInternal(altsOrOpts, 4);\n    }\n    OR5(altsOrOpts) {\n      return this.orInternal(altsOrOpts, 5);\n    }\n    OR6(altsOrOpts) {\n      return this.orInternal(altsOrOpts, 6);\n    }\n    OR7(altsOrOpts) {\n      return this.orInternal(altsOrOpts, 7);\n    }\n    OR8(altsOrOpts) {\n      return this.orInternal(altsOrOpts, 8);\n    }\n    OR9(altsOrOpts) {\n      return this.orInternal(altsOrOpts, 9);\n    }\n    MANY(actionORMethodDef) {\n      this.manyInternal(0, actionORMethodDef);\n    }\n    MANY1(actionORMethodDef) {\n      this.manyInternal(1, actionORMethodDef);\n    }\n    MANY2(actionORMethodDef) {\n      this.manyInternal(2, actionORMethodDef);\n    }\n    MANY3(actionORMethodDef) {\n      this.manyInternal(3, actionORMethodDef);\n    }\n    MANY4(actionORMethodDef) {\n      this.manyInternal(4, actionORMethodDef);\n    }\n    MANY5(actionORMethodDef) {\n      this.manyInternal(5, actionORMethodDef);\n    }\n    MANY6(actionORMethodDef) {\n      this.manyInternal(6, actionORMethodDef);\n    }\n    MANY7(actionORMethodDef) {\n      this.manyInternal(7, actionORMethodDef);\n    }\n    MANY8(actionORMethodDef) {\n      this.manyInternal(8, actionORMethodDef);\n    }\n    MANY9(actionORMethodDef) {\n      this.manyInternal(9, actionORMethodDef);\n    }\n    MANY_SEP(options) {\n      this.manySepFirstInternal(0, options);\n    }\n    MANY_SEP1(options) {\n      this.manySepFirstInternal(1, options);\n    }\n    MANY_SEP2(options) {\n      this.manySepFirstInternal(2, options);\n    }\n    MANY_SEP3(options) {\n      this.manySepFirstInternal(3, options);\n    }\n    MANY_SEP4(options) {\n      this.manySepFirstInternal(4, options);\n    }\n    MANY_SEP5(options) {\n      this.manySepFirstInternal(5, options);\n    }\n    MANY_SEP6(options) {\n      this.manySepFirstInternal(6, options);\n    }\n    MANY_SEP7(options) {\n      this.manySepFirstInternal(7, options);\n    }\n    MANY_SEP8(options) {\n      this.manySepFirstInternal(8, options);\n    }\n    MANY_SEP9(options) {\n      this.manySepFirstInternal(9, options);\n    }\n    AT_LEAST_ONE(actionORMethodDef) {\n      this.atLeastOneInternal(0, actionORMethodDef);\n    }\n    AT_LEAST_ONE1(actionORMethodDef) {\n      return this.atLeastOneInternal(1, actionORMethodDef);\n    }\n    AT_LEAST_ONE2(actionORMethodDef) {\n      this.atLeastOneInternal(2, actionORMethodDef);\n    }\n    AT_LEAST_ONE3(actionORMethodDef) {\n      this.atLeastOneInternal(3, actionORMethodDef);\n    }\n    AT_LEAST_ONE4(actionORMethodDef) {\n      this.atLeastOneInternal(4, actionORMethodDef);\n    }\n    AT_LEAST_ONE5(actionORMethodDef) {\n      this.atLeastOneInternal(5, actionORMethodDef);\n    }\n    AT_LEAST_ONE6(actionORMethodDef) {\n      this.atLeastOneInternal(6, actionORMethodDef);\n    }\n    AT_LEAST_ONE7(actionORMethodDef) {\n      this.atLeastOneInternal(7, actionORMethodDef);\n    }\n    AT_LEAST_ONE8(actionORMethodDef) {\n      this.atLeastOneInternal(8, actionORMethodDef);\n    }\n    AT_LEAST_ONE9(actionORMethodDef) {\n      this.atLeastOneInternal(9, actionORMethodDef);\n    }\n    AT_LEAST_ONE_SEP(options) {\n      this.atLeastOneSepFirstInternal(0, options);\n    }\n    AT_LEAST_ONE_SEP1(options) {\n      this.atLeastOneSepFirstInternal(1, options);\n    }\n    AT_LEAST_ONE_SEP2(options) {\n      this.atLeastOneSepFirstInternal(2, options);\n    }\n    AT_LEAST_ONE_SEP3(options) {\n      this.atLeastOneSepFirstInternal(3, options);\n    }\n    AT_LEAST_ONE_SEP4(options) {\n      this.atLeastOneSepFirstInternal(4, options);\n    }\n    AT_LEAST_ONE_SEP5(options) {\n      this.atLeastOneSepFirstInternal(5, options);\n    }\n    AT_LEAST_ONE_SEP6(options) {\n      this.atLeastOneSepFirstInternal(6, options);\n    }\n    AT_LEAST_ONE_SEP7(options) {\n      this.atLeastOneSepFirstInternal(7, options);\n    }\n    AT_LEAST_ONE_SEP8(options) {\n      this.atLeastOneSepFirstInternal(8, options);\n    }\n    AT_LEAST_ONE_SEP9(options) {\n      this.atLeastOneSepFirstInternal(9, options);\n    }\n    RULE(name, implementation, config = DEFAULT_RULE_CONFIG) {\n      if (includes(this.definedRulesNames, name)) {\n        const errMsg = defaultGrammarValidatorErrorProvider.buildDuplicateRuleNameError({\n          topLevelRule: name,\n          grammarName: this.className\n        });\n        const error = {\n          message: errMsg,\n          type: ParserDefinitionErrorType.DUPLICATE_RULE_NAME,\n          ruleName: name\n        };\n        this.definitionErrors.push(error);\n      }\n      this.definedRulesNames.push(name);\n      const ruleImplementation = this.defineRule(name, implementation, config);\n      this[name] = ruleImplementation;\n      return ruleImplementation;\n    }\n    OVERRIDE_RULE(name, impl, config = DEFAULT_RULE_CONFIG) {\n      const ruleErrors = validateRuleIsOverridden(name, this.definedRulesNames, this.className);\n      this.definitionErrors = this.definitionErrors.concat(ruleErrors);\n      const ruleImplementation = this.defineRule(name, impl, config);\n      this[name] = ruleImplementation;\n      return ruleImplementation;\n    }\n    BACKTRACK(grammarRule, args) {\n      return function () {\n        this.isBackTrackingStack.push(1);\n        const orgState = this.saveRecogState();\n        try {\n          grammarRule.apply(this, args);\n          return true;\n        } catch (e) {\n          if (isRecognitionException(e)) {\n            return false;\n          } else {\n            throw e;\n          }\n        } finally {\n          this.reloadRecogState(orgState);\n          this.isBackTrackingStack.pop();\n        }\n      };\n    }\n    // GAST export APIs\n    getGAstProductions() {\n      return this.gastProductionsCache;\n    }\n    getSerializedGastProductions() {\n      return serializeGrammar(values(this.gastProductionsCache));\n    }\n  }\n  class RecognizerEngine {\n    initRecognizerEngine(tokenVocabulary, config) {\n      this.className = this.constructor.name;\n      this.shortRuleNameToFull = {};\n      this.fullRuleNameToShort = {};\n      this.ruleShortNameIdx = 256;\n      this.tokenMatcher = tokenStructuredMatcherNoCategories;\n      this.subruleIdx = 0;\n      this.definedRulesNames = [];\n      this.tokensMap = {};\n      this.isBackTrackingStack = [];\n      this.RULE_STACK = [];\n      this.RULE_OCCURRENCE_STACK = [];\n      this.gastProductionsCache = {};\n      if (has(config, \"serializedGrammar\")) {\n        throw Error(\"The Parser's configuration can no longer contain a <serializedGrammar> property.\\n\tSee: https://chevrotain.io/docs/changes/BREAKING_CHANGES.html#_6-0-0\\n\tFor Further details.\");\n      }\n      if (isArray$1(tokenVocabulary)) {\n        if (isEmpty(tokenVocabulary)) {\n          throw Error(\"A Token Vocabulary cannot be empty.\\n\tNote that the first argument for the parser constructor\\n\tis no longer a Token vector (since v4.0).\");\n        }\n        if (typeof tokenVocabulary[0].startOffset === \"number\") {\n          throw Error(\"The Parser constructor no longer accepts a token vector as the first argument.\\n\tSee: https://chevrotain.io/docs/changes/BREAKING_CHANGES.html#_4-0-0\\n\tFor Further details.\");\n        }\n      }\n      if (isArray$1(tokenVocabulary)) {\n        this.tokensMap = reduce(tokenVocabulary, (acc, tokType) => {\n          acc[tokType.name] = tokType;\n          return acc;\n        }, {});\n      } else if (has(tokenVocabulary, \"modes\") && every(flatten(values(tokenVocabulary.modes)), isTokenType)) {\n        const allTokenTypes2 = flatten(values(tokenVocabulary.modes));\n        const uniqueTokens = uniq(allTokenTypes2);\n        this.tokensMap = reduce(uniqueTokens, (acc, tokType) => {\n          acc[tokType.name] = tokType;\n          return acc;\n        }, {});\n      } else if (isObject(tokenVocabulary)) {\n        this.tokensMap = clone(tokenVocabulary);\n      } else {\n        throw new Error(\"<tokensDictionary> argument must be An Array of Token constructors, A dictionary of Token constructors or an IMultiModeLexerDefinition\");\n      }\n      this.tokensMap[\"EOF\"] = EOF;\n      const allTokenTypes = has(tokenVocabulary, \"modes\") ? flatten(values(tokenVocabulary.modes)) : values(tokenVocabulary);\n      const noTokenCategoriesUsed = every(allTokenTypes, tokenConstructor => isEmpty(tokenConstructor.categoryMatches));\n      this.tokenMatcher = noTokenCategoriesUsed ? tokenStructuredMatcherNoCategories : tokenStructuredMatcher;\n      augmentTokenTypes(values(this.tokensMap));\n    }\n    defineRule(ruleName, impl, config) {\n      if (this.selfAnalysisDone) {\n        throw Error(`Grammar rule <${ruleName}> may not be defined after the 'performSelfAnalysis' method has been called'\nMake sure that all grammar rule definitions are done before 'performSelfAnalysis' is called.`);\n      }\n      const resyncEnabled = has(config, \"resyncEnabled\") ? config.resyncEnabled : DEFAULT_RULE_CONFIG.resyncEnabled;\n      const recoveryValueFunc = has(config, \"recoveryValueFunc\") ? config.recoveryValueFunc : DEFAULT_RULE_CONFIG.recoveryValueFunc;\n      const shortName = this.ruleShortNameIdx << BITS_FOR_METHOD_TYPE + BITS_FOR_OCCURRENCE_IDX;\n      this.ruleShortNameIdx++;\n      this.shortRuleNameToFull[shortName] = ruleName;\n      this.fullRuleNameToShort[ruleName] = shortName;\n      let invokeRuleWithTry;\n      if (this.outputCst === true) {\n        invokeRuleWithTry = function invokeRuleWithTry2(...args) {\n          try {\n            this.ruleInvocationStateUpdate(shortName, ruleName, this.subruleIdx);\n            impl.apply(this, args);\n            const cst = this.CST_STACK[this.CST_STACK.length - 1];\n            this.cstPostRule(cst);\n            return cst;\n          } catch (e) {\n            return this.invokeRuleCatch(e, resyncEnabled, recoveryValueFunc);\n          } finally {\n            this.ruleFinallyStateUpdate();\n          }\n        };\n      } else {\n        invokeRuleWithTry = function invokeRuleWithTryCst(...args) {\n          try {\n            this.ruleInvocationStateUpdate(shortName, ruleName, this.subruleIdx);\n            return impl.apply(this, args);\n          } catch (e) {\n            return this.invokeRuleCatch(e, resyncEnabled, recoveryValueFunc);\n          } finally {\n            this.ruleFinallyStateUpdate();\n          }\n        };\n      }\n      const wrappedGrammarRule = Object.assign(invokeRuleWithTry, {\n        ruleName,\n        originalGrammarAction: impl\n      });\n      return wrappedGrammarRule;\n    }\n    invokeRuleCatch(e, resyncEnabledConfig, recoveryValueFunc) {\n      const isFirstInvokedRule = this.RULE_STACK.length === 1;\n      const reSyncEnabled = resyncEnabledConfig && !this.isBackTracking() && this.recoveryEnabled;\n      if (isRecognitionException(e)) {\n        const recogError = e;\n        if (reSyncEnabled) {\n          const reSyncTokType = this.findReSyncTokenType();\n          if (this.isInCurrentRuleReSyncSet(reSyncTokType)) {\n            recogError.resyncedTokens = this.reSyncTo(reSyncTokType);\n            if (this.outputCst) {\n              const partialCstResult = this.CST_STACK[this.CST_STACK.length - 1];\n              partialCstResult.recoveredNode = true;\n              return partialCstResult;\n            } else {\n              return recoveryValueFunc(e);\n            }\n          } else {\n            if (this.outputCst) {\n              const partialCstResult = this.CST_STACK[this.CST_STACK.length - 1];\n              partialCstResult.recoveredNode = true;\n              recogError.partialCstResult = partialCstResult;\n            }\n            throw recogError;\n          }\n        } else if (isFirstInvokedRule) {\n          this.moveToTerminatedState();\n          return recoveryValueFunc(e);\n        } else {\n          throw recogError;\n        }\n      } else {\n        throw e;\n      }\n    }\n    // Implementation of parsing DSL\n    optionInternal(actionORMethodDef, occurrence) {\n      const key = this.getKeyForAutomaticLookahead(OPTION_IDX, occurrence);\n      return this.optionInternalLogic(actionORMethodDef, occurrence, key);\n    }\n    optionInternalLogic(actionORMethodDef, occurrence, key) {\n      let lookAheadFunc = this.getLaFuncFromCache(key);\n      let action;\n      if (typeof actionORMethodDef !== \"function\") {\n        action = actionORMethodDef.DEF;\n        const predicate = actionORMethodDef.GATE;\n        if (predicate !== void 0) {\n          const orgLookaheadFunction = lookAheadFunc;\n          lookAheadFunc = () => {\n            return predicate.call(this) && orgLookaheadFunction.call(this);\n          };\n        }\n      } else {\n        action = actionORMethodDef;\n      }\n      if (lookAheadFunc.call(this) === true) {\n        return action.call(this);\n      }\n      return void 0;\n    }\n    atLeastOneInternal(prodOccurrence, actionORMethodDef) {\n      const laKey = this.getKeyForAutomaticLookahead(AT_LEAST_ONE_IDX, prodOccurrence);\n      return this.atLeastOneInternalLogic(prodOccurrence, actionORMethodDef, laKey);\n    }\n    atLeastOneInternalLogic(prodOccurrence, actionORMethodDef, key) {\n      let lookAheadFunc = this.getLaFuncFromCache(key);\n      let action;\n      if (typeof actionORMethodDef !== \"function\") {\n        action = actionORMethodDef.DEF;\n        const predicate = actionORMethodDef.GATE;\n        if (predicate !== void 0) {\n          const orgLookaheadFunction = lookAheadFunc;\n          lookAheadFunc = () => {\n            return predicate.call(this) && orgLookaheadFunction.call(this);\n          };\n        }\n      } else {\n        action = actionORMethodDef;\n      }\n      if (lookAheadFunc.call(this) === true) {\n        let notStuck = this.doSingleRepetition(action);\n        while (lookAheadFunc.call(this) === true && notStuck === true) {\n          notStuck = this.doSingleRepetition(action);\n        }\n      } else {\n        throw this.raiseEarlyExitException(prodOccurrence, PROD_TYPE.REPETITION_MANDATORY, actionORMethodDef.ERR_MSG);\n      }\n      this.attemptInRepetitionRecovery(this.atLeastOneInternal, [prodOccurrence, actionORMethodDef], lookAheadFunc, AT_LEAST_ONE_IDX, prodOccurrence, NextTerminalAfterAtLeastOneWalker);\n    }\n    atLeastOneSepFirstInternal(prodOccurrence, options) {\n      const laKey = this.getKeyForAutomaticLookahead(AT_LEAST_ONE_SEP_IDX, prodOccurrence);\n      this.atLeastOneSepFirstInternalLogic(prodOccurrence, options, laKey);\n    }\n    atLeastOneSepFirstInternalLogic(prodOccurrence, options, key) {\n      const action = options.DEF;\n      const separator = options.SEP;\n      const firstIterationLookaheadFunc = this.getLaFuncFromCache(key);\n      if (firstIterationLookaheadFunc.call(this) === true) {\n        action.call(this);\n        const separatorLookAheadFunc = () => {\n          return this.tokenMatcher(this.LA(1), separator);\n        };\n        while (this.tokenMatcher(this.LA(1), separator) === true) {\n          this.CONSUME(separator);\n          action.call(this);\n        }\n        this.attemptInRepetitionRecovery(this.repetitionSepSecondInternal, [prodOccurrence, separator, separatorLookAheadFunc, action, NextTerminalAfterAtLeastOneSepWalker], separatorLookAheadFunc, AT_LEAST_ONE_SEP_IDX, prodOccurrence, NextTerminalAfterAtLeastOneSepWalker);\n      } else {\n        throw this.raiseEarlyExitException(prodOccurrence, PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR, options.ERR_MSG);\n      }\n    }\n    manyInternal(prodOccurrence, actionORMethodDef) {\n      const laKey = this.getKeyForAutomaticLookahead(MANY_IDX, prodOccurrence);\n      return this.manyInternalLogic(prodOccurrence, actionORMethodDef, laKey);\n    }\n    manyInternalLogic(prodOccurrence, actionORMethodDef, key) {\n      let lookaheadFunction = this.getLaFuncFromCache(key);\n      let action;\n      if (typeof actionORMethodDef !== \"function\") {\n        action = actionORMethodDef.DEF;\n        const predicate = actionORMethodDef.GATE;\n        if (predicate !== void 0) {\n          const orgLookaheadFunction = lookaheadFunction;\n          lookaheadFunction = () => {\n            return predicate.call(this) && orgLookaheadFunction.call(this);\n          };\n        }\n      } else {\n        action = actionORMethodDef;\n      }\n      let notStuck = true;\n      while (lookaheadFunction.call(this) === true && notStuck === true) {\n        notStuck = this.doSingleRepetition(action);\n      }\n      this.attemptInRepetitionRecovery(this.manyInternal, [prodOccurrence, actionORMethodDef], lookaheadFunction, MANY_IDX, prodOccurrence, NextTerminalAfterManyWalker,\n      // The notStuck parameter is only relevant when \"attemptInRepetitionRecovery\"\n      // is invoked from manyInternal, in the MANY_SEP case and AT_LEAST_ONE[_SEP]\n      // An infinite loop cannot occur as:\n      // - Either the lookahead is guaranteed to consume something (Single Token Separator)\n      // - AT_LEAST_ONE by definition is guaranteed to consume something (or error out).\n      notStuck);\n    }\n    manySepFirstInternal(prodOccurrence, options) {\n      const laKey = this.getKeyForAutomaticLookahead(MANY_SEP_IDX, prodOccurrence);\n      this.manySepFirstInternalLogic(prodOccurrence, options, laKey);\n    }\n    manySepFirstInternalLogic(prodOccurrence, options, key) {\n      const action = options.DEF;\n      const separator = options.SEP;\n      const firstIterationLaFunc = this.getLaFuncFromCache(key);\n      if (firstIterationLaFunc.call(this) === true) {\n        action.call(this);\n        const separatorLookAheadFunc = () => {\n          return this.tokenMatcher(this.LA(1), separator);\n        };\n        while (this.tokenMatcher(this.LA(1), separator) === true) {\n          this.CONSUME(separator);\n          action.call(this);\n        }\n        this.attemptInRepetitionRecovery(this.repetitionSepSecondInternal, [prodOccurrence, separator, separatorLookAheadFunc, action, NextTerminalAfterManySepWalker], separatorLookAheadFunc, MANY_SEP_IDX, prodOccurrence, NextTerminalAfterManySepWalker);\n      }\n    }\n    repetitionSepSecondInternal(prodOccurrence, separator, separatorLookAheadFunc, action, nextTerminalAfterWalker) {\n      while (separatorLookAheadFunc()) {\n        this.CONSUME(separator);\n        action.call(this);\n      }\n      this.attemptInRepetitionRecovery(this.repetitionSepSecondInternal, [prodOccurrence, separator, separatorLookAheadFunc, action, nextTerminalAfterWalker], separatorLookAheadFunc, AT_LEAST_ONE_SEP_IDX, prodOccurrence, nextTerminalAfterWalker);\n    }\n    doSingleRepetition(action) {\n      const beforeIteration = this.getLexerPosition();\n      action.call(this);\n      const afterIteration = this.getLexerPosition();\n      return afterIteration > beforeIteration;\n    }\n    orInternal(altsOrOpts, occurrence) {\n      const laKey = this.getKeyForAutomaticLookahead(OR_IDX, occurrence);\n      const alts = isArray$1(altsOrOpts) ? altsOrOpts : altsOrOpts.DEF;\n      const laFunc = this.getLaFuncFromCache(laKey);\n      const altIdxToTake = laFunc.call(this, alts);\n      if (altIdxToTake !== void 0) {\n        const chosenAlternative = alts[altIdxToTake];\n        return chosenAlternative.ALT.call(this);\n      }\n      this.raiseNoAltException(occurrence, altsOrOpts.ERR_MSG);\n    }\n    ruleFinallyStateUpdate() {\n      this.RULE_STACK.pop();\n      this.RULE_OCCURRENCE_STACK.pop();\n      this.cstFinallyStateUpdate();\n      if (this.RULE_STACK.length === 0 && this.isAtEndOfInput() === false) {\n        const firstRedundantTok = this.LA(1);\n        const errMsg = this.errorMessageProvider.buildNotAllInputParsedMessage({\n          firstRedundant: firstRedundantTok,\n          ruleName: this.getCurrRuleFullName()\n        });\n        this.SAVE_ERROR(new NotAllInputParsedException(errMsg, firstRedundantTok));\n      }\n    }\n    subruleInternal(ruleToCall, idx, options) {\n      let ruleResult;\n      try {\n        const args = options !== void 0 ? options.ARGS : void 0;\n        this.subruleIdx = idx;\n        ruleResult = ruleToCall.apply(this, args);\n        this.cstPostNonTerminal(ruleResult, options !== void 0 && options.LABEL !== void 0 ? options.LABEL : ruleToCall.ruleName);\n        return ruleResult;\n      } catch (e) {\n        throw this.subruleInternalError(e, options, ruleToCall.ruleName);\n      }\n    }\n    subruleInternalError(e, options, ruleName) {\n      if (isRecognitionException(e) && e.partialCstResult !== void 0) {\n        this.cstPostNonTerminal(e.partialCstResult, options !== void 0 && options.LABEL !== void 0 ? options.LABEL : ruleName);\n        delete e.partialCstResult;\n      }\n      throw e;\n    }\n    consumeInternal(tokType, idx, options) {\n      let consumedToken;\n      try {\n        const nextToken = this.LA(1);\n        if (this.tokenMatcher(nextToken, tokType) === true) {\n          this.consumeToken();\n          consumedToken = nextToken;\n        } else {\n          this.consumeInternalError(tokType, nextToken, options);\n        }\n      } catch (eFromConsumption) {\n        consumedToken = this.consumeInternalRecovery(tokType, idx, eFromConsumption);\n      }\n      this.cstPostTerminal(options !== void 0 && options.LABEL !== void 0 ? options.LABEL : tokType.name, consumedToken);\n      return consumedToken;\n    }\n    consumeInternalError(tokType, nextToken, options) {\n      let msg;\n      const previousToken = this.LA(0);\n      if (options !== void 0 && options.ERR_MSG) {\n        msg = options.ERR_MSG;\n      } else {\n        msg = this.errorMessageProvider.buildMismatchTokenMessage({\n          expected: tokType,\n          actual: nextToken,\n          previous: previousToken,\n          ruleName: this.getCurrRuleFullName()\n        });\n      }\n      throw this.SAVE_ERROR(new MismatchedTokenException(msg, nextToken, previousToken));\n    }\n    consumeInternalRecovery(tokType, idx, eFromConsumption) {\n      if (this.recoveryEnabled &&\n      // TODO: more robust checking of the exception type. Perhaps Typescript extending expressions?\n      eFromConsumption.name === \"MismatchedTokenException\" && !this.isBackTracking()) {\n        const follows = this.getFollowsForInRuleRecovery(tokType, idx);\n        try {\n          return this.tryInRuleRecovery(tokType, follows);\n        } catch (eFromInRuleRecovery) {\n          if (eFromInRuleRecovery.name === IN_RULE_RECOVERY_EXCEPTION) {\n            throw eFromConsumption;\n          } else {\n            throw eFromInRuleRecovery;\n          }\n        }\n      } else {\n        throw eFromConsumption;\n      }\n    }\n    saveRecogState() {\n      const savedErrors = this.errors;\n      const savedRuleStack = clone(this.RULE_STACK);\n      return {\n        errors: savedErrors,\n        lexerState: this.exportLexerState(),\n        RULE_STACK: savedRuleStack,\n        CST_STACK: this.CST_STACK\n      };\n    }\n    reloadRecogState(newState) {\n      this.errors = newState.errors;\n      this.importLexerState(newState.lexerState);\n      this.RULE_STACK = newState.RULE_STACK;\n    }\n    ruleInvocationStateUpdate(shortName, fullName, idxInCallingRule) {\n      this.RULE_OCCURRENCE_STACK.push(idxInCallingRule);\n      this.RULE_STACK.push(shortName);\n      this.cstInvocationStateUpdate(fullName);\n    }\n    isBackTracking() {\n      return this.isBackTrackingStack.length !== 0;\n    }\n    getCurrRuleFullName() {\n      const shortName = this.getLastExplicitRuleShortName();\n      return this.shortRuleNameToFull[shortName];\n    }\n    shortRuleNameToFullName(shortName) {\n      return this.shortRuleNameToFull[shortName];\n    }\n    isAtEndOfInput() {\n      return this.tokenMatcher(this.LA(1), EOF);\n    }\n    reset() {\n      this.resetLexerState();\n      this.subruleIdx = 0;\n      this.isBackTrackingStack = [];\n      this.errors = [];\n      this.RULE_STACK = [];\n      this.CST_STACK = [];\n      this.RULE_OCCURRENCE_STACK = [];\n    }\n  }\n  class ErrorHandler {\n    initErrorHandler(config) {\n      this._errors = [];\n      this.errorMessageProvider = has(config, \"errorMessageProvider\") ? config.errorMessageProvider : DEFAULT_PARSER_CONFIG.errorMessageProvider;\n    }\n    SAVE_ERROR(error) {\n      if (isRecognitionException(error)) {\n        error.context = {\n          ruleStack: this.getHumanReadableRuleStack(),\n          ruleOccurrenceStack: clone(this.RULE_OCCURRENCE_STACK)\n        };\n        this._errors.push(error);\n        return error;\n      } else {\n        throw Error(\"Trying to save an Error which is not a RecognitionException\");\n      }\n    }\n    get errors() {\n      return clone(this._errors);\n    }\n    set errors(newErrors) {\n      this._errors = newErrors;\n    }\n    // TODO: consider caching the error message computed information\n    raiseEarlyExitException(occurrence, prodType, userDefinedErrMsg) {\n      const ruleName = this.getCurrRuleFullName();\n      const ruleGrammar = this.getGAstProductions()[ruleName];\n      const lookAheadPathsPerAlternative = getLookaheadPathsForOptionalProd(occurrence, ruleGrammar, prodType, this.maxLookahead);\n      const insideProdPaths = lookAheadPathsPerAlternative[0];\n      const actualTokens = [];\n      for (let i = 1; i <= this.maxLookahead; i++) {\n        actualTokens.push(this.LA(i));\n      }\n      const msg = this.errorMessageProvider.buildEarlyExitMessage({\n        expectedIterationPaths: insideProdPaths,\n        actual: actualTokens,\n        previous: this.LA(0),\n        customUserDescription: userDefinedErrMsg,\n        ruleName\n      });\n      throw this.SAVE_ERROR(new EarlyExitException(msg, this.LA(1), this.LA(0)));\n    }\n    // TODO: consider caching the error message computed information\n    raiseNoAltException(occurrence, errMsgTypes) {\n      const ruleName = this.getCurrRuleFullName();\n      const ruleGrammar = this.getGAstProductions()[ruleName];\n      const lookAheadPathsPerAlternative = getLookaheadPathsForOr(occurrence, ruleGrammar, this.maxLookahead);\n      const actualTokens = [];\n      for (let i = 1; i <= this.maxLookahead; i++) {\n        actualTokens.push(this.LA(i));\n      }\n      const previousToken = this.LA(0);\n      const errMsg = this.errorMessageProvider.buildNoViableAltMessage({\n        expectedPathsPerAlt: lookAheadPathsPerAlternative,\n        actual: actualTokens,\n        previous: previousToken,\n        customUserDescription: errMsgTypes,\n        ruleName: this.getCurrRuleFullName()\n      });\n      throw this.SAVE_ERROR(new NoViableAltException(errMsg, this.LA(1), previousToken));\n    }\n  }\n  class ContentAssist {\n    initContentAssist() {}\n    computeContentAssist(startRuleName, precedingInput) {\n      const startRuleGast = this.gastProductionsCache[startRuleName];\n      if (isUndefined(startRuleGast)) {\n        throw Error(`Rule ->${startRuleName}<- does not exist in this grammar.`);\n      }\n      return nextPossibleTokensAfter([startRuleGast], precedingInput, this.tokenMatcher, this.maxLookahead);\n    }\n    // TODO: should this be a member method or a utility? it does not have any state or usage of 'this'...\n    // TODO: should this be more explicitly part of the public API?\n    getNextPossibleTokenTypes(grammarPath) {\n      const topRuleName = head(grammarPath.ruleStack);\n      const gastProductions = this.getGAstProductions();\n      const topProduction = gastProductions[topRuleName];\n      const nextPossibleTokenTypes = new NextAfterTokenWalker(topProduction, grammarPath).startWalking();\n      return nextPossibleTokenTypes;\n    }\n  }\n  const RECORDING_NULL_OBJECT = {\n    description: \"This Object indicates the Parser is during Recording Phase\"\n  };\n  Object.freeze(RECORDING_NULL_OBJECT);\n  const HANDLE_SEPARATOR = true;\n  const MAX_METHOD_IDX = Math.pow(2, BITS_FOR_OCCURRENCE_IDX) - 1;\n  const RFT = createToken2({\n    name: \"RECORDING_PHASE_TOKEN\",\n    pattern: Lexer2.NA\n  });\n  augmentTokenTypes([RFT]);\n  const RECORDING_PHASE_TOKEN = createTokenInstance(RFT, \"This IToken indicates the Parser is in Recording Phase\\n\tSee: https://chevrotain.io/docs/guide/internals.html#grammar-recording for details\",\n  // Using \"-1\" instead of NaN (as in EOF) because an actual number is less likely to\n  // cause errors if the output of LA or CONSUME would be (incorrectly) used during the recording phase.\n  -1, -1, -1, -1, -1, -1);\n  Object.freeze(RECORDING_PHASE_TOKEN);\n  const RECORDING_PHASE_CSTNODE = {\n    name: \"This CSTNode indicates the Parser is in Recording Phase\\n\tSee: https://chevrotain.io/docs/guide/internals.html#grammar-recording for details\",\n    children: {}\n  };\n  class GastRecorder {\n    initGastRecorder(config) {\n      this.recordingProdStack = [];\n      this.RECORDING_PHASE = false;\n    }\n    enableRecording() {\n      this.RECORDING_PHASE = true;\n      this.TRACE_INIT(\"Enable Recording\", () => {\n        for (let i = 0; i < 10; i++) {\n          const idx = i > 0 ? i : \"\";\n          this[`CONSUME${idx}`] = function (arg1, arg2) {\n            return this.consumeInternalRecord(arg1, i, arg2);\n          };\n          this[`SUBRULE${idx}`] = function (arg1, arg2) {\n            return this.subruleInternalRecord(arg1, i, arg2);\n          };\n          this[`OPTION${idx}`] = function (arg1) {\n            return this.optionInternalRecord(arg1, i);\n          };\n          this[`OR${idx}`] = function (arg1) {\n            return this.orInternalRecord(arg1, i);\n          };\n          this[`MANY${idx}`] = function (arg1) {\n            this.manyInternalRecord(i, arg1);\n          };\n          this[`MANY_SEP${idx}`] = function (arg1) {\n            this.manySepFirstInternalRecord(i, arg1);\n          };\n          this[`AT_LEAST_ONE${idx}`] = function (arg1) {\n            this.atLeastOneInternalRecord(i, arg1);\n          };\n          this[`AT_LEAST_ONE_SEP${idx}`] = function (arg1) {\n            this.atLeastOneSepFirstInternalRecord(i, arg1);\n          };\n        }\n        this[`consume`] = function (idx, arg1, arg2) {\n          return this.consumeInternalRecord(arg1, idx, arg2);\n        };\n        this[`subrule`] = function (idx, arg1, arg2) {\n          return this.subruleInternalRecord(arg1, idx, arg2);\n        };\n        this[`option`] = function (idx, arg1) {\n          return this.optionInternalRecord(arg1, idx);\n        };\n        this[`or`] = function (idx, arg1) {\n          return this.orInternalRecord(arg1, idx);\n        };\n        this[`many`] = function (idx, arg1) {\n          this.manyInternalRecord(idx, arg1);\n        };\n        this[`atLeastOne`] = function (idx, arg1) {\n          this.atLeastOneInternalRecord(idx, arg1);\n        };\n        this.ACTION = this.ACTION_RECORD;\n        this.BACKTRACK = this.BACKTRACK_RECORD;\n        this.LA = this.LA_RECORD;\n      });\n    }\n    disableRecording() {\n      this.RECORDING_PHASE = false;\n      this.TRACE_INIT(\"Deleting Recording methods\", () => {\n        const that = this;\n        for (let i = 0; i < 10; i++) {\n          const idx = i > 0 ? i : \"\";\n          delete that[`CONSUME${idx}`];\n          delete that[`SUBRULE${idx}`];\n          delete that[`OPTION${idx}`];\n          delete that[`OR${idx}`];\n          delete that[`MANY${idx}`];\n          delete that[`MANY_SEP${idx}`];\n          delete that[`AT_LEAST_ONE${idx}`];\n          delete that[`AT_LEAST_ONE_SEP${idx}`];\n        }\n        delete that[`consume`];\n        delete that[`subrule`];\n        delete that[`option`];\n        delete that[`or`];\n        delete that[`many`];\n        delete that[`atLeastOne`];\n        delete that.ACTION;\n        delete that.BACKTRACK;\n        delete that.LA;\n      });\n    }\n    //   Parser methods are called inside an ACTION?\n    //   Maybe try/catch/finally on ACTIONS while disabling the recorders state changes?\n    // @ts-expect-error -- noop place holder\n    ACTION_RECORD(impl) {}\n    // Executing backtracking logic will break our recording logic assumptions\n    BACKTRACK_RECORD(grammarRule, args) {\n      return () => true;\n    }\n    // LA is part of the official API and may be used for custom lookahead logic\n    // by end users who may forget to wrap it in ACTION or inside a GATE\n    LA_RECORD(howMuch) {\n      return END_OF_FILE;\n    }\n    topLevelRuleRecord(name, def) {\n      try {\n        const newTopLevelRule = new Rule({\n          definition: [],\n          name\n        });\n        newTopLevelRule.name = name;\n        this.recordingProdStack.push(newTopLevelRule);\n        def.call(this);\n        this.recordingProdStack.pop();\n        return newTopLevelRule;\n      } catch (originalError) {\n        if (originalError.KNOWN_RECORDER_ERROR !== true) {\n          try {\n            originalError.message = originalError.message + '\\n\t This error was thrown during the \"grammar recording phase\" For more info see:\\n\thttps://chevrotain.io/docs/guide/internals.html#grammar-recording';\n          } catch (mutabilityError) {\n            throw originalError;\n          }\n        }\n        throw originalError;\n      }\n    }\n    // Implementation of parsing DSL\n    optionInternalRecord(actionORMethodDef, occurrence) {\n      return recordProd.call(this, Option, actionORMethodDef, occurrence);\n    }\n    atLeastOneInternalRecord(occurrence, actionORMethodDef) {\n      recordProd.call(this, RepetitionMandatory, actionORMethodDef, occurrence);\n    }\n    atLeastOneSepFirstInternalRecord(occurrence, options) {\n      recordProd.call(this, RepetitionMandatoryWithSeparator, options, occurrence, HANDLE_SEPARATOR);\n    }\n    manyInternalRecord(occurrence, actionORMethodDef) {\n      recordProd.call(this, Repetition, actionORMethodDef, occurrence);\n    }\n    manySepFirstInternalRecord(occurrence, options) {\n      recordProd.call(this, RepetitionWithSeparator, options, occurrence, HANDLE_SEPARATOR);\n    }\n    orInternalRecord(altsOrOpts, occurrence) {\n      return recordOrProd.call(this, altsOrOpts, occurrence);\n    }\n    subruleInternalRecord(ruleToCall, occurrence, options) {\n      assertMethodIdxIsValid(occurrence);\n      if (!ruleToCall || has(ruleToCall, \"ruleName\") === false) {\n        const error = new Error(`<SUBRULE${getIdxSuffix(occurrence)}> argument is invalid expecting a Parser method reference but got: <${JSON.stringify(ruleToCall)}>\n inside top level rule: <${this.recordingProdStack[0].name}>`);\n        error.KNOWN_RECORDER_ERROR = true;\n        throw error;\n      }\n      const prevProd = last(this.recordingProdStack);\n      const ruleName = ruleToCall.ruleName;\n      const newNoneTerminal = new NonTerminal({\n        idx: occurrence,\n        nonTerminalName: ruleName,\n        label: options === null || options === void 0 ? void 0 : options.LABEL,\n        // The resolving of the `referencedRule` property will be done once all the Rule's GASTs have been created\n        referencedRule: void 0\n      });\n      prevProd.definition.push(newNoneTerminal);\n      return this.outputCst ? RECORDING_PHASE_CSTNODE : RECORDING_NULL_OBJECT;\n    }\n    consumeInternalRecord(tokType, occurrence, options) {\n      assertMethodIdxIsValid(occurrence);\n      if (!hasShortKeyProperty(tokType)) {\n        const error = new Error(`<CONSUME${getIdxSuffix(occurrence)}> argument is invalid expecting a TokenType reference but got: <${JSON.stringify(tokType)}>\n inside top level rule: <${this.recordingProdStack[0].name}>`);\n        error.KNOWN_RECORDER_ERROR = true;\n        throw error;\n      }\n      const prevProd = last(this.recordingProdStack);\n      const newNoneTerminal = new Terminal({\n        idx: occurrence,\n        terminalType: tokType,\n        label: options === null || options === void 0 ? void 0 : options.LABEL\n      });\n      prevProd.definition.push(newNoneTerminal);\n      return RECORDING_PHASE_TOKEN;\n    }\n  }\n  function recordProd(prodConstructor, mainProdArg, occurrence, handleSep = false) {\n    assertMethodIdxIsValid(occurrence);\n    const prevProd = last(this.recordingProdStack);\n    const grammarAction = isFunction(mainProdArg) ? mainProdArg : mainProdArg.DEF;\n    const newProd = new prodConstructor({\n      definition: [],\n      idx: occurrence\n    });\n    if (handleSep) {\n      newProd.separator = mainProdArg.SEP;\n    }\n    if (has(mainProdArg, \"MAX_LOOKAHEAD\")) {\n      newProd.maxLookahead = mainProdArg.MAX_LOOKAHEAD;\n    }\n    this.recordingProdStack.push(newProd);\n    grammarAction.call(this);\n    prevProd.definition.push(newProd);\n    this.recordingProdStack.pop();\n    return RECORDING_NULL_OBJECT;\n  }\n  function recordOrProd(mainProdArg, occurrence) {\n    assertMethodIdxIsValid(occurrence);\n    const prevProd = last(this.recordingProdStack);\n    const hasOptions = isArray$1(mainProdArg) === false;\n    const alts = hasOptions === false ? mainProdArg : mainProdArg.DEF;\n    const newOrProd = new Alternation({\n      definition: [],\n      idx: occurrence,\n      ignoreAmbiguities: hasOptions && mainProdArg.IGNORE_AMBIGUITIES === true\n    });\n    if (has(mainProdArg, \"MAX_LOOKAHEAD\")) {\n      newOrProd.maxLookahead = mainProdArg.MAX_LOOKAHEAD;\n    }\n    const hasPredicates = some(alts, currAlt => isFunction(currAlt.GATE));\n    newOrProd.hasPredicates = hasPredicates;\n    prevProd.definition.push(newOrProd);\n    forEach(alts, currAlt => {\n      const currAltFlat = new Alternative({\n        definition: []\n      });\n      newOrProd.definition.push(currAltFlat);\n      if (has(currAlt, \"IGNORE_AMBIGUITIES\")) {\n        currAltFlat.ignoreAmbiguities = currAlt.IGNORE_AMBIGUITIES;\n      } else if (has(currAlt, \"GATE\")) {\n        currAltFlat.ignoreAmbiguities = true;\n      }\n      this.recordingProdStack.push(currAltFlat);\n      currAlt.ALT.call(this);\n      this.recordingProdStack.pop();\n    });\n    return RECORDING_NULL_OBJECT;\n  }\n  function getIdxSuffix(idx) {\n    return idx === 0 ? \"\" : `${idx}`;\n  }\n  function assertMethodIdxIsValid(idx) {\n    if (idx < 0 || idx > MAX_METHOD_IDX) {\n      const error = new Error(\n      // The stack trace will contain all the needed details\n      `Invalid DSL Method idx value: <${idx}>\n\tIdx value must be a none negative value smaller than ${MAX_METHOD_IDX + 1}`);\n      error.KNOWN_RECORDER_ERROR = true;\n      throw error;\n    }\n  }\n  class PerformanceTracer {\n    initPerformanceTracer(config) {\n      if (has(config, \"traceInitPerf\")) {\n        const userTraceInitPerf = config.traceInitPerf;\n        const traceIsNumber = typeof userTraceInitPerf === \"number\";\n        this.traceInitMaxIdent = traceIsNumber ? userTraceInitPerf : Infinity;\n        this.traceInitPerf = traceIsNumber ? userTraceInitPerf > 0 : userTraceInitPerf;\n      } else {\n        this.traceInitMaxIdent = 0;\n        this.traceInitPerf = DEFAULT_PARSER_CONFIG.traceInitPerf;\n      }\n      this.traceInitIndent = -1;\n    }\n    TRACE_INIT(phaseDesc, phaseImpl) {\n      if (this.traceInitPerf === true) {\n        this.traceInitIndent++;\n        const indent = new Array(this.traceInitIndent + 1).join(\"\t\");\n        if (this.traceInitIndent < this.traceInitMaxIdent) {\n          console.log(`${indent}--> <${phaseDesc}>`);\n        }\n        const {\n          time,\n          value\n        } = timer(phaseImpl);\n        const traceMethod = time > 10 ? console.warn : console.log;\n        if (this.traceInitIndent < this.traceInitMaxIdent) {\n          traceMethod(`${indent}<-- <${phaseDesc}> time: ${time}ms`);\n        }\n        this.traceInitIndent--;\n        return value;\n      } else {\n        return phaseImpl();\n      }\n    }\n  }\n  function applyMixins(derivedCtor, baseCtors) {\n    baseCtors.forEach(baseCtor => {\n      const baseProto = baseCtor.prototype;\n      Object.getOwnPropertyNames(baseProto).forEach(propName => {\n        if (propName === \"constructor\") {\n          return;\n        }\n        const basePropDescriptor = Object.getOwnPropertyDescriptor(baseProto, propName);\n        if (basePropDescriptor && (basePropDescriptor.get || basePropDescriptor.set)) {\n          Object.defineProperty(derivedCtor.prototype, propName, basePropDescriptor);\n        } else {\n          derivedCtor.prototype[propName] = baseCtor.prototype[propName];\n        }\n      });\n    });\n  }\n  const END_OF_FILE = createTokenInstance(EOF, \"\", NaN, NaN, NaN, NaN, NaN, NaN);\n  Object.freeze(END_OF_FILE);\n  const DEFAULT_PARSER_CONFIG = Object.freeze({\n    recoveryEnabled: false,\n    maxLookahead: 3,\n    dynamicTokensEnabled: false,\n    outputCst: true,\n    errorMessageProvider: defaultParserErrorProvider,\n    nodeLocationTracking: \"none\",\n    traceInitPerf: false,\n    skipValidations: false\n  });\n  const DEFAULT_RULE_CONFIG = Object.freeze({\n    recoveryValueFunc: () => void 0,\n    resyncEnabled: true\n  });\n  var ParserDefinitionErrorType;\n  (function (ParserDefinitionErrorType2) {\n    ParserDefinitionErrorType2[ParserDefinitionErrorType2[\"INVALID_RULE_NAME\"] = 0] = \"INVALID_RULE_NAME\";\n    ParserDefinitionErrorType2[ParserDefinitionErrorType2[\"DUPLICATE_RULE_NAME\"] = 1] = \"DUPLICATE_RULE_NAME\";\n    ParserDefinitionErrorType2[ParserDefinitionErrorType2[\"INVALID_RULE_OVERRIDE\"] = 2] = \"INVALID_RULE_OVERRIDE\";\n    ParserDefinitionErrorType2[ParserDefinitionErrorType2[\"DUPLICATE_PRODUCTIONS\"] = 3] = \"DUPLICATE_PRODUCTIONS\";\n    ParserDefinitionErrorType2[ParserDefinitionErrorType2[\"UNRESOLVED_SUBRULE_REF\"] = 4] = \"UNRESOLVED_SUBRULE_REF\";\n    ParserDefinitionErrorType2[ParserDefinitionErrorType2[\"LEFT_RECURSION\"] = 5] = \"LEFT_RECURSION\";\n    ParserDefinitionErrorType2[ParserDefinitionErrorType2[\"NONE_LAST_EMPTY_ALT\"] = 6] = \"NONE_LAST_EMPTY_ALT\";\n    ParserDefinitionErrorType2[ParserDefinitionErrorType2[\"AMBIGUOUS_ALTS\"] = 7] = \"AMBIGUOUS_ALTS\";\n    ParserDefinitionErrorType2[ParserDefinitionErrorType2[\"CONFLICT_TOKENS_RULES_NAMESPACE\"] = 8] = \"CONFLICT_TOKENS_RULES_NAMESPACE\";\n    ParserDefinitionErrorType2[ParserDefinitionErrorType2[\"INVALID_TOKEN_NAME\"] = 9] = \"INVALID_TOKEN_NAME\";\n    ParserDefinitionErrorType2[ParserDefinitionErrorType2[\"NO_NON_EMPTY_LOOKAHEAD\"] = 10] = \"NO_NON_EMPTY_LOOKAHEAD\";\n    ParserDefinitionErrorType2[ParserDefinitionErrorType2[\"AMBIGUOUS_PREFIX_ALTS\"] = 11] = \"AMBIGUOUS_PREFIX_ALTS\";\n    ParserDefinitionErrorType2[ParserDefinitionErrorType2[\"TOO_MANY_ALTS\"] = 12] = \"TOO_MANY_ALTS\";\n    ParserDefinitionErrorType2[ParserDefinitionErrorType2[\"CUSTOM_LOOKAHEAD_VALIDATION\"] = 13] = \"CUSTOM_LOOKAHEAD_VALIDATION\";\n  })(ParserDefinitionErrorType || (ParserDefinitionErrorType = {}));\n  class Parser {\n    /**\n     *  @deprecated use the **instance** method with the same name instead\n     */\n    static performSelfAnalysis(parserInstance) {\n      throw Error(\"The **static** `performSelfAnalysis` method has been deprecated.\t\\nUse the **instance** method with the same name instead.\");\n    }\n    performSelfAnalysis() {\n      this.TRACE_INIT(\"performSelfAnalysis\", () => {\n        let defErrorsMsgs;\n        this.selfAnalysisDone = true;\n        const className = this.className;\n        this.TRACE_INIT(\"toFastProps\", () => {\n          toFastProperties(this);\n        });\n        this.TRACE_INIT(\"Grammar Recording\", () => {\n          try {\n            this.enableRecording();\n            forEach(this.definedRulesNames, currRuleName => {\n              const wrappedRule = this[currRuleName];\n              const originalGrammarAction = wrappedRule[\"originalGrammarAction\"];\n              let recordedRuleGast;\n              this.TRACE_INIT(`${currRuleName} Rule`, () => {\n                recordedRuleGast = this.topLevelRuleRecord(currRuleName, originalGrammarAction);\n              });\n              this.gastProductionsCache[currRuleName] = recordedRuleGast;\n            });\n          } finally {\n            this.disableRecording();\n          }\n        });\n        let resolverErrors = [];\n        this.TRACE_INIT(\"Grammar Resolving\", () => {\n          resolverErrors = resolveGrammar({\n            rules: values(this.gastProductionsCache)\n          });\n          this.definitionErrors = this.definitionErrors.concat(resolverErrors);\n        });\n        this.TRACE_INIT(\"Grammar Validations\", () => {\n          if (isEmpty(resolverErrors) && this.skipValidations === false) {\n            const validationErrors = validateGrammar({\n              rules: values(this.gastProductionsCache),\n              tokenTypes: values(this.tokensMap),\n              errMsgProvider: defaultGrammarValidatorErrorProvider,\n              grammarName: className\n            });\n            const lookaheadValidationErrors = validateLookahead({\n              lookaheadStrategy: this.lookaheadStrategy,\n              rules: values(this.gastProductionsCache),\n              tokenTypes: values(this.tokensMap),\n              grammarName: className\n            });\n            this.definitionErrors = this.definitionErrors.concat(validationErrors, lookaheadValidationErrors);\n          }\n        });\n        if (isEmpty(this.definitionErrors)) {\n          if (this.recoveryEnabled) {\n            this.TRACE_INIT(\"computeAllProdsFollows\", () => {\n              const allFollows = computeAllProdsFollows(values(this.gastProductionsCache));\n              this.resyncFollows = allFollows;\n            });\n          }\n          this.TRACE_INIT(\"ComputeLookaheadFunctions\", () => {\n            var _a, _b;\n            (_b = (_a = this.lookaheadStrategy).initialize) === null || _b === void 0 ? void 0 : _b.call(_a, {\n              rules: values(this.gastProductionsCache)\n            });\n            this.preComputeLookaheadFunctions(values(this.gastProductionsCache));\n          });\n        }\n        if (!Parser.DEFER_DEFINITION_ERRORS_HANDLING && !isEmpty(this.definitionErrors)) {\n          defErrorsMsgs = map(this.definitionErrors, defError => defError.message);\n          throw new Error(`Parser Definition Errors detected:\n ${defErrorsMsgs.join(\"\\n-------------------------------\\n\")}`);\n        }\n      });\n    }\n    constructor(tokenVocabulary, config) {\n      this.definitionErrors = [];\n      this.selfAnalysisDone = false;\n      const that = this;\n      that.initErrorHandler(config);\n      that.initLexerAdapter();\n      that.initLooksAhead(config);\n      that.initRecognizerEngine(tokenVocabulary, config);\n      that.initRecoverable(config);\n      that.initTreeBuilder(config);\n      that.initContentAssist();\n      that.initGastRecorder(config);\n      that.initPerformanceTracer(config);\n      if (has(config, \"ignoredIssues\")) {\n        throw new Error(\"The <ignoredIssues> IParserConfig property has been deprecated.\\n\tPlease use the <IGNORE_AMBIGUITIES> flag on the relevant DSL method instead.\\n\tSee: https://chevrotain.io/docs/guide/resolving_grammar_errors.html#IGNORING_AMBIGUITIES\\n\tFor further details.\");\n      }\n      this.skipValidations = has(config, \"skipValidations\") ? config.skipValidations : DEFAULT_PARSER_CONFIG.skipValidations;\n    }\n  }\n  Parser.DEFER_DEFINITION_ERRORS_HANDLING = false;\n  applyMixins(Parser, [Recoverable, LooksAhead, TreeBuilder, LexerAdapter, RecognizerEngine, RecognizerApi, ErrorHandler, ContentAssist, GastRecorder, PerformanceTracer]);\n  class CstParser2 extends Parser {\n    constructor(tokenVocabulary, config = DEFAULT_PARSER_CONFIG) {\n      const configClone = clone(config);\n      configClone.outputCst = true;\n      super(tokenVocabulary, configClone);\n    }\n  }\n  return {\n    CstParser: CstParser2,\n    Lexer: Lexer2,\n    createToken: createToken2\n  };\n})();\nexport { CstParser, Lexer, createToken };\n//# sourceMappingURL=chevrotain.js.map","map":null,"metadata":{},"sourceType":"module","externalDependencies":[]}